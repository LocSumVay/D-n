{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "362dfbb7298c4ccfb4f0bbf1a5dedc57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0f4bb0079bf4febb5f1bb48153e0d14",
              "IPY_MODEL_08c8c8b507fd4806a80a8d26cb654f2a",
              "IPY_MODEL_17b571160def451b8945c899013a089b"
            ],
            "layout": "IPY_MODEL_e3cb558ca5cf412b8831ce0eb15471b7"
          }
        },
        "e0f4bb0079bf4febb5f1bb48153e0d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d30ec370ca742e6881177b1b87b90aa",
            "placeholder": "​",
            "style": "IPY_MODEL_8fd6006b6a434df3b32f821ac781fb40",
            "value": "Dl Completed...: 100%"
          }
        },
        "08c8c8b507fd4806a80a8d26cb654f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bf8b163710e4a7e8a561f0dffab6996",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4c08a8964ce430089fd1e463e97ea6b",
            "value": 1
          }
        },
        "17b571160def451b8945c899013a089b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20ef2aa8de1e4d41b1a3464f071b5c8f",
            "placeholder": "​",
            "style": "IPY_MODEL_b2cecf6df1f14bcf84082a595d25bd15",
            "value": " 1/1 [10:34&lt;00:00, 257.78s/ url]"
          }
        },
        "e3cb558ca5cf412b8831ce0eb15471b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d30ec370ca742e6881177b1b87b90aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fd6006b6a434df3b32f821ac781fb40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bf8b163710e4a7e8a561f0dffab6996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e4c08a8964ce430089fd1e463e97ea6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20ef2aa8de1e4d41b1a3464f071b5c8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2cecf6df1f14bcf84082a595d25bd15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3648620bb7e547db9c42caec8b1f6e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a290ad3aaa64040ac49d32a23359fa3",
              "IPY_MODEL_b860646f7055468e8b5491b91820af4e",
              "IPY_MODEL_ec247e9aa6934e3382b3858b463032be"
            ],
            "layout": "IPY_MODEL_d1036df891c645e096a8c18d5c60d438"
          }
        },
        "0a290ad3aaa64040ac49d32a23359fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80cc5300df2f4a6489569eafd090fda7",
            "placeholder": "​",
            "style": "IPY_MODEL_0b65c9dc2e064f84a7ecbec5add31474",
            "value": "Dl Size...: 100%"
          }
        },
        "b860646f7055468e8b5491b91820af4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7b29a5bf00b43378227429960dc55d2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80929b05f75847ab924da25a5a9fbdec",
            "value": 1
          }
        },
        "ec247e9aa6934e3382b3858b463032be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faff839ee9f54165b4f53673a8771b81",
            "placeholder": "​",
            "style": "IPY_MODEL_96c8ca43139847fcbaf40fcd93d67903",
            "value": " 4764/4764 [10:34&lt;00:00, 19.87 MiB/s]"
          }
        },
        "d1036df891c645e096a8c18d5c60d438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80cc5300df2f4a6489569eafd090fda7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b65c9dc2e064f84a7ecbec5add31474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7b29a5bf00b43378227429960dc55d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "80929b05f75847ab924da25a5a9fbdec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "faff839ee9f54165b4f53673a8771b81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96c8ca43139847fcbaf40fcd93d67903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1d81a1b9b3441309f4b79ef4f016c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2cc5ff48be846558982c3d3e4520b60",
              "IPY_MODEL_fe8a4c192bab47d7b4dca1548e84c3d1",
              "IPY_MODEL_f6304526f01048348798d93fb7cb9faf"
            ],
            "layout": "IPY_MODEL_8cfab347b74a4d25839432e1e129271e"
          }
        },
        "c2cc5ff48be846558982c3d3e4520b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23ea32e8adc642fdae55dda5d17d60c0",
            "placeholder": "​",
            "style": "IPY_MODEL_66b03592b2f548be968dfbe40314fd65",
            "value": "Extraction completed...:   2%"
          }
        },
        "fe8a4c192bab47d7b4dca1548e84c3d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70326882a8c644ff8bb5f14bf468bf9b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8b7173918444f16a3410b447dfb5a81",
            "value": 1
          }
        },
        "f6304526f01048348798d93fb7cb9faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba1fae6497b944969114607da4167a89",
            "placeholder": "​",
            "style": "IPY_MODEL_f91048a9e9124a589d5d990466b988bb",
            "value": " 2139/101008 [10:34&lt;6:07:14,  4.49 file/s]"
          }
        },
        "8cfab347b74a4d25839432e1e129271e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23ea32e8adc642fdae55dda5d17d60c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66b03592b2f548be968dfbe40314fd65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70326882a8c644ff8bb5f14bf468bf9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c8b7173918444f16a3410b447dfb5a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba1fae6497b944969114607da4167a89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f91048a9e9124a589d5d990466b988bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/tensorflow-deep-learning/blob/main/07_food_vision_milestone_project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2PPYrQIztfX"
      },
      "source": [
        "# 07. Milestone Project 1: 🍔👁 Food Vision Big™\n",
        "\n",
        "Trong notebook trước ([transfer learning phần 3: scaling up](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb)), chúng ta đã xây dựng Food Vision mini: mô hình transfer learning đánh bại kết quả ban đầu của [tài liệu Food101](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/) chỉ với 10% dữ liệu.\n",
        "\n",
        "Có thể các bạn đang thắc mắc điều gì sẽ xảy ra nếu chúng ta sử dụng toàn bộ dữ liệu?\n",
        "\n",
        "Đây là điều mà chúng ta sẽ tìm hiểu trong notebook này!\n",
        "\n",
        "Chúng ta sẽ xây dựng Food Vision Big™ (Bài toán thực phẩm), sử dụng toàn bộ dữ liệu từ tập dữ liệu Food101.\n",
        "\n",
        "Có tổng cộng 75,750 ảnh huấn luyện và 25,250 ảnh kiểm tra.\n",
        "\n",
        "Và đoán xem...\n",
        "\n",
        "Lần này **chúng ta đặt mục tiêu vượt qua [DeepFood](https://www.researchgate.net/publication/304163308_DeepFood_Deep_Learning-Based_Food_Image_Recognition_for_Computer-Aided_Dietary_Assessment)**, tài liệu xuất bản năm 2016 sử dụng CNN được huấn luyện 2-3 ngày, đạt được top-1 accuracy (77.4%).\n",
        "\n",
        "> 🔑 **Lưu ý:** **Top-1 accuracy** nghĩa là \"độ chính xác cho đầu ra giá trị kích hoạt softmax cao nhất theo mô hình\" (do softmax xuất ra giá trị cho mỗi lớp nhưng top-1 nghĩa là chỉ giá trị lớn nhất mới được đánh giá). **Top-5 accuracy** nghĩa là \"độ chính xác cho 5 đầu ra giá trị kích hoạt softmax hàng đầu theo mô hình\", hay nói cách khác, true label có xuất hiện trong top 5 giá trị kích hoạt không? Top-5 accuracy score thường cao hơn hẳn so với top-1.\n",
        "\n",
        "|  | 🍔👁 Food Vision Big™ | 🍔👁 Food Vision mini |\n",
        "|-----|-----|-----|\n",
        "| Nguồn dataset | TensorFlow Datasets | Download đã tiền xử lý từ Kaggle |\n",
        "| Dữ liệu huấn luyện | 75,750 ảnh | 7,575 ảnh |\n",
        "| Dữ liệu kiểm tra | 25,250 ảnh | 25,250 ảnh |\n",
        "| Mixed precision | Có | Không |\n",
        "| Data loading | Thực hiện với tf.data API | Hàm đã xây của TensorFlow |  \n",
        "| Kết quả mục tiêu | 77.4% top-1 accuracy (vượt [tài liệu DeepFood](https://arxiv.org/abs/1606.05675)) | 50.76% top-1 accuracy (vượt [tài liệu Food101](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/static/bossard_eccv14_food-101.pdf)) |\n",
        "\n",
        "*Bảng so sánh sự khác nhau giữa Food Vision Big (notebook này) với Food Vision mini (notebook trước).*\n",
        "\n",
        "Cùng với nỗ lực vượt qua kết quả của tài liệu DeepFood, chúng ta sẽ tìm hiểu hai phương pháp giúp cải thiện đáng kể tốc độ huấn luyện mô hình:\n",
        "1. Prefetching\n",
        "2. Mixed precision training\n",
        "\n",
        "Chúng ta sẽ tìm hiểu thêm về chúng sau.\n",
        "\n",
        "## Những điều chúng ta sẽ tìm hiểu\n",
        "\n",
        "* Sử dụng TensorFlow Datasets để download và khám phá dữ liệu\n",
        "* Tạo hàm tiền xử lý dữ liệu\n",
        "* Batch và chuẩn bị tập dữ liệu để lập mô hình (**giúp tập dữ liệu chạy nhanh hơn**)\n",
        "* Tạo callback lập mô hình\n",
        "* Thiết lập **mixed precision training**\n",
        "* Xây dựng mô hình feature extraction (xem [transfer learning phần 1: feature extraction](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb))\n",
        "* Tinh chỉnh mô hình feature extraction (xem [transfer learning phần 2: fine-tuning](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb))\n",
        "* Xem các kết quả huấn luyện trên TensorBoard\n",
        "\n",
        "## Cách sử dụng notebook này\n",
        "\n",
        "Các bạn có thể đọc qua các mô tả và code (tất cả sẽ chạy, trừ những cell mắc lỗi có chủ đích), nhưng có một lựa chọn tốt hơn.\n",
        "\n",
        "Tự viết toàn bộ code.\n",
        "\n",
        "Nghiêm túc đấy. Hãy tạo notebook mới và tự viết lại từng dòng. Kiểm tra xem bạn có thể thay đổi nó không và lý do cho điều đó.\n",
        "\n",
        "Bạn không cần viết mô tả bằng văn bản nhưng tự viết lại code là một cách tuyệt vời để có trải nghiệm thực tiễn.\n",
        "\n",
        "Đừng lo lắng nếu mắc sai sót, ai cũng đều mắc lỗi cả. Cách thực hiện tốt hơn và mắc ít lỗi hơn là **viết nhiều code hơn**.\n",
        "\n",
        "> 📖 **Tài liệu:** Xem bộ tài liệu khóa học đầy đủ trên GitHub: https://github.com/mrdbourke/tensorflow-deep-learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLaDq25mykWN"
      },
      "source": [
        "## Kiểm tra GPU\n",
        "\n",
        "Với notebook này, chúng ta sẽ thực hiện khác biệt.\n",
        "\n",
        "Chúng ta sẽ sử dụng mixed precision training.\n",
        "\n",
        "được đề xuất trong [TensorFlow 2.4.0](https://blog.tensorflow.org/2020/12/whats-new-in-tensorflow-24.html) (đặc trưng rất mới tại thời điểm viết).\n",
        "\n",
        "**Mixed precision training** thực hiện những gì?\n",
        "\n",
        "Mixed precision training sử dụng tổ hợp của các kiểu dữ liệu precision đơn lẻ (float32) và half-preicison (float16) để tăng tốc độ huấn luyện mô hình (gấp 3 lần trên các GPU hiện đại).\n",
        "\n",
        "Chúng ta sẽ nói về điều này sau, hãy đọc [tài liệu của TensorFlow về mixed precision](https://www.tensorflow.org/guide/mixed_precision) để biết thêm chi tiết.\n",
        "\n",
        "Còn bây giờ, trước khi đi tiếp, nếu muốn sử dụng mixed precision training, chúng ta cần đảm bảo GPU cấp nguồn cho phiên bản Google Colab của chúng ta (nếu bạn đang sử dụng Google Colab) tương thích.\n",
        "\n",
        "Để mixed precision training hoạt động, cần truy cập vào GPU với hệ số tương thích tính toán trên 7.0.\n",
        "\n",
        "Google Colab cung cấp các GPU P100, K80 và T4, tuy nhiên, **GPU P100 và K80 không tương thích với mixed precision training**.\n",
        "\n",
        "Do đó, trước khi tiến hành, chúng ta cần đảm bảo **có quyền truy cập vào GPU Tesla T4 ở phiên bản Google Colab**.\n",
        "\n",
        "Nếu bạn đang không dùng Google Colab, có thể tìm danh sách các [khả năng tính toán khác nhau của Nvidia GPU trên website Nvidia developer](https://developer.nvidia.com/cuda-gpus#compute).\n",
        "\n",
        "> 🔑 **Lưu ý:** Nếu bạn chạy cell bên dưới và thấy P100 hoặc K80, hãy thử vào Runtime -> Factory Reset Runtime (lưu ý: điều này sẽ loại bất cứ dữ liệu và biến đã lưu nào khỏi phiên bản Colab) rồi thử lại để lấy T4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAC_5rYJicZ4",
        "outputId": "93f103a3-0704-4845-cc07-4fb6e4a9371e"
      },
      "source": [
        "# Nếu không dùng Google Colab, điều này sẽ xuất ra \"Tesla T4\", nếu không,\n",
        "# bạn sẽ không thể sử dụng mixed precision training\n",
        "!nvidia-smi -L"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWgb38BYKhS_"
      },
      "source": [
        "Do mixed precision training được đề xuất trong TensorFlow 2.4.0 nên hãy đảm bảo bạn sử dụng TensorFlow ít nhất là từ bản 2.4.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LpEDWLxKg46",
        "outputId": "bb9c2ec1-8901-4729-d6eb-e4eeabbc5fe0"
      },
      "source": [
        "# Kiểm tra phiên bản TensorFlow (nên là từ 2.4.0 trở lên)\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPwSfuFDzT5v"
      },
      "source": [
        "## Tạo hàm hỗ trợ\n",
        "\n",
        "Chúng ta đã tạo một chuỗi các hàm hỗ trợ ở notebook trước. Thay vì viết lại (điều này rất dài dòng), chúng ta sẽ import file [`helper_functions.py`](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py) từ kho GitHub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC2R6bOZzhQd",
        "outputId": "ff0e861a-117e-4da6-bd47-d79d7409898c"
      },
      "source": [
        "# Lấy file hàm hỗ trợ\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-21 19:01:38--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-21 19:01:38 (30.6 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqKKuFt7zYvf"
      },
      "source": [
        "# Import chuỗi các hàm hỗ trợ cho notebook (chúng ta đã tạo/sử dụng trong notebook trước)\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5BE7WYl9b_8"
      },
      "source": [
        "## Sử dụng TensorFlow Datasets để download dữ liệu\n",
        "\n",
        "Ở notebook trước, chúng ta đã download ảnh thực phẩm (từ [tập dữ liệu Food101](https://www.kaggle.com/dansbecker/food-101/home)) trên Google Storage.\n",
        "\n",
        "Đây là quy trình điển hình mà chúng ta sẽ dùng nếu đang làm việc với tập dữ liệu của mình.\n",
        "\n",
        "Tuy nhiên, có một cách khác để chuẩn bị sẵn các tập dữ liệu dùng với TensorFlow.\n",
        "\n",
        "Chúng ta có thể truy cập nhiều tập dữ liệu phổ biến nhất trong thế giới Machine learning (thường đề cập tới và sử dụng như các đánh giá xếp hạng) qua [TensorFlow Datasets (TFDS)](https://www.tensorflow.org/datasets/overview).\n",
        "\n",
        "**TensorFlow Datasets** là gì?\n",
        "\n",
        "Nơi dành cho cho các tập dữ liệu ML đã chuẩn bị và sẵn sàng để sử dụng.\n",
        "\n",
        "Tại sao cần sử dụng TensorFlow Datasets?\n",
        "\n",
        "* Load dữ liệu đã có trong Tensor\n",
        "* Luyện tập trên các tập dữ liệu đã thiết lập tốt\n",
        "* Thử nghiệm với các kỹ thuật data loading khác nhau (như chúng ta sẽ dùng trong notebook này\n",
        "* Thử nghiệm với các đặc trưng TensorFlow mới một cách nhanh chóng (như mixed precision training)\n",
        "\n",
        "Tại sao không sử dụng TensorFlow Datasets?\n",
        "\n",
        "* Các tập dữ liệu tĩnh (chúng không thay đổi, giống như các tập dữ liệu trong thực tế)\n",
        "* Có thể không thích hợp với bài toán vấn đề của bạn (nhưng tốt để thử nghiệm)\n",
        "\n",
        "Để bắt đầu, chúng ta sẽ import TensorFlow Datasets dưới alias `tfds`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDMExkAG8ztE"
      },
      "source": [
        "# Lấy TensorFlow Datasets\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TRPTGvpNuJm"
      },
      "source": [
        "Để tìm tất cả các tập dữ liệu có sẵn trong TensorFlow Datasets, bạn có thể dùng phương thức `list_builders()`.\n",
        "\n",
        "Sau đó, chúng ta có thể kiểm tra xem tập dữ liệu mà chúng ta theo dõi (`\"food101\"`) có hiện diện không."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXA8b2619s0X",
        "outputId": "8b69b698-f3e7-4178-9c87-07cb78780988"
      },
      "source": [
        "# Liệt kê các tập dữ liệu có sẵn\n",
        "datasets_list = tfds.list_builders() # lấy tất cả các tập dữ liệu có sẵn trong TFDS\n",
        "print(\"food101\" in datasets_list) # tập dữ liệu mà chúng ta đang tìm có sẵn không?"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUK_zulYNfVY"
      },
      "source": [
        "Có vẻ tập dữ liệu mà chúng ta theo dõi đã có sẵn (lưu ý có nhiều tập dữ liệu có sẵn nhưng chúng ta chỉ theo dõi Food101).\n",
        "\n",
        "Chúng ta có thể sử dụng phương thức [`tfds.load()`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load) để truy cập vào tập dữ liệu Food101 từ TFDS.\n",
        "\n",
        "Cụ thể, chúng ta sẽ phải truyền cho nó một ít tham số để cho nó biết chúng ta đang tìm gì:\n",
        "* `name` (str) : tập dữ liệu mục tiêu (chẳng hạn: `\"food101\"`)\n",
        "* `split` (list, tùy chọn) : phần dữ liệu chia tách của tập dữ liệu mà chúng ta đang theo dõi (chẳng hạn: `[\"train\", \"validation\"]`)\n",
        "  * tham số `split` khá phức tạp. Xem [tài liệu](https://github.com/tensorflow/datasets/blob/master/docs/splits.md) để biết thêm.\n",
        "* `shuffle_files` (bool) : có xáo trộn các file trong download hay không, mặc định là `False`\n",
        "* `as_supervised` (bool) : `True` để download các mẫu dữ liệu ở định dạng tuple (`(data, label)`) hoặc `False` cho định dạng dictionary\n",
        "* `with_info` (bool) : `True` để download tập dữ liệu metadata (nhãn, số mẫu,...)\n",
        "\n",
        "> 🔑 **Lưu ý:** Việc gọi phương thức `tfds.load()` sẽ bắt đầu download một tập dữ liệu mục tiêu vào ổ đĩa nếu tham số `download=True` được thiết lập (mặc định). Tập dữ liệu này có thể trên 100GB nên hãy đảm bảo bạn có đủ dung lượng."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "362dfbb7298c4ccfb4f0bbf1a5dedc57",
            "e0f4bb0079bf4febb5f1bb48153e0d14",
            "08c8c8b507fd4806a80a8d26cb654f2a",
            "17b571160def451b8945c899013a089b",
            "e3cb558ca5cf412b8831ce0eb15471b7",
            "2d30ec370ca742e6881177b1b87b90aa",
            "8fd6006b6a434df3b32f821ac781fb40",
            "7bf8b163710e4a7e8a561f0dffab6996",
            "e4c08a8964ce430089fd1e463e97ea6b",
            "20ef2aa8de1e4d41b1a3464f071b5c8f",
            "b2cecf6df1f14bcf84082a595d25bd15",
            "3648620bb7e547db9c42caec8b1f6e90",
            "0a290ad3aaa64040ac49d32a23359fa3",
            "b860646f7055468e8b5491b91820af4e",
            "ec247e9aa6934e3382b3858b463032be",
            "d1036df891c645e096a8c18d5c60d438",
            "80cc5300df2f4a6489569eafd090fda7",
            "0b65c9dc2e064f84a7ecbec5add31474",
            "e7b29a5bf00b43378227429960dc55d2",
            "80929b05f75847ab924da25a5a9fbdec",
            "faff839ee9f54165b4f53673a8771b81",
            "96c8ca43139847fcbaf40fcd93d67903",
            "b1d81a1b9b3441309f4b79ef4f016c82",
            "c2cc5ff48be846558982c3d3e4520b60",
            "fe8a4c192bab47d7b4dca1548e84c3d1",
            "f6304526f01048348798d93fb7cb9faf",
            "8cfab347b74a4d25839432e1e129271e",
            "23ea32e8adc642fdae55dda5d17d60c0",
            "66b03592b2f548be968dfbe40314fd65",
            "70326882a8c644ff8bb5f14bf468bf9b",
            "c8b7173918444f16a3410b447dfb5a81",
            "ba1fae6497b944969114607da4167a89",
            "f91048a9e9124a589d5d990466b988bb"
          ]
        },
        "id": "ClXZDWng-s8F",
        "outputId": "a7c36000-06e6-4061-b0f6-2e6221fbf80a"
      },
      "source": [
        "# Load dữ liệu (mất khoảng 5-6 phút trong Google Colab)\n",
        "(train_data, test_data), ds_info = tfds.load(name=\"food101\", # tập dữ liệu mục tiêu để lấy từ TFDS\n",
        "                                             split=[\"train\", \"validation\"], # chúng ta nên lấy phần chia tách dữ liệu nào? lưu ý: không phải tất cả các tập dữ liệu đều có train, valid, test\n",
        "                                             shuffle_files=True, # có xáo trộn file trong download không?\n",
        "                                             as_supervised=True, # download dữ liệu ở định dạng tuple (sample, label), chẳng hạn (image, label)\n",
        "                                             with_info=True) # có gồm tập dữ liệu metadata không? nếu có, tfds.load() trả về tuple (data, ds_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 4.65 GiB (download: 4.65 GiB, generated: Unknown size, total: 4.65 GiB) to /root/tensorflow_datasets/food101/2.0.0...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "362dfbb7298c4ccfb4f0bbf1a5dedc57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3648620bb7e547db9c42caec8b1f6e90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1d81a1b9b3441309f4b79ef4f016c82"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSxo6soUwTQl"
      },
      "source": [
        "Sau vài phút download, chúng ta đã truy cập vào toàn bộ tập dữ liệu Food101 (ở dạng tensor), sẵn sàng để lập mô hình.\n",
        "\n",
        "Giờ hãy lấy một ít thông tin từ tập dữ liệu của chúng ta, bắt đầu với tên lớp.\n",
        "\n",
        " Việc lấy tên lớp từ tập dữ liệu TFDS yêu cầu download biến \"`dataset_info`\" (bằng cách dùng tham số `as_supervised=True` trong phương thức `tfds.load()`, **lưu ý:** điều này sẽ chỉ hoạt động với các tập dữ liệu được giám sát trong TFDS)\n",
        "\n",
        "Chúng ta có thể truy cập tên lớp của một tập dữ liệu cụ thể với thuộc tính `dataset_info.features` và truy cập thuộc tính `names` của khóa `\"label\"`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zoy8Tu7VR2ji"
      },
      "source": [
        "# Các đặc trưng của Food101 TFDS\n",
        "ds_info.features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2UkCaLsDXaR"
      },
      "source": [
        "# Lấy tên lớp\n",
        "class_names = ds_info.features[\"label\"].names\n",
        "class_names[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwsBAkGKwh08"
      },
      "source": [
        "### Khám phá dữ liệu Food101 từ TFDS\n",
        "\n",
        "Chúng ta đã download tập dữ liệu Food101 từ TFDS, hãy thực hiện những gì mà một nhà khám phá dữ liệu tốt nên làm.\n",
        "\n",
        "Nói cách khác, hãy \"visualize, visualize, visualize (trực quan hóa)\"\n",
        "\n",
        "Tìm hiểu một vài chi tiết về tập dữ liệu của chúng ta:\n",
        "* Shape của dữ liệu đầu vào (image tensor)\n",
        "* Kiểu dữ liệu của dữ liệu đầu vào\n",
        "* Label của dữ liệu đầu vào trông như thế nào? (chẳng hạn: mã hóa one-hot với mà hóa nhãn)\n",
        "* Các nhãn có khớp với tên lớp không?\n",
        "\n",
        "Để thực hiện, hãy lấy một mẫu từ dữ liệu huấn luyện (sử dụng [phương thức `.take()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#take)) và khám phá nó."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eO2qVy3A-CC"
      },
      "source": [
        "# Lấy một mẫu từ dữ liệu huấn luyện\n",
        "train_one_sample = train_data.take(1) # các mẫu ở định dạng (image_tensor, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsZj4K3ETdvB"
      },
      "source": [
        "Vì chúng ta đã sử dụng tham số `as_supervised=True` trong phương thức `tfds.load()` ở trên nên các mẫu dữ liệu có cấu trúc dạng tuple `(data, label)` hoặc trong trường hợp của chúng ta `(image_tensor, label)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m--0wDNDTU8S"
      },
      "source": [
        "# Một mẫu của dữ liệu huấn luyện trông như thế nào?\n",
        "train_one_sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP1MeznpTsbM"
      },
      "source": [
        "Hãy lặp qua một mẫu huấn luyện đơn lẻ và lấy một số thông tin từ `image_tensor` và `label`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjz4goiHBMO7"
      },
      "source": [
        "# Xuất ra thông tin về mẫu huấn luyện\n",
        "for image, label in train_one_sample:\n",
        "  print(f\"\"\"\n",
        "  Image shape: {image.shape}\n",
        "  Image dtype: {image.dtype}\n",
        "  Target class from Food101 (tensor form): {label}\n",
        "  Class name (str form): {class_names[label.numpy()]}\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4_od8dUUSHE"
      },
      "source": [
        "Bởi vì chúng ta sẽ thiết lập tham số `shuffle_files=True` trong phương thức `tfds.load()` ở trên nên việc chạy cell trên một vài lần sẽ cho các kết quả khác nhau mỗi lần.\n",
        "\n",
        "Kiểm tra chúng, bạn sẽ nhận thấy một số ảnh có các shape khác nhau, chẳng hạn: `(512, 342, 3)` và `(512, 512, 3)` (height, width, color_channels).\n",
        "\n",
        "Hãy xem một trong số các image tensor của tập dữ liệu Food101 từ TFDS trông như thế nào."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuZmVEH-WS4b"
      },
      "source": [
        "# Image tensor từ tập dữ liệu Food101 của TFDS trông như thế nào?\n",
        "image_1 = image_1\n",
        "image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jJF7njRVKh6"
      },
      "source": [
        "# Giá trị lớn nhất và nhỏ nhất là bao nhiêu?\n",
        "tf.reduce_min(image), tf.reduce_max(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2GvO7HjVF5i"
      },
      "source": [
        "Có vẻ image tensor có các giá trị trong khoảng 0-255 (các giá trị màu red, green, blue tiêu chuẩn) và các giá trị thuộc kiểu dữ liệu `unit8`.\n",
        "\n",
        "Chúng ta có thể sẽ phải tiền xử lý chúng trước khi truyền chúng vào mạng nơ-ron. Tuy nhiên, chúng ta sẽ giải quyết điều này sau.\n",
        "\n",
        "Trong lúc đó, hãy xem chúng ta có thể vẽ mẫu ảnh không."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llQyIBfJWc5x"
      },
      "source": [
        "### Vẽ ảnh từ TensorFlow Datasets\n",
        "\n",
        "Chúng ta đã thấy các image tensor ở định dạng tensor, bây giờ hãy thực hiện theo phương châm của chúng ta.\n",
        "\n",
        "\"Visualize, visualize, visualize!\"\n",
        "\n",
        "Hãy vẽ một trong các mẫu ảnh sử dụng [`matplotlib.pyplot.imshow()`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html) và đặt title thành tên lớp mục tiêu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK581hgPWyLm"
      },
      "source": [
        "# Vẽ image tensor\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(image)\n",
        "plt.title(class_names[label.numpy()]) # thêm title vào ảnh bằng cách lập chỉ mục danh sách class_names\n",
        "plt.axis(False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mBAtGnPWQHy"
      },
      "source": [
        "Tuyệt!\n",
        "\n",
        "Có vẻ dữ liệu Food101 mà chúng ta thu được từ TFDS tương tự với những tập dữ liệu mà chúng ta đang sử dụng ở các notebook trước.\n",
        "\n",
        "Bây giờ hãy tiền xử lý nó và chuẩn bị để sử dụng với mạng nơ-ron."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeRJnQMIYLcy"
      },
      "source": [
        "## Tạo các hàm tiền xử lý dữ liệu\n",
        "\n",
        "Ở các notebook trước, chúng ta đã dùng phương thức [`tf.keras.preprocessing.image_dataset_from_directory()`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory) để load ảnh vào khi chúng ở định dạng folder.\n",
        "\n",
        "Thực hiện như vậy nghĩa là dữ liệu được load vào một định dạng sẵn sàng để dùng cho mô hình.\n",
        "\n",
        "Tuy nhiên, do chúng ta đã download dữ liệu từ TensorFlow Datasets nên cần thực hiện nhiều bước tiền xử lý trước khi sẵn sàng lập mô hình.\n",
        "\n",
        " Cụ thể, dữ liệu của chúng ta hiện:\n",
        "\n",
        "* Ở kiểu dữ liệu `uint8`\n",
        "* Gồm tất cả các tensor có kích thước khác nhau (các ảnh có kích thước khác nhau)\n",
        "* Không biến đổi tỷ lệ (giá trị điểm ảnh trong khoảng 0-255)\n",
        "\n",
        "Trong khi đó, các mô hình muốn dữ liệu:\n",
        "\n",
        "* Ở kiểu dữ liệu `float32`\n",
        "* Có tất cả các tensor có kích thước như nhau (các batch yêu cầu toàn bộ tensor có shape giống nhau, chẳng hạn: `(224, 224, 3)`)  \n",
        "* Có biến đổi tỷ lệ (các giá trị trong khoảng 0-1), còn được gọi là chuẩn hóa\n",
        "\n",
        "Để xử lý những điều này, chúng ta sẽ tạo hàm `preprocess_img()`:\n",
        "\n",
        "* Resize tensor ảnh đầu vào thành kích thước chỉ định với [`tf.image.resize()`](https://www.tensorflow.org/api_docs/python/tf/image/resize)\n",
        "* Chuyển kiểu dữ liệu hiện tại của tensor ảnh đầu vào thành `tf.float32` với [`tf.cast()`](https://www.tensorflow.org/api_docs/python/tf/cast)\n",
        "\n",
        "> 🔑 **Lưu ý:** Mô hình EfficientNetBX đã huấn luyện trước trong [`tf.keras.applications.efficientnet`](https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet) (thứ chúng ta sẽ sử dụng) có phép tái tỷ lệ tích hợp. Nhưng với nhiều kiến trúc mô hình khác, bạn sẽ muốn tái tỷ lệ dữ liệu của mình (chẳng hạn: lấy các giá trị trong khoảng 0-1). Điều này có thể được tích hợp bên trong hàm \"`preprocess_img()`\" (như bên dưới) hoặc trong mô hình ở dạng [`tf.keras.layers.experimental.preprocessing.Rescaling`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Rescaling) layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKuwdjm0CWc1"
      },
      "source": [
        "# Tạo hàm để tiền xử lý ảnh\n",
        "def preprocess_img(image, label, img_shape=224):\n",
        "  \"\"\"\n",
        "  Chuyển kiểu dữ liệu ảnh từ 'uint8' -> 'float32' và reshape ảnh thành\n",
        "  [img_shape, img_shape, color_channels]\n",
        "  \"\"\"\n",
        "  image = tf.image.resize(image, [img_shape, img_shape]) # reshape thành img_shape\n",
        "  return tf.cast(image, tf.float32), label # trả về tuple (float32_image, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6kGGFa1Z3Nz"
      },
      "source": [
        "Hàm `preprocess_img()` ở trên lấy ảnh và nhãn làm đầu vào (dù nó không ảnh hưởng gì tới nhãn) vì tập dữ liệu của chúng ta hiện đang ở cấu trúc tuple `(image, label)`.\n",
        "\n",
        "Hãy thử hàm trên một ảnh mục tiêu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqPDUGCvHI4K"
      },
      "source": [
        "# Tiền xử lý một mẫu ảnh đơn lẻ và kiểm tra đầu ra\n",
        "preprocessed_img = preprocess_img(image, label)[0]\n",
        "print(f\"Image before preprocessing:\\n {image[:2]}...,\\nShape: {image.shape},\\nDatatype: {image.dtype}\\n\")\n",
        "print(f\"Image after preprocessing:\\n {preprocessed_img[:2]}...,\\nShape: {preprocessed_img.shape},\\nDatatype: {preprocessed_img.dtype}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhIIvprqaHEZ"
      },
      "source": [
        "Có vẻ hàm `preprocess_img()` đang hoạt động như mong đợi.\n",
        "\n",
        "Ảnh đầu vào được chuyển từ `uint8` sang `float32` và reshape từ shape hiện tại thành `(224, 224, 3)`.\n",
        "\n",
        "Nó trông như thế nào?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYtMxQzZY0F7"
      },
      "source": [
        "# Chúng ta vẫn có thể ve ảnh đã tiền xử lý miễn là\n",
        "# chia cho 255 (để tương thích vói matplotlib)\n",
        "plt.imshow(preprocessed_img/255.)\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsIaJZEU7y_M"
      },
      "source": [
        "Hình thức ăn này khiến tôi đói rồi. Sao chúng ta không bắt đầu mô hình hóa nó?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2rd4_3CjdGE"
      },
      "source": [
        "## Batch & chuẩn bị tập dữ liệu\n",
        "\n",
        "Trước khi mô hình hóa dữ liệu, chúng ta cần biến nó thành các batch.\n",
        "\n",
        "Tại sao?\n",
        "\n",
        "Vì việc tính toán trên các batch sẽ có tiết kiệm bộ nhớ hơn.\n",
        "\n",
        "Chúng ta biến dữ liệu từ 101,000 image tensor và nhãn (kết hợp huấn luyện và kiểm tra) thành các batch gồm 32 cặp ảnh và nhãn, cho phép khớp với bộ nhớ của CPU.\n",
        "\n",
        "Để thực hiện một cách hiệu quả, chúng ta sẽ tận dụng nhiều phương thức từ [`tf.data` API](https://www.tensorflow.org/api_docs/python/tf/data).\n",
        "\n",
        "> 📖 **Tài liệu:** Hãy xem tài liệu của TensorFlow [Better performance with the tf.data API](https://www.tensorflow.org/guide/data_performance) để load dữ liệu theo cách hiệu quả nhất có thể.\n",
        "\n",
        "Cụ thể, chúng ta sẽ sử dụng:\n",
        "\n",
        "* [`map()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) - ánh xạ một hàm đã xác định trước tới tập dữ liệu mục tiêu (chẳng hạn: `preprocess_img()` tới image tensor)\n",
        "* [`shuffle()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle) - xáo trộn ngẫu nhiên các phần tử của tập dữ liệu mục tiêu trên `buffer_size` (lý tưởng là `buffer_size` bằng với kích thước của tập dữ liệu; tuy nhiên, điều này có thể ảnh hưởng tới bộ nhớ\n",
        "* [`batch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch) - biến các phần tử của tập dữ liệu mục tiêu thành các batch (do tham số `batch_size` xác định kích thước)\n",
        "* [`prefetch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch) - chuẩn bị các batch dữ liệu tiếp theo trong khi các batch dữ liệu khác được tính toán (cải thiện tốc độ load dữ liệu nhưng tốn bộ nhớ)\n",
        "* Extra: [`cache()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#cache) - trữ (lưu chúng để sử dụng sau) các phần tử trong tập dữ liệu mục tiêu, lưu thời lượng load (chỉ hoạt động nếu tập dữ liệu nhỏ vừa khớp với bộ nhớ, các phiên bản Colab tiêu chuẩn chỉ có bộ nhớ 12GB)\n",
        "\n",
        "Những điều cần lưu ý:\n",
        "- Không thể nhóm hàng loạt các tensort có shape khác nhau (ví dụ: kích thước ảnh khác nhau cần reshape ảnh trước nên dùng hàm `preprocess_img()`)\n",
        "- `shuffle()` giữ buffer (vùng đệm) của số mà bạn truyền cho nó các ảnh đã xáo trộn, con số này sẽ là tất cả các mẫu trong tập huấn luyện, tuy nhiên nếu tập huấn luyện lớn thì buffer này sẽ không khớp với bộ nhớ (con số lớn như 1000 hoặc 10000 thường đã đủ để xáo trộn)\n",
        "- Đối với các phương thức với tham số `num_parallel_calls` có sẵn (chẳng hạn như `map()`), đặt nó thành `num_parallel_calls=tf.data.AUTOTUNE` sẽ đồng thời tiền xử lý và cải thiện đáng kể tốc độ\n",
        "- Không thể sử dụng `cache()` trừ khi tập dữ liệu có thể vừa với bộ nhớ\n",
        "\n",
        "Phía trên có khá nhiều thứ. Nhưng sau khi đã viết code ở dưới, mọi thứ sẽ bắt đầu dễ hiểu hơn.\n",
        "\n",
        "Chúng ta sẽ đi qua mọi thứ theo trình tự sau:\n",
        "\n",
        "```\n",
        "Dataset ban đầu (ví dụ: train_data) -> map() -> shuffle() -> batch() -> prefetch() -> PrefetchDataset\n",
        "```\n",
        "\n",
        "Điều này tương đương với diễn giải sau:\n",
        "\n",
        "> \"Hãy ánh xạ hàm tiền xử lý này trên tập dữ liệu huấn luyện, sau đó xáo trộn các phần từ trước khi nhóm chúng lại với nhau và đảm bảo bạn chuẩn bị các batch mới (prefetch) trong khi mô hình đang xem qua batch hiện tại.\"\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/07-prefetching-from-hands-on-ml.png)\n",
        "\n",
        "*Những gì xảy ra khi dùng prefetching (nhanh hơn) với không dùng prefetching (chậm hơn). **Nguồn:** [Aurélien Géron. \"Hands-On Machine Learning with Scikit-Learn\", Keras & TensorFlow, trang 422](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/).*  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhA4gq-pI2W3"
      },
      "source": [
        "# Ánh xạ hàm tiền xử lý tới dữ liệu huấn luyện (và thực hiện song song)\n",
        "train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "# Xáo trộn train_data và biến nó thành các batch và prefetch nó (load nhanh hơn)\n",
        "train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Ánh xạ hàm tiền xử lý tới dữ liệu kiểm tra\n",
        "test_data = test_data.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "# Biến dữ liệu kiểm tra thành các batch (không cần xáo trộn)\n",
        "test_data = test_data.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnTPWyAhlKO3"
      },
      "source": [
        "Giờ hãy kiểm tra xem các tập dữ liệu đã chuẩn bị trông như thế nào."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_fBkGqfJFxT"
      },
      "source": [
        "train_data, test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1fxgyWnlQNU"
      },
      "source": [
        "Xuất sắc! Có vẻ dữ liệu hiện đang ở dạng tuple `(image, label)` với kiểu dữ liệu `(tf.float32, tf.int64)`, đây là những gì mà mô hình theo đuổi.\n",
        "\n",
        "> 🔑 **Lưu ý:** Chúng ta có thể thoát mà không cần gọi phương thức `prefetch()` ở cuối tập dữ liệu, tuy nhiên các bạn có thể sẽ thấy tốc độ load dữ liệu sẽ chậm hơn đáng kể khi xây dựng mô hình. Do đó phần lớp pipeline đầu vào tập dữ liệu sẽ kết thúc với một lệnh gọi [`prefecth()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj3umnpMvSw8"
      },
      "source": [
        "## Tạo modelling callback\n",
        "\n",
        "Vì chúng ta sẽ huấn luyện trên một lượng lớn dữ liệu và quá trình này có thể tốn nhiều thời gian nên hãy thiết lập một số modelling callback để chắc chắn nhật ký huấn luyện của mô hình được theo dõi và mô hình được checkpoint (lưu lại) sau nhiều mốc huấn luyện khác nhau.\n",
        "\n",
        "Để thực hiện những điều này, chúng ta sẽ sử dụng các callback sau:\n",
        "* [`tf.keras.callbacks.TensorBoard()`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) - cho phép theo dõi lịch sử huấn luyện mô hình để chúng ta có thể kiểm tra nó sau (**lưu ý:** chúng ta đã tạo callback này trước khi import nó từ `helper_functions.py` làm `create_tensorboard_callback()`)\n",
        "* [`tf.keras.callbacks.ModelCheckpoint()`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) - lưu tiến trình mô hình ở nhiều khoảng do đó chúng ta có thể load và sử dụng lại nó sau mà không cần huấn luyện lại\n",
        "  * Việc checkpoint cũng hữu ích nên chúng ta có thể bắt đầu tinh chỉnh mô hình ở một epoch nhất định và hoàn nguyên về trạng thái trước đó nếu việc tinh chỉnh không mang lại lợi ích gì"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyYmxPnlXOwd"
      },
      "source": [
        "# Tạo TensorBoard callback (đã có \"create_tensorboard_callback()\" từ notebook trước)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Tạo ModelCheckpoint callback để lưu tiến trình mô hình\n",
        "checkpoint_path = \"model_checkpoints/cp.ckpt\" # việc lưu trọng số yêu cầu \".ckpt\" extension\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                      montior=\"val_acc\", # lưu các trọng số của mô hình với validation accuracy tốt nhất\n",
        "                                                      save_best_only=True, # chỉ lưu những trọng số tốt nhất\n",
        "                                                      save_weights_only=True, # chỉ lưu các trọng số của mô hình (không phải toàn bộ mô hình)\n",
        "                                                      verbose=0) # không in ra dù mô hình có đang được lưu hay không"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyXlCU50UElG"
      },
      "source": [
        "## Thiết lập mixed precision training\n",
        "\n",
        "Chúng ta đã đề cập tới mixed precision training ở trên.\n",
        "\n",
        "Tuy nhiên, chúng ta đã không giải thích nhiều về điều này.\n",
        "\n",
        "Tensor trong TensorFlow thường mặc định có kiểu dữ liệu float32 (trừ những loại được chỉ định).\n",
        "\n",
        "Trong khoa học máy tính, float32 còn được gọi là [định dạng single-precision floating-point](https://en.wikipedia.org/wiki/Single-precision_floating-point_format). 32 nghĩa là nó thường chiếm 32 bit trong bộ nhớ máy tính.\n",
        "\n",
        "Bộ nhớ của GPU có hạn, do đó nó chỉ có thể xử lý một vài float32 cùng một lúc.\n",
        "\n",
        "Lúc này mixed precision training có tác dụng.\n",
        "\n",
        "Mixed precision training dùng kết hợp tensor float16 và float32 để sử dụng bộ nhớ GPU tốt hơn.\n",
        "\n",
        "Bạn có đoán được float16 nghĩa là gì không?\n",
        "\n",
        "Nếu float32 là single-precision floating-point thì float16 là [định dạng half-precision floating-point](https://en.wikipedia.org/wiki/Half-precision_floating-point_format). Nếu bạn đoán vậy thì đúng rồi đấy! Còn nếu không đoán đúng thì cũng không sao, giờ bạn đã biết.\n",
        "\n",
        "Với những tensor ở định dạng float16, mỗi phần tử chiếm 16 bit trong bộ nhớ máy tính.\n",
        "\n",
        "Vậy điều này có gì hữu ích?\n",
        "\n",
        "Như đã đề cập trước đó, khi sử dụng mixed precision training, mô hình sẽ tận dụng các kiểu dữ liệu float32 và float32 để dùng ít bộ nhớ hơn khi có thể và chạy nhanh hơn (dùng ít bộ nhớ hơn mỗi tensor nghĩa là có thể tính toán đồng thời nhiều tensor).\n",
        "\n",
        "Như vậy, sử dụng mixed precision training có thể cải thiện hiệu suất của các GPU hiện đại (GPU với hệ số khả năng tính toán trên 7.8) lên gấp 3 lần.\n",
        "\n",
        "Hãy đọc qua [hướng dẫn của TensorFlow về mixed precision](https://www.tensorflow.org/guide/mixed_precision) để xem thêm các diễn giải chi tiết (ít nhất cũng hãy xem quan phần tổng kết).\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/07-mixed-precision-speedup-equals-3x-gpu.png)\n",
        "*Do mixed precision training sử dụng kết hợp các kiểu dữ liệu float32 và float16 nên các bạn sẽ thấy tốc độ của các GPU hiện đại tăng lên gấp 3.*\n",
        "\n",
        "> 🔑 **Lưu ý:** Nếu GPU không có hệ số trên 7.0 (chẳng hạn: P100 trong Colab) thì mixed precision sẽ không hoạt động (xem [\"Supported Hardware\"](https://www.tensorflow.org/guide/mixed_precision#supported_hardware) trong hướng dẫn về mixed precision để biết thêm chi tiết).\n",
        "\n",
        "> 📖 **Tài liệu:** Để tìm hiểu thêm về precision trong khoa học máy tính (chi tiết đại lượng số mà máy tính biểu thị), hãy xem trên [Wikipedia](https://en.wikipedia.org/wiki/Precision_(computer_science)) (và các tài liệu đi kèm).\n",
        "\n",
        "Hãy xem làm thế nào để khởi động mixed precision training trong TensorFlow.\n",
        "\n",
        "Điều tuyệt vời là [`tensorflow.keras.mixed_precision`](https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/) API giúp chúng ta dễ dàng bắt đầu.\n",
        "\n",
        "Trước tiên, chúng ta sẽ import API rồi sử dụng phương thức [`set_global_policy()`](https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/set_global_policy) để đặt *dtype policy* thành `\"mixed_float16\"`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BuEjmlybR7V"
      },
      "source": [
        "# Khởi động mixed precision training\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy(policy=\"mixed_float16\") # đạt global policy thành mixed precision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLxlu7VyYoQm"
      },
      "source": [
        "Cell trên sẽ chạy mà không bị lỗi miễn là GPU có khả năng tính toán trên 7.0.\n",
        "\n",
        "Chúng ta có thể kiểm tra global dtype policy (là policy sẽ được các layer dùng trong mô hình) bằng phương thức [`mixed_precision.global_policy()`](https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/global_policy)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzSWJP8KkKae"
      },
      "source": [
        "mixed_precision.global_policy() # nên xuất ra \"mixed_float16\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpnAW2ltXCpE"
      },
      "source": [
        "Vì global dtype policy hiện giờ là `\"mixed_float16\"` nên mô hình sẽ từ động tận dụng các biến float16 khi có thể, do đó tăng tốc huấn luyện."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA8FBJwwvVoG"
      },
      "source": [
        "## Xây dựng mô hình feature extraction\n",
        "\n",
        "Callback: sẵn sàng triển khai.\n",
        "\n",
        "Mixed precision: đã khởi động.\n",
        "\n",
        "Hãy xây dựng mô hình.\n",
        "\n",
        "Do tập dữ liệu khá lớn nên chúng ta sẽ tinh chỉnh pretrained model đang có (EfficienetNetB0).\n",
        "\n",
        "Nhưng trước khi tiến hành fine-tuning, hãy thiết lập mô hình feature-extraction.\n",
        "\n",
        "Xin nhắc lại trình tự điển hình cho transfer learning như sau:\n",
        "\n",
        "1. Xây dựng mô hình feature extraction (thay vài layer trên đầu của pretrained model)\n",
        "2. Huấn luyện vài epoch với các layer thấp hơn bị đóng băng\n",
        "3. Tinh chỉnh nếu cần với nhiều layer không bị đóng băng\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/07-feature-extraction-then-fine-tune.png)\n",
        "*Trước khi tinh chỉnh, tốt nhất là huấn luyện mô hình feature extraction với các layer trên cùng tùy chỉnh.*\n",
        "\n",
        "Để xây dựng mô hình feature extraction (đề cập trong [Transfer Learning trong TensorFlow Phần 1: Feature extraction](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb)), chúng ta sẽ:\n",
        "* Sử dụng `EfficientNetB0` từ [`tf.keras.applications`](https://www.tensorflow.org/api_docs/python/tf/keras/applications) đã huấn luyện trên ImageNet làm base model\n",
        "  * Chúng ta sẽ download nó mà không cần các layer trên cùng bằng tham số `include_top=False`, do đó chúng ta có thể tạo các layer đầu ra của riêng mình\n",
        "* Đóng băng các layer của base model để có thể sử dụng các pattern đã tìm hiểu trước mà mô hình tìm thấy trên ImageNet\n",
        "* Kết hợp đầu vào, base model, pooling layer và các layer đầu ra trong [Functional model](https://keras.io/guides/functional_api/)\n",
        "* Biên dịch mô hình Functional sử dụng thuật toán tối ưu Adam và [sparse categorical crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) làm hàm mất mát (do các nhãn **không** được mã hóa one-hot)\n",
        "* Khớp mô hình cho 3 epoch bằng TensorBoard và ModelCheckpoint callback\n",
        "\n",
        "> 🔑 **Lưu ý:** Vì chúng ta đang sử dụng mixed precision training nên mô hình cần một layer đầu ra riêng biệt với hard-coded `dtype=float32`, ví dụ: `layers.Activation(\"softmax\", dtype=tf.float32)`. Điều này đảm bảo đầu ra của mô hình được trả về kiểu dữ liệu float32, ổn định hơn về mặt số so với kiểu dữ liệu float16 (quan trọng với tính toán loss). Xem phần [\"Building the model\"](https://www.tensorflow.org/guide/mixed_precision#building_the_model) trong hướng dẫn của TensorFlow để biết thêm chi tiết.\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/07-mixed-precision-code-before-and-after.png)\n",
        "*Khởi động mixed precision trong TensorFlow với 3 dòng code.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrkWpCzfXKE7"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# Tạo base model\n",
        "input_shape = (224, 224, 3)\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False # freeze base model layers đóng băng các layer của base model\n",
        "\n",
        "# Tạo Functional model\n",
        "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "# Lưu ý: mô hình EfficientNetBX có tích hợp rescaling nhưng nếu mô hình của bạn không có, bạn có thể có layer như dưới đây\n",
        "# x = preprocessing.Rescaling(1./255)(x)\n",
        "x = base_model(inputs, training=False) #  chỉ đặt base_model thành chế độ suy luận\n",
        "x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
        "x = layers.Dense(len(class_names))(x) # muốn một nơ-ron đầu ra mỗi lớp\n",
        "# Tách activation của layer đầu ra, do đó chúng ta có thể xuất ra float32 activation\n",
        "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Biên dịch mô hình\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", # Sử dụng sparse_categorical_crossentropy khi các nhãn *không phải* one-hot\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfEG8ud_jsNY"
      },
      "source": [
        "# Kiểm tra mô hình\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIXkEdnNGpKi"
      },
      "source": [
        "## Kiểm tra các dtype policy của layer (chúng ta có đang dùng mixed precision không?)\n",
        "\n",
        "Mô hình đã sẵn sàng!\n",
        "\n",
        "Trước đó chúng ta có nói rằng mixed precision API sẽ tự động thay đổi dtype policy của các layer thành bất kỳ global dtype policy nào (trong trường hợp này nó là `\"mixed_float16\"`).\n",
        "\n",
        "Chúng ta có thể kiểm tra điều này bằng cách lặp qua các layer của mô hình và in ra các thuộc tính của layer như `dtype` và `dtype_policy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk__ebBLHC-Q"
      },
      "source": [
        "# Kiểm tra thuộc tính dtype_policy của các layer trong mô hình\n",
        "for layer in model.layers:\n",
        "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy) # Kiểm tra dtype policy của các layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w6Gv6ySfpNY"
      },
      "source": [
        "Qua phần trên, chúng ta thấy:\n",
        "* `layer.name` (str) : tên của layer mà chúng ta đọc được, được xác định bởi tham số `name` khi xây dựng\n",
        "* `layer.trainable` (bool) : liệu một layer có thể huấn luyện hay không (tất cả các layer đều có thể huấn luyện trừ layer efficientnetb0 vì chúng ta đã đặt thuộc tính `trainable` thành `False`\n",
        "* `layer.dtype` : kiểu dữ liệu mà layer lưu trữ các biến của nó trong đó\n",
        "* `layer.dtype_policy` : kiểu dữ liệu mà một layer tính toán trong đó\n",
        "\n",
        "> 🔑 **Lưu ý:** Một layer có thể có dtype `float32` và dtype policy `\"mixed_float16\"` vì nó lưu trữ các biến (trọng số và độ chệch) trong `float32` (ổn định hơn về mặt số học), tuy nhiên nó tính toán trong `float16` (nhanh hơn).\n",
        "\n",
        "Chúng ta cũng có thể kiểm tra các chi tiết tương tự cho base model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL_THJCYGenQ",
        "outputId": "f9fddd10-32bf-43c0-dbec-73edad6ef3a9"
      },
      "source": [
        "# Kiểm tra các layer trong base model và xem chúng đang sử dụng dtype policy nào\n",
        "for layer in model.layers[1].layers[:20]: # chỉ kiểm tra 20 layer đầu tiên để tiết kiệm không gian đầu ra\n",
        "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_1 False float32 <Policy \"float32\">\n",
            "rescaling False float32 <Policy \"mixed_float16\">\n",
            "normalization False float32 <Policy \"mixed_float16\">\n",
            "rescaling_1 False float32 <Policy \"mixed_float16\">\n",
            "stem_conv_pad False float32 <Policy \"mixed_float16\">\n",
            "stem_conv False float32 <Policy \"mixed_float16\">\n",
            "stem_bn False float32 <Policy \"mixed_float16\">\n",
            "stem_activation False float32 <Policy \"mixed_float16\">\n",
            "block1a_dwconv False float32 <Policy \"mixed_float16\">\n",
            "block1a_bn False float32 <Policy \"mixed_float16\">\n",
            "block1a_activation False float32 <Policy \"mixed_float16\">\n",
            "block1a_se_squeeze False float32 <Policy \"mixed_float16\">\n",
            "block1a_se_reshape False float32 <Policy \"mixed_float16\">\n",
            "block1a_se_reduce False float32 <Policy \"mixed_float16\">\n",
            "block1a_se_expand False float32 <Policy \"mixed_float16\">\n",
            "block1a_se_excite False float32 <Policy \"mixed_float16\">\n",
            "block1a_project_conv False float32 <Policy \"mixed_float16\">\n",
            "block1a_project_bn False float32 <Policy \"mixed_float16\">\n",
            "block2a_expand_conv False float32 <Policy \"mixed_float16\">\n",
            "block2a_expand_bn False float32 <Policy \"mixed_float16\">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GerkBr7GiDIj"
      },
      "source": [
        "> 🔑 **Lưu ý:** Mixed precision API tự động khiến các layer có lợi từ việc sử dụng `\"mixed_float16\"` dtype policy dùng nó. Nó cũng ngăn cản các layer không dùng nó khỏi việc sử dụng nó (chẳng hạn: layer chuẩn hóa ở đầu base model)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJz5S66ojyUS"
      },
      "source": [
        "## Khớp mô hình feature extraction\n",
        "\n",
        "Mô hình đã trông khá tốt. Hãy khớp nó vớ dữ liệu.\n",
        "\n",
        "3 epoch đã đủ để các layer trên cùng điều chỉnh trọng số của chúng với dữ liệu ảnh thức ăn.\n",
        "\n",
        "Để tiết kiệm thời gian mỗi epoch, chúng ta sẽ chỉ kiểm định trên 15% dữ liệu kiểm tra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v7rXZG-ZkNJ",
        "outputId": "eb77936b-21b1-41a6-bcf4-8b959d8999bc"
      },
      "source": [
        "# Khớp mô hình với các callback\n",
        "history_101_food_classes_feature_extract = model.fit(train_data,\n",
        "                                                     epochs=3,\n",
        "                                                     steps_per_epoch=len(train_data),\n",
        "                                                     validation_data=test_data,\n",
        "                                                     validation_steps=int(0.15 * len(test_data)),\n",
        "                                                     callbacks=[create_tensorboard_callback(\"training_logs\",\n",
        "                                                                                            \"efficientnetb0_101_classes_all_data_feature_extract\"),\n",
        "                                                                model_checkpoint])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: training_logs/efficientnetb0_101_classes_all_data_feature_extract/20240421-174226\n",
            "Epoch 1/3\n",
            "2368/2368 [==============================] - 245s 93ms/step - loss: 1.7197 - accuracy: 0.5813 - val_loss: 1.1303 - val_accuracy: 0.7015\n",
            "Epoch 2/3\n",
            "2368/2368 [==============================] - 205s 85ms/step - loss: 1.2002 - accuracy: 0.6898 - val_loss: 1.0275 - val_accuracy: 0.7211\n",
            "Epoch 3/3\n",
            "2368/2368 [==============================] - 208s 87ms/step - loss: 1.0550 - accuracy: 0.7244 - val_loss: 0.9978 - val_accuracy: 0.7248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg01Gh3EnQSu"
      },
      "source": [
        "Có vẻ mô hình feature extraction đang thực hiện khá tốt. Chúng ta có nên đánh giá trên toàn bộ tập dữ liệu kiểm tra không?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhV7fvTreV27",
        "outputId": "4fb6b4c1-9995-4be9-c272-1e399c52aacf"
      },
      "source": [
        "# Đánh giá mô hình (phiên bản chưa lưu) trên toàn bộ tập dữ liệu kiểm tra\n",
        "results_feature_extract_model = model.evaluate(test_data)\n",
        "results_feature_extract_model"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "790/790 [==============================] - 58s 73ms/step - loss: 0.9983 - accuracy: 0.7286\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9983130693435669, 0.7285940647125244]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI0li4ZenctF"
      },
      "source": [
        "Do chúng ta đã sử dụng `ModelCheckpoint` callback nên chúng ta có một phiên bản đã lưu của mô hình trong directory `model_checkpoints`.\n",
        "\n",
        "Hãy load nó vào và đảm bảo nó hoạt động tốt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNGoI1cS21um"
      },
      "source": [
        "## Load và đánh giá các trọng số checkpoint\n",
        "\n",
        "Chúng ta có thể load và đánh giá các checkpoint của mô hình bằng cách:\n",
        "\n",
        "1. Clone (Sao chép) mô hình sử dụng [`tf.keras.models.clone_model()`](https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model) để tạo bản sao của mô hình feature extraction có các tham số được thiết lập lại.\n",
        "2. Gọi phương thức `load_weights()` trong mô hình đã clone, truyền cho nó đường dẫn tới nơi lưu các trọng số đã chekpoint.\n",
        "3. Gọi `evaluate()` trên mô hình đã clone với các trọng số đã load.\n",
        "\n",
        "Nhắc lại rằng các checkpoint rất hữu ích khi chúng ta thực hiện thử nghiệm như tinh chỉnh mô hình. Trong trường hợp tinh chỉnh mô hình feature extraction mà không thấy có cải thiện thì chúng ta có thể hoàn nguyên về phiên bản mô hình đã checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5a_eh9RKBSY",
        "outputId": "923d4a78-8257-4fab-a52c-8f9ddb6340d9"
      },
      "source": [
        "# Clone mô hình mà chúng ta đã tạo (điều này sẽ thiết lập lại các trọng số)\n",
        "cloned_model = tf.keras.models.clone_model(model)\n",
        "cloned_model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " efficientnetb0 (Functional  (None, None, None, 1280   4049571   \n",
            " )                           )                                   \n",
            "                                                                 \n",
            " pooling_layer (GlobalAvera  (None, 1280)              0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 101)               129381    \n",
            "                                                                 \n",
            " softmax_float32 (Activatio  (None, 101)               0         \n",
            " n)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4178952 (15.94 MB)\n",
            "Trainable params: 129381 (505.39 KB)\n",
            "Non-trainable params: 4049571 (15.45 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3NBOvb9bkAHa",
        "outputId": "f4d31b7a-7300-41ba-ab54-e8c3f5567f35"
      },
      "source": [
        "# Các checkpoint được lưu ở đâu?\n",
        "checkpoint_path"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model_checkpoints/cp.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnagdIagKGZY",
        "outputId": "27f2dbf5-2e6c-4dfa-9eab-51741a9764ca"
      },
      "source": [
        "# Load các trọng số được checkpoint vào mô hình đã clone\n",
        "cloned_model.load_weights(checkpoint_path)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f59abe38ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh_-7URJlapr"
      },
      "source": [
        "Mỗi lần thay đổi mô hình (gồm việc load các trọng số), chúng ta phải biên dịch lại."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So0ybUwRKNSf"
      },
      "source": [
        "# Biên dịch cloned_model (với các tham số tương tự như mô hình ban đầu)\n",
        "cloned_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=[\"accuracy\"])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZtbkOhHKKLs",
        "outputId": "2f58a89b-c2c1-4b2d-ab5c-0aed1e227bea"
      },
      "source": [
        "# Đánh giá mô hình đã clone với các trọng số đã load (nên có hệ số giống với mô hình đã huấn luyện)\n",
        "results_cloned_model_with_loaded_weights = cloned_model.evaluate(test_data)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "790/790 [==============================] - 87s 103ms/step - loss: 1.3641 - accuracy: 0.6364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_441Jd7PlkN4"
      },
      "source": [
        "Kết quả của mô hình đã clone với trọng số đã load phải rất gần với kết quả của mô hình feature extraction (nếu cell dưới đây lỗi thì sẽ xảy ra lỗi)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6j46R_L3VED"
      },
      "source": [
        "Clone mô hình sẽ bảo toàn `dtype_policy` của các layer (nhưng không bảo toàn trọng số) nên chúng ta có thể tiếp tục tinh chỉnh với mô hình đã clone nếu muốn và nó vẫn sẽ sử dụng mixed precision dtype policy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjCO0tm9Je3N",
        "outputId": "8e229563-0eda-4f23-b09a-c9d1800ef8e9"
      },
      "source": [
        "# Kiểm tra các layer trong base model và xem chúng đang sử dụng dtype policy nào\n",
        "for layer in cloned_model.layers[1].layers[:20]: # chỉ kiểm tra 20 layer đầu tiên để tiết kiệm dung lượng\n",
        "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_1 True float32 <Policy \"float32\">\n",
            "rescaling False float32 <Policy \"mixed_float16\">\n",
            "normalization False float32 <Policy \"mixed_float16\">\n",
            "rescaling_1 False float32 <Policy \"mixed_float16\">\n",
            "stem_conv_pad False float32 <Policy \"mixed_float16\">\n",
            "stem_conv False float32 <Policy \"mixed_float16\">\n",
            "stem_bn False float32 <Policy \"mixed_float16\">\n",
            "stem_activation False float32 <Policy \"mixed_float16\">\n",
            "block1a_dwconv False float32 <Policy \"mixed_float16\">\n",
            "block1a_bn False float32 <Policy \"mixed_float16\">\n",
            "block1a_activation False float32 <Policy \"mixed_float16\">\n",
            "block1a_se_squeeze False float32 <Policy \"mixed_float16\">\n",
            "block1a_se_reshape False float32 <Policy \"mixed_float16\">\n",
            "block1a_se_reduce False float32 <Policy \"mixed_float16\">\n",
            "block1a_se_expand False float32 <Policy \"mixed_float16\">\n",
            "block1a_se_excite False float32 <Policy \"mixed_float16\">\n",
            "block1a_project_conv False float32 <Policy \"mixed_float16\">\n",
            "block1a_project_bn False float32 <Policy \"mixed_float16\">\n",
            "block2a_expand_conv False float32 <Policy \"mixed_float16\">\n",
            "block2a_expand_bn False float32 <Policy \"mixed_float16\">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvTGiIFv3eOe"
      },
      "source": [
        "## Lưu toàn bộ mô hình vào file\n",
        "\n",
        "Chúng ta cũng có thể lưu toàn bộ mô hình bằng phương thức [`save()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#save).\n",
        "\n",
        "Vì mô hình khá lớn, chúng ta có thể sẽ cần lưu nó vào Google Drive (nếu đang sử dụng Google Colab) để load nó cho các sử dụng sau này.\n",
        "\n",
        "> 🔑 **Lưu ý:** Lưu ý: Việc lưu vào Google Drive yêu cầu phải cài Google Drive (vào Files -> Mount Drive)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH4jkVPBoPhe"
      },
      "source": [
        "# ## Lưu mô hình vào Google Drive (tùy chọn)\n",
        "\n",
        "# # Tạo save path vào drive\n",
        "# save_dir = \"drive/MyDrive/tensorflow_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision/\"\n",
        "# # os.makedirs(save_dir) # Tạo directory nếu nó không tồn tại\n",
        "\n",
        "# # Lưu mô hình\n",
        "# model.save(save_dir)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P1L5fiwnApE"
      },
      "source": [
        "Chúng ta cũng có thể lưu nó trực tiếp vào Google Colab instance của chúng ta.\n",
        "\n",
        "> 🔑 **Lưu ý:** Lưu ý: Bộ nhớ Google Colab là tạm thời và mô hình sẽ tự xóa (cùng với bất kỳ file đã lưu nào khác) khi phiên Colab hết hạn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHKn4Ex57wzF"
      },
      "source": [
        "# Lưu mô hình cục bộ (nếu đang sử dụng Google Colab, mô hình đã lưu sẽ kết thúc Colab instance)\n",
        "save_dir = \"07_efficientnetb0_feature_extract_model_mixed_precision\"\n",
        "model.save(save_dir)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKiEXBC6n83F"
      },
      "source": [
        "Một lần nữa, chúng ta có thể kiểm tra xem mô hình có được lưu chính xác hay không bằng cách load vào và đánh giá nó."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKGDBKrU6rej"
      },
      "source": [
        "# Load mô hình đã lưu trước đó ở trên\n",
        "loaded_saved_model = tf.keras.models.load_model(save_dir)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT50keE46i9y"
      },
      "source": [
        "Việc load `SavedModel` cũng giữ lại tất cả các layer bên dưới `dtype_policy` (chúng ta muốn chúng là `\"mixed_float16\"`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUJXpxmMKnYV",
        "outputId": "317da029-cee4-4bbb-8571-f4e2160006e3"
      },
      "source": [
        "# Kiểm tra các layer trong base model và xem chúng đang sử dụng dtype policy nào\n",
        "for layer in loaded_saved_model.layers[1].layers[:20]: # chỉ kiểm tra 20 layer đầu tiên để tiết kiệm không gian đầu ra\n",
        "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_1 True float32 <Policy \"float32\">\n",
            "rescaling False float32 <Policy \"mixed_float16\">\n",
            "normalization False float32 <Policy \"mixed_float16\">\n",
            "rescaling_1 False float32 <Policy \"mixed_float16\">\n",
            "stem_conv_pad False float32 <Policy \"mixed_float16\">\n",
            "stem_conv False float32 <Policy \"mixed_float16\">\n",
            "stem_bn False float32 <Policy \"mixed_float16\">\n",
            "stem_activation False float32 <Policy \"mixed_float16\">\n",
            "block1a_dwconv False float32 <Policy \"mixed_float16\">\n",
            "block1a_bn False float32 <Policy \"mixed_float16\">\n",
            "block1a_activation False float32 <Policy \"mixed_float16\">\n",
            "block1a_se_squeeze False float32 <Policy \"mixed_float16\">\n",
            "block1a_se_reshape False float32 <Policy \"mixed_float16\">\n",
            "block1a_se_reduce False float32 <Policy \"mixed_float16\">\n",
            "block1a_se_expand False float32 <Policy \"mixed_float16\">\n",
            "block1a_se_excite False float32 <Policy \"mixed_float16\">\n",
            "block1a_project_conv False float32 <Policy \"mixed_float16\">\n",
            "block1a_project_bn False float32 <Policy \"mixed_float16\">\n",
            "block2a_expand_conv False float32 <Policy \"mixed_float16\">\n",
            "block2a_expand_bn False float32 <Policy \"mixed_float16\">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qym9gSm6vL_",
        "outputId": "ba28870b-83d7-4d78-8571-043dd742662d"
      },
      "source": [
        "# Kiểm tra chất lượng của mô hình đã load (phải giống như results_feature_extract_model)\n",
        "results_loaded_saved_model = loaded_saved_model.evaluate(test_data)\n",
        "results_loaded_saved_model"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "790/790 [==============================] - 63s 77ms/step - loss: 0.9983 - accuracy: 0.7286\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9983136057853699, 0.7285940647125244]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BUhHSXI-l0v"
      },
      "source": [
        "# Kết quả của mô hình đã load phải bằng (hoặc ít nhất là rất gần) với kết quả của mô hình trước khi lưu\n",
        "# Lưu ý: điều này sẽ chỉ hoạt động nếu bạn đã cài đặt các biến kết quả\n",
        "import numpy as np\n",
        "assert np.isclose(results_feature_extract_model, results_loaded_saved_model).all()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXlDCU8zoUiK"
      },
      "source": [
        "Đó là những gì chúng ta muốn! Mô hình đã load hoạt động như thường.\n",
        "\n",
        "> 🔑 **Lưu ý:** Hãy dành một chút thời gian để đảm bảo mô hình được lưu chính xác vì việc huấn luyện trên nhiều dữ liệu có thể tốn thời gian, cho nên đảm bảo là chúng ta không phải huấn luyện liên tục từ đầu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj21OVxBGlw9"
      },
      "source": [
        "## Chuẩn bị các layer của mô hình cho fine-tuning\n",
        "\n",
        "Mô hình feature-extraction đang cho thấy một số kết quả hứa hẹn sau ba epoch. Nhưng do chúng ta có quá nhiều dữ liệu, nên có lẽ chúng ta sẽ phải xem xét những kết quả mà chúng ta có thể nhận được khi fine-tuning (fine-tuning thường hoạt động tốt nhất khi có nhiều dữ liệu).\n",
        "\n",
        "Các bạn còn nhớ mục tiêu đánh bại [DeepFood paper](https://arxiv.org/pdf/1606.05675.pdf) không?\n",
        "\n",
        "Họ đạt được độ chính xác 77.4% - top 1 trên Food101 trong vòng 2-3 ngày huấn luyện.\n",
        "\n",
        "Bạn có nghĩ rằng fine-tuning sẽ giúp chúng ta đạt được điều đó không?\n",
        "\n",
        "Hãy cùng tìm hiểu.\n",
        "\n",
        "Trước tiên, hãy load mô hình đã lưu.\n",
        "\n",
        "> 🔑 **Lưu ý:** Cần nhớ quy trình fine-tuning truyền thống: đóng băng pre-trained base model, sau đó chỉ huấn luyện các layer đầu ra trong một vài vòng lặp để cập nhật trọng số trực tiếp với dữ liệu tùy chỉnh (feature extraction). Tiếp đó sẽ bỏ đóng băng một số hoặc tất cả các layer trong base model và tiếp tục huấn luyện cho đến khi mô hình ngừng cải thiện.\n",
        "\n",
        "Giống như tất cả các chương trình nấu, tôi đã lưu một mô hình mà tôi đã chuẩn bị trước đó (mô hình feature extraction ở trên) vào Google Storage.\n",
        "\n",
        "Chúng ta có thể download nó để đảm bảo từ giờ chúng ta sẽ sử dụng cùng một mô hình."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veoEmC6V-cZv",
        "outputId": "9f0bb734-10da-416a-ba1b-d923a68a2141"
      },
      "source": [
        "# Download mô hình đã lưu từ Google Storage\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision.zip"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-21 18:21:24--  https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.141.207, 142.251.2.207, 2607:f8b0:4023:c0d::cf, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.141.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16976857 (16M) [application/zip]\n",
            "Saving to: ‘07_efficientnetb0_feature_extract_model_mixed_precision.zip’\n",
            "\n",
            "07_efficientnetb0_f 100%[===================>]  16.19M  82.7MB/s    in 0.2s    \n",
            "\n",
            "2024-04-21 18:21:24 (82.7 MB/s) - ‘07_efficientnetb0_feature_extract_model_mixed_precision.zip’ saved [16976857/16976857]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5uIf_0J-jRt",
        "outputId": "ea5d8184-6669-47ce-fd03-075d5cbfa236"
      },
      "source": [
        "# Giải nén SavedModel đã download từ Google Storage\n",
        "!mkdir downloaded_gs_model # tạo dir mới để lưu trữ mô hình feature extraction đã download\n",
        "!unzip 07_efficientnetb0_feature_extract_model_mixed_precision.zip -d downloaded_gs_model"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  07_efficientnetb0_feature_extract_model_mixed_precision.zip\n",
            "   creating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/\n",
            "   creating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/variables/\n",
            "  inflating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/variables/variables.data-00000-of-00001  \n",
            "  inflating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/variables/variables.index  \n",
            "  inflating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/saved_model.pb  \n",
            "   creating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/assets/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xbs5ywA6_CWV",
        "outputId": "5fc67839-737c-43c8-b0db-004a0d92ec3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load và đánh giá mô hình GS đã download\n",
        "loaded_gs_model = tf.keras.models.load_model(\"/content/downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
            "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_158253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_191539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_196076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_195780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_196153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_180010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_191136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_160354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_195703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_159392) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_191213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_193678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_194051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_158768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_191907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_162720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_194708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_196195) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_194258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_188022) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_161995) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_183149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_158824) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_159787) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_158482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_158588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_195449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_194377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_162615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_192238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_160121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_192860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_191865) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_160016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_194750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_169029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_170771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_159448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_194631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_192979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_193263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_160977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_162953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_159836) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_191581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_158539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_162382) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_196449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_163238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_162277) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_192487) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_191255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_163009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_194335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_193559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_159730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_161759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_192161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_193305) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_160748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_161371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_192937) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_196568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_191788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_159106) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_159497) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_161315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_184891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_178256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_161710) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_161653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_159212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_158197) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_189764) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_192606) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_195081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_162333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_160797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_194009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_195822) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_161033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_195330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_159163) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_160459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_195407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_163058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_192280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_162671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference__wrapped_model_152628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_162044) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_158873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_160410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_195004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_192564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_161082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_161420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_193636) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_196775) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_160072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_161939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_193932) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_193186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_158302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_195123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_191462) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_196526) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_160692) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEZSqPs6pQxy",
        "outputId": "0d8c76a3-cc31-4c62-dc6f-0d9cf7dac00d"
      },
      "source": [
        "# Lấy summary của mô hình đã download\n",
        "loaded_gs_model.summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " efficientnetb0 (Functional  (None, None, None, 1280   4049571   \n",
            " )                           )                                   \n",
            "                                                                 \n",
            " pooling_layer (GlobalAvera  (None, 1280)              0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 101)               129381    \n",
            "                                                                 \n",
            " softmax_float32 (Activatio  (None, 101)               0         \n",
            " n)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4178952 (15.94 MB)\n",
            "Trainable params: 129381 (505.39 KB)\n",
            "Non-trainable params: 4049571 (15.45 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH6sS_DNzSe_"
      },
      "source": [
        "Bây giờ hãy đảm bảo rằng mô hình đã load của chúng ta đang hoạt động như mong đợi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlGs5V3Tosx3",
        "outputId": "da9bc199-cedc-4457-b2cb-d41ea09bc859"
      },
      "source": [
        "# How does the loaded model perform?\n",
        "results_loaded_gs_model = loaded_gs_model.evaluate(test_data)\n",
        "results_loaded_gs_model"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "790/790 [==============================] - 93s 109ms/step - loss: 1.0881 - accuracy: 0.7066\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0880988836288452, 0.7066138386726379]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZokTvmxzXv8"
      },
      "source": [
        "Tuyệt vời, mô hình đã load của chúng ta đang hoạt động như mong muốn.\n",
        "\n",
        "Lần đầu tạo mô hình, chúng ta đóng băng tất cả các layer trong base model bằng cách đặt `base_model.trainable=False` nhưng vì chúng ta đã load mô hình từ file, nên hãy kiểm tra xem các layer có thể huấn luyện được không."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-RQ633CapPk",
        "outputId": "db780eea-935a-4255-9ef2-c9850f35d4f3"
      },
      "source": [
        "# Có bất kỳ layer nào bị đóng băng trong mô hình của chúng ta không?\n",
        "for layer in loaded_gs_model.layers:\n",
        "  layer.trainable = True # đặt tất cả các layer thành trainable\n",
        "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy) # đảm bảo mô hình đã load đang sử dụng mixed precision dtype_policy (\"mixed_float16\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_layer True float32 <Policy \"float32\">\n",
            "efficientnetb0 True float32 <Policy \"mixed_float16\">\n",
            "pooling_layer True float32 <Policy \"mixed_float16\">\n",
            "dense True float32 <Policy \"mixed_float16\">\n",
            "softmax_float32 True float32 <Policy \"float32\">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTzYLrzGzs6W"
      },
      "source": [
        "Có vẻ như mỗi layer trong mô hình đã load đều có thể huấn luyện được. Nhưng điều gì sẽ xảy ra nếu chúng ta tìm hiểu sâu hơn một chút và kiểm tra từng layer trong base model?\n",
        "\n",
        "> 🤔 **Câu hỏi:** *Layer nào trong mô hình đã load là base model của chúng ta?*\n",
        "\n",
        "Trước khi lưu Functional model vào file, chúng ta tạo mô hình đó với năm layer (các layer bên dưới được lập chỉ mục 0):\n",
        "0. Input layer\n",
        "1. Ppre-trained base model layer (`tf.keras.applications.EfficientNetB0`)\n",
        "2. Pooling layer\n",
        "3. Fully-connected (dense) layer\n",
        "4. Output softmax activation (với float32 dtype)\n",
        "\n",
        "Do đó, để kiểm tra layer của base model, chúng ta có thể truy cập thuộc tính `layers` của layer ở chỉ mục 1 trong mô hình."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rob4ClPIa2hp",
        "outputId": "440faab9-14e3-44c6-b2e0-d8e3e7c5271b"
      },
      "source": [
        "# Kiểm tra các layer trong base model và xem chúng đang sử dụng dtype policy nào\n",
        "for layer in loaded_gs_model.layers[1].layers[:20]:\n",
        "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_1 True float32 <Policy \"float32\">\n",
            "rescaling True float32 <Policy \"mixed_float16\">\n",
            "normalization True float32 <Policy \"float32\">\n",
            "stem_conv_pad True float32 <Policy \"mixed_float16\">\n",
            "stem_conv True float32 <Policy \"mixed_float16\">\n",
            "stem_bn True float32 <Policy \"mixed_float16\">\n",
            "stem_activation True float32 <Policy \"mixed_float16\">\n",
            "block1a_dwconv True float32 <Policy \"mixed_float16\">\n",
            "block1a_bn True float32 <Policy \"mixed_float16\">\n",
            "block1a_activation True float32 <Policy \"mixed_float16\">\n",
            "block1a_se_squeeze True float32 <Policy \"mixed_float16\">\n",
            "block1a_se_reshape True float32 <Policy \"mixed_float16\">\n",
            "block1a_se_reduce True float32 <Policy \"mixed_float16\">\n",
            "block1a_se_expand True float32 <Policy \"mixed_float16\">\n",
            "block1a_se_excite True float32 <Policy \"mixed_float16\">\n",
            "block1a_project_conv True float32 <Policy \"mixed_float16\">\n",
            "block1a_project_bn True float32 <Policy \"mixed_float16\">\n",
            "block2a_expand_conv True float32 <Policy \"mixed_float16\">\n",
            "block2a_expand_bn True float32 <Policy \"mixed_float16\">\n",
            "block2a_expand_activation True float32 <Policy \"mixed_float16\">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRmD0IvT1bR_"
      },
      "source": [
        "Tuyệt vời, có vẻ như mỗi layer trong base model đều có thể huấn luyện được (không đóng băng) và mọi layer sẽ sử dụng dtype policy `\"mixed_policy16\"` đều đang sử dụng dtype policy này.\n",
        "\n",
        "Do chúng ta có rất nhiều dữ liệu (750 hình ảnh x 101 lớp huấn luyện = 75750 hình ảnh huấn luyện), nên hãy giữ tất cả các layer của base model không bị đóng băng.\n",
        "\n",
        "> 🔑 **Lưu ý:** Nếu có ít dữ liệu (ít hơn 100 hình ảnh mỗi lớp), chúng ta sẽ chỉ cần giải nén và tinh chỉnh ít layer trong base model. Nếu không, chúng ta có nguy cơ gặp overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6_6m5jb2Nea"
      },
      "source": [
        "## Callback\n",
        "\n",
        "Chúng ta sắp bắt đầu tinh chỉnh mô hình học sâu với hơn 200 layer, sử dụng hơn 100,000 hình ảnh (75k+ huấn luyện, 25K+ kiểm tra), nghĩa là thời gian huấn luyện mô hình có thể sẽ lâu hơn nhiều so với trước đây.\n",
        "\n",
        "> 🤔 **Câu hỏi:** *Quá trình huấn luyện sẽ mất bao lâu?*\n",
        "\n",
        "Có thể là một vài giờ hoặc trong trường hợp [DeepFood paper](https://arxiv.org/pdf/1606.05675.pdf) (baseline mà chúng ta đang cố gắng đánh bại), mô hình hoạt động tốt nhất của họ tốn 2-3 ngày gian huấn luyện.\n",
        "\n",
        "Chúng ta sẽ chỉ biết mất bao lâu khi bắt đầu huấn luyện.\n",
        "\n",
        "> 🤔 **Câu hỏi:** *Khi nào thì ngừng huấn luyện?*\n",
        "\n",
        "Lý tưởng nhất là khi mô hình ngừng cải thiện. Nhưng do bản chất của DL, khó có thể biết chính xác khi nào mô hình sẽ ngừng cải thiện.\n",
        "\n",
        "May thay, có một giải pháp: [`EarlyStopping` callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping).\n",
        "\n",
        "`EarlyStopping` callback giám sát một phép đo chất lượng cụ thể cho mô hình(ví dụ: `val_loss`) và khi nó ngừng cải thiện trong một số epoch, thì huấn luyện sẽ tự động dừng lại.\n",
        "\n",
        "`EarlyStopping` callback kết hợp với `ModelCheckpoint` callback sẽ tự động lưu mô hình thực hiện tốt nhất, chúng ta có thể tiếp tục huấn luyện mô hình không giới hạn số lượng epoch cho đến khi nó ngừng cải thiện.\n",
        "\n",
        "Hãy thiết lập cả hai callback để theo dõi `val_loss` của mô hình."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcKFVlXVwjJy"
      },
      "source": [
        "# Thiết lập EarlyStopping callback để ngừng huấn luyện nếu val_loss của mô hình không cải thiện trong 3 epoch\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", # theo dõi phép đo val loss\n",
        "                                                  patience=3) # nếu val loss giảm trong 3 epoch liên tiếp, hãy ngừng huấn luyện\n",
        "\n",
        "# Tạo ModelCheckpoint callback để lưu mô hình tốt nhất trong quá trình fine-tuning\n",
        "checkpoint_path = \"fine_tune_checkpoints/\"\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                      save_best_only=True,\n",
        "                                                      monitor=\"val_loss\")"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14cdwkIi4WnG"
      },
      "source": [
        "Các callback cho fine-tuning đã sẵn sàng.\n",
        "\n",
        "Nếu bạn định huấn luyện các mô hình lớn thì `ModelCheckpoint` và `EarlyStopping là hai callback mà bạn cần tìm hiểu.\n",
        "\n",
        "Chúng ta gần như đã sẵn sàng để bắt đầu tinh chỉnh mô hình, tuy nhiên còn một callback nữa mà chúng ta sẽ triển khai, đó là [`ReduceLROnPlateau`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau).\n",
        "\n",
        "Các bạn còn nhớ learning rate là siêu tham số mô hình quan trọng nhất có thể điều chỉnh không? (nếu không, hãy coi đây như một lời nhắc nhở).\n",
        "\n",
        "`ReduceLROnPlateau` callback giúp điều chỉnh learning rate.\n",
        "\n",
        "Giống như `ModelCheckpoint` và `EarlyStopping` callback, `ReduceLROnPlateau` callback theo dõi một phép đo cụ thể và khi phép đo đó ngừng cải thiện, nó sẽ giảm learning rate theo một hệ số nhất định (ví dụ: chia learning rate cho 10).\n",
        "\n",
        "> 🤔 **Câu hỏi:** *Tại sao cần giảm learning rate?*\n",
        "\n",
        "Giả sử có một đồng xu ở phía sau ghế sofa và bạn đang cố gắng lấy nó bằng các ngón tay của mình.\n",
        "\n",
        "Bây giờ, hãy coi learning rate là kích thước của các chuyển động mà bàn tay của bạn thực hiện đối với đồng xu.\n",
        "\n",
        "Bạn càng đến gần thì khả năng chuyển động tay càng nhỏ, nếu không, đồng xu sẽ bị mất.\n",
        "\n",
        "Chất lượng lý tưởng của mô hình tương đương với việc lấy đồng xu. Vì vậy, khi quá trình huấn luyện diễn ra và mô hình ngày càng tiến gần hơn đến chất lượng lý tưởng (còn gọi là **hội tụ**), chúng ta muốn số lượng nó học được ngày càng ít đi.\n",
        "\n",
        "Để thực hiện điều này, chúng ta sẽ tạo một instance của `ReduceLROnPlateau` callback để theo dõi validation loss như `EarlyStopping` callback.\n",
        "\n",
        "Khi validation loss ngừng cải thiện trong hai hoặc nhiều epoch, chúng ta sẽ giảm learning rate xuống theo hệ số 5 (ví dụ:`0.001` thành `0.0002`).\n",
        "\n",
        "Và để đảm bảo learning rate không quá thấp (có thể khiến mô hình không học được gì), chúng ta sẽ đặt learning rate tối thiểu thành `1e-7`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I794Kaiq4Ekk"
      },
      "source": [
        "# Tạo learning rate để giảm callback\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                                 factor=0.2, # nhân learning rate với 0.2 (giảm 5 lần)\n",
        "                                                 patience=2,\n",
        "                                                 verbose=1, # in ra khi nào learning rate giảm\n",
        "                                                 min_lr=1e-7)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v0BHURF6Lnz"
      },
      "source": [
        "Learning rate đã được giảm!\n",
        "\n",
        "Trước khi bắt đầu huấn luyện, chúng ta phải biên dịch lại mô hình của mình.\n",
        "\n",
        "Chúng ta sẽ sử categorical crossentropy làm loss và vì chúng ta đang tinh chỉnh, hãy sử dụng learning rate thấp hơn 10 lần so với mặc định của Adam optimizer (`1e-4` thay vì `1e-3`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlpO9LflcVHW"
      },
      "source": [
        "# Biên dịch mô hình\n",
        "loaded_gs_model.compile(loss=\"sparse_categorical_crossentropy\", # sparse_categorical_crossentropy cho các nhãn *không phải* one-hot\n",
        "                        optimizer=tf.keras.optimizers.Adam(0.0001), # learning rate thấp hơn 10 lần so với mặc định\n",
        "                        metrics=[\"accuracy\"])"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo1bio8SYxvc"
      },
      "source": [
        "Mô hình đã được biên dịch.\n",
        "\n",
        "Bây giờ hãy khớp nó với toàn bộ dữ liệu.\n",
        "\n",
        "Chúng ta sẽ thiết lập nó để chạy cho 100 epoch.\n",
        "\n",
        "Do chúng ta sẽ sử dụng `EarlyStopping` callback nên nó có thể dừng lại trước khi đạt 100 epoch.\n",
        "\n",
        "> 🔑 **Lưu ý:** Chạy cell bên dưới sẽ thiết lập mô hình để tinh chỉnh tất cả các trọng số đã huấn luyện trước trong base model trên tất cả dữ liệu của Food101. Thực hiện như vậy với data pipeline **không được tối ưu hóa** và **không có** mixed precision training sẽ tốn khá nhiều thời gian cho mỗi epoch, tùy thuộc vào loại GPU chúng ta đang dùng (khoảng 15-20 phút đối với Colab GPU). Nhưng đừng lo lắng, code mà chúng ta đã viết ở trên sẽ đảm bảo nó chạy nhanh hơn nhiều (khoảng 4-5 phút mỗi epoch)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkUtOdVkbMPC",
        "outputId": "2d490a70-b2ec-444b-c214-d0a7bf674040"
      },
      "source": [
        "# Bắt đầu tinh chỉnh (tất cả các layer)\n",
        "history_101_food_classes_all_data_fine_tune = loaded_gs_model.fit(train_data,\n",
        "                                                        epochs=100, # tinh chỉnh tối đa 100 epoch\n",
        "                                                        steps_per_epoch=len(train_data),\n",
        "                                                        validation_data=test_data,\n",
        "                                                        validation_steps=int(0.15 * len(test_data)), # validation trong quá trình huấn luyện trên 15% dữ liệu kiểm tra\n",
        "                                                        callbacks=[create_tensorboard_callback(\"training_logs\", \"efficientb0_101_classes_all_data_fine_tuning\"), # theo dõi nhật ký huấn luyện của mô hình\n",
        "                                                                   model_checkpoint, # chỉ lưu mô hình tốt nhất trong quá trình huấn luyện\n",
        "                                                                   early_stopping, # ngừng mô hình sau X epoch mà không có cải thiện\n",
        "                                                                   reduce_lr]) # giảm learning rate sau X epoch mà không có cải thiện"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: training_logs/efficientb0_101_classes_all_data_fine_tuning/20240421-182428\n",
            "Epoch 1/100\n",
            "2368/2368 [==============================] - 547s 202ms/step - loss: 0.9207 - accuracy: 0.7514 - val_loss: 0.8057 - val_accuracy: 0.7778 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "2368/2368 [==============================] - 465s 194ms/step - loss: 0.5770 - accuracy: 0.8397 - val_loss: 0.7701 - val_accuracy: 0.7903 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "1906/2368 [=======================>......] - ETA: 1:14 - loss: 0.3294 - accuracy: 0.9063"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC2HLXePh9Af"
      },
      "source": [
        "> 🔑 **Lưu ý:** Nếu không sử dụng mixed precision hoặc các kỹ thuật như [`prefetch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch) trong phần *Batch & chuẩn bị tập dữ liệu* thì việc tinh chỉnh mô hình có thể lâu hơn 2.5-3 lần mỗi epoch (xem ví dụ output bên dưới ).\n",
        "\n",
        "| | Prefetch và mixed precision | Không có prefetch và không có mixed precision |\n",
        "|-----|-----|-----|\n",
        "| Thời gian mỗi epoch | ~280-300s | ~1127-1397s |\n",
        "\n",
        "*Kết quả từ việc tinh chỉnh 🍔👁 Food Vision Big™ trên tập dữ liệu Food101, sử dụng chủ yếu là EfficienetNetB0 với Google Colab Tesla T4 GPU.*\n",
        "\n",
        "```\n",
        "Saving TensorBoard log files to: training_logs/efficientB0_101_classes_all_data_fine_tuning/20200928-013008\n",
        "Epoch 1/100\n",
        "2368/2368 [==============================] - 1397s 590ms/step - loss: 1.2068 - accuracy: 0.6820 - val_loss: 1.1623 - val_accuracy: 0.6894\n",
        "Epoch 2/100\n",
        "2368/2368 [==============================] - 1193s 504ms/step - loss: 0.9459 - accuracy: 0.7444 - val_loss: 1.1549 - val_accuracy: 0.6872\n",
        "Epoch 3/100\n",
        "2368/2368 [==============================] - 1143s 482ms/step - loss: 0.7848 - accuracy: 0.7838 - val_loss: 1.0402 - val_accuracy: 0.7142\n",
        "Epoch 4/100\n",
        "2368/2368 [==============================] - 1127s 476ms/step - loss: 0.6599 - accuracy: 0.8149 - val_loss: 0.9599 - val_accuracy: 0.7373\n",
        "```\n",
        "*Ví dụ về thời gian fine-tuning cho dữ liệu non-prefetched cũng như non-mixed precision training (lâu hơn ~ 2.5-3 lần mỗi epoch).*\n",
        "\n",
        "Hãy đảm bảo rằng chúng mô hình đã được lưu trước khi chúng ta bắt đầu đánh giá nó."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwjxnUsgI558"
      },
      "source": [
        "# # Lưu mô hình vào Google Drive (tùy chọn)\n",
        "# loaded_gs_model.save(\"/content/drive/MyDrive/tensorflow_course/food_vision/07_efficientnetb0_fine_tuned_101_classes_mixed_precision/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1As0OhYHFX-"
      },
      "source": [
        "# Lưu mô hình cục bộ (lưu ý: nếu đang sử dụng Google Colab và lưu mô hình cục bộ, mô hình sẽ bị xóa khi phiên Google Colab kết thúc)\n",
        "loaded_gs_model.save(\"07_efficientnetb0_fine_tuned_101_classes_mixed_precision\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcpNGcSAZ2UC"
      },
      "source": [
        "Có vẻ như mô hình đã đạt được một số điểm chất lượng từ fine-tuning, hãy đánh giá trên toàn bộ tập dữ liệu kiểm tra và xem liệu có thể đánh bại kết quả của [DeepFood paper](https://arxiv.org/abs/1606.05675) là độ chính xác 77.4% hay không."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CR6q8MYM37K"
      },
      "source": [
        "# Đánh giá mô hình đã load được huấn luyện với mixed precision\n",
        "results_loaded_gs_model_fine_tuned = loaded_gs_model.evaluate(test_data)\n",
        "results_loaded_gs_model_fine_tuned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR-S5bKP0IxA"
      },
      "source": [
        "Có vẻ như mô hình của chúng ta đã đánh bại các kết quả được đề cập trong DeepFood paper cho Food101 (độ chính xác 77.4% - top 1 của DeepFood so với độ chính xác ~79% top 1 của chúng ta)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0H1rSG9RBBV"
      },
      "source": [
        "## Download mô hình đã tinh chỉnh từ Google Storage\n",
        "\n",
        "Như đã đề cập trước đó, việc huấn luyện có thể tốn khá nhiều thời gian.\n",
        "\n",
        "Như bất kỳ chương trình nấu ăn nào, đây là thứ chúng ta chuẩn bị trước ...\n",
        "\n",
        "Đây là một mô hình được tinh chỉnh, giống hệt như mô hình mà chúng ta đã huấn luyện ở trên nhưng được lưu vào Google Storage để có thể truy cập, nhập và đánh giá."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRuBSsPxI8Yg"
      },
      "source": [
        "# Download và đánh giá mô hình đã tinh chỉnh từ Google Storage\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_fine_tuned_101_classes_mixed_precision.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_KhgOeA_hCG"
      },
      "source": [
        " Mô hình đã download có định dạng zip (`.zip`), vì vậy hãy giải nén nó thành Google Colab instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNh0cPL7JBpv"
      },
      "source": [
        "# Giải nén mô hình đã tinh chỉnh\n",
        "!mkdir downloaded_fine_tuned_gs_model # tạo directory riêng cho mô hình đã tinh chỉnh được download từ Google Storage\n",
        "!unzip /content/07_efficientnetb0_fine_tuned_101_classes_mixed_precision -d downloaded_fine_tuned_gs_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blFdr0QJ_oQY"
      },
      "source": [
        "Bây giờ chúng ta có thể load nó bằng phương thức [`tf.keras.models.load_model()`](https://www.tensorflow.org/tutorials/keras/save_and_load) và nhận được summary (nó phải giống hệt như mô hình chúng ta đã tạo ở trên).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBWWTb-QKuW1"
      },
      "source": [
        "# Load mô hình đã tinh chỉnh từ Google Storage và đánh giá\n",
        "loaded_fine_tuned_gs_model = tf.keras.models.load_model(\"/content/downloaded_fine_tuned_gs_model/07_efficientnetb0_fine_tuned_101_classes_mixed_precision\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sysv2pDmJoe8"
      },
      "source": [
        "# Nhận model summary (có cùng kiến trúc mô hình như trên)\n",
        "loaded_fine_tuned_gs_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxP8rbAj_4lY"
      },
      "source": [
        "Cuối cùng, chúng ta có thể đánh giá mô hình trên dữ liệu kiểm tra (cần load biến `test_data`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms0R3LZ9Jrr5"
      },
      "source": [
        "# Lưu ý: Ngay cả khi bạn đang load mô hình từ Google Storage, bạn vẫn cần load biến test_data để cell này hoạt động\n",
        "results_downloaded_fine_tuned_gs_model = loaded_fine_tuned_gs_model.evaluate(test_data)\n",
        "results_downloaded_fine_tuned_gs_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMAXmidMc_hA"
      },
      "source": [
        "Mô hình đã lưu của chúng ta đang hoạt động như mong đợi (kết quả tốt hơn so với DeepFood!).\n",
        "\n",
        "Chúc mừng! Bạn vừa huấn luyện một mô hình thị giác máy tính với chất lượng có tính cạnh tranh với một tài liệu nghiên cứu trong thời gian ngắn hơn rất nhiều (mô hình của chúng ta mất ~20 phút để huấn luyện so với mô hình của DeepFood huấn luyện trong 2-3 ngày)\n",
        "\n",
        "Nói cách khác, bạn đã cải tiến Food Vision!\n",
        "\n",
        "Nếu bạn muốn nâng cao hơn, có thể thử sử dụng mô hình [`EfficientNetB4`](https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB4) (phiên bản lớn hơn của `EfficientNetB0`). Ở thời điểm viết bài, họ EfficientNet có [kết quả phân loại tân tiến nhất](https://paperswithcode.com/sota/fine-grained-image-classification-on-food-101) trên tập dữ liệu Food101.\n",
        "\n",
        "> 📖 **Tài liệu:** Để biết mô hình nào hiện đang hoạt động tốt nhất trên một tập dữ liệu hoặc loại bài toán nhất định cũng như nghiên cứu về xu hướng học máy mới nhất, hãy kiểm tra [paperswithcode.com](http://paperswithcode.com/) và [sotabench.com](https://sotabench.com/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFjooc5Gy0I2"
      },
      "source": [
        "## Hiển thị kết quả huấn luyện trên TensorBoard\n",
        "\n",
        "Chúng ta đã theo dõi nhật ký huấn luyện fine-tuning của mô hình bằng cách sử dụng `TensorBoard` callback, hãy upload và kiểm tra chúng trên TensorBoard.dev."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW9x3o1kWlO3"
      },
      "source": [
        "!tensorboard dev upload --logdir ./training_logs \\\n",
        "  --name \"Fine-tuning EfficientNetB0 on all Food101 Data\" \\\n",
        "  --description \"Training results for fine-tuning EfficientNetB0 on Food101 Data with learning rate 0.0001\" \\\n",
        "  --one_shot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnqjq9aWM6pd"
      },
      "source": [
        "View experiment: https://tensorboard.dev/experiment/2KINdYxgSgW2bUg7dIvevw/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvn5JfmuVSCf"
      },
      "source": [
        "Xem [các training curve của mô hình trên TensorBoard.dev](https://tensorboard.dev/experiment/2KINdYxgSgW2bUg7dIvevw/), có vẻ như mô hình fine-tuning có tăng chất lượng nhưng bắt đầu quá khớp khi tiếp tục huấn luyện.\n",
        "\n",
        "Xem các training curve trên TensorBoard.dev tại đây: https://tensorboard.dev/experiment/2KINdYxgSgW2bUg7dIvevw/\n",
        "\n",
        "Để khắc phục điều này, ở các thử nghiệm tương lai, chúng ta có thể thử:\n",
        "* Một vòng lặp khác của `EfficientNet` (ví dụ: `EfficientNetB4` thay vì `EfficientNetB0`).\n",
        "* Bỏ đóng băng ít layer hơn của base model và huấn luyện chúng thay vì bỏ đóng băng toàn bộ base model trong một lần thực hiện.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUpOtu_tNWcJ"
      },
      "source": [
        "# Xem các thử nghiệm TensorBoard trước đây\n",
        "!tensorboard dev list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-Rl-L0hNbEv"
      },
      "source": [
        "# Xóa các thử nghiệm TensorBoard trước đây\n",
        "# !tensorboard dev delete --experiment_id YOUR_EXPERIMENT_ID\n",
        "\n",
        "# Ví dụ\n",
        "!tensorboard dev delete --experiment_id OAE6KXizQZKQxDiqI3cnUQ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDDrrqy5egTn"
      },
      "source": [
        "## 🛠 Bài tập thực hành\n",
        "> **Lưu ý:** Các bạn cần làm phần bài tập này để chuẩn bị cho phiên review lab.\n",
        "\n",
        "1. Sử dụng các kỹ thuật đánh giá tương tự trên mô hình Food Vision quy mô lớn như chúng ta đã thực hiện trong notebook trước ([Transfer Learning Phần 3: Scaling up](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb)). Cụ thể:\n",
        "  * Confusion matrix giữa tất cả các dự đoán của mô hình và true label.\n",
        "  * Biểu đồ hiển thị f1-score của mỗi lớp.\n",
        "2. Trực quan hóa của mô hình đưa ra dự đoán trên các hình ảnh.\n",
        "3. Huấn luyện lại mô hình (feature extraction và fine-tuning) mà chúng ta đã huấn luyện trong notebook này, ngoại trừ lần này sẽ sử dụng [`EfficientNetB4`](https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB4) làm base model thay vì `EfficientNetB0`. Bạn có thấy cải thiện về chất lượng không? Có tốn nhiều thời gian huấn luyện hơn không? Có bất kỳ đánh đổi nào cần xem xét không?\n",
        "4. Kể tên một lợi ích quan trọng của mixed precision training, lợi ích này thế nào?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Our function needs a different name to sklearn's plot_confusion_matrix\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False):\n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "\n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes),\n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "\n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  ### Added: Rotate xticks for readability & increase font size (required due to such a large confusion matrix)\n",
        "  plt.xticks(rotation=70, fontsize=text_size)\n",
        "  plt.yticks(fontsize=text_size)\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    if norm:\n",
        "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "    else:\n",
        "      plt.text(j, i, f\"{cm[i, j]}\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "\n",
        "  # Save the figure to the current working directory\n",
        "  if savefig:\n",
        "    fig.savefig(\"confusion_matrix.png\")"
      ],
      "metadata": {
        "id": "1H2XWi-poEsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_classes = loaded_gs_model.predict(test_data)\n",
        "y_labels = test_data.labels\n",
        "make_confusion_matrix(y_true=y_labels,\n",
        "                      y_pred=pred_classes,\n",
        "                      classes=class_names,\n",
        "                      figsize=(100, 100),\n",
        "                      text_size=20,\n",
        "                      norm=False,\n",
        "                      savefig=True)"
      ],
      "metadata": {
        "id": "T87I9NiZowf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_labels, pred_classes))\n",
        "class_f1_scores = {}\n",
        "# Loop through classification report items\n",
        "for k, v in classification_report_dict.items():\n",
        "  if k == \"accuracy\": # stop once we get to accuracy key\n",
        "    break\n",
        "  else:\n",
        "    # Append class names and f1-scores to new dictionary\n",
        "    class_f1_scores[class_names[int(k)]] = v[\"f1-score\"]\n",
        "class_f1_scores\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 25))\n",
        "scores = ax.barh(range(len(f1_scores)), f1_scores[\"f1-score\"].values)\n",
        "ax.set_yticks(range(len(f1_scores)))\n",
        "ax.set_yticklabels(list(f1_scores[\"class_name\"]))\n",
        "ax.set_xlabel(\"f1-score\")\n",
        "ax.set_title(\"F1-Scores for 10 Different Classes\")\n",
        "ax.invert_yaxis(); # reverse the order\n",
        "\n",
        "def autolabel(rects):\n",
        "  for rect in rects:\n",
        "    width = rect.get_width()\n",
        "    ax.text(1.03*width, rect.get_y() + rect.get_height()/1.5,\n",
        "            f\"{width:.2f}\",\n",
        "            ha='center', va='bottom')\n",
        "\n",
        "autolabel(scores)\n"
      ],
      "metadata": {
        "id": "T6A98_Jwox6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Trực quan hóa của mô hình đưa ra dự đoán\n",
        "def predict_(img,model = model):\n",
        "  img = tf.image.resize(img,(224,224))\n",
        "  img_1 = tf.expand_dims(img,axis =0)\n",
        "  kq = model.predict(img_1)\n",
        "  kq_1 = np.argmax(kq)\n",
        "  kq_2 = max(kq)\n",
        "  kq_1 =  [kq_1]\n",
        "  plt.imshow(img)\n",
        "  plt.title(f'predict {kq_1} : {kq_2*100}%')\n",
        "predict_(image_1)\n",
        "\n"
      ],
      "metadata": {
        "id": "6O3wCHrnzDmX",
        "outputId": "d2e3d814-4f8c-4cd1-9c1a-d9305eeb745d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid decimal literal (<ipython-input-47-9863107719cd>, line 10)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-47-9863107719cd>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    predict_(image*255.astype('unit8'))\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.Huấn luyện lại mô hình sử dụng EfficientNetB4\n",
        "input = tf.keras.layers.Input(shape=(224,224,3))\n",
        "base_m = tf.keras.applications.EfficientNetB4(include_top=False)\n",
        "base_m.trainable = True\n",
        "x = base_m(input)\n",
        "x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
        "x = layers.Dense(len(class_names))(x)\n",
        "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n",
        "mode_b4 = tf.keras.Model(inputs, outputs)\n",
        "model_b4.compile(loss=\"sparse_categorical_crossentropy\", # Sử dụng sparse_categorical_crossentropy khi các nhãn *không phải* one-hot\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "history_b4 = model_b4.fit(train_data,\n",
        "                          epochs=100, # tinh chỉnh tối đa 100 epoch\n",
        "                          steps_per_epoch=len(train_data),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=int(0.15 * len(test_data)), # validation trong quá trình huấn luyện trên 15% dữ liệu kiểm tra\n",
        "                          callbacks=[create_tensorboard_callback(\"training_logs\", \"efficientb0_101_classes_all_data_fine_tuning\"), # theo dõi nhật ký huấn luyện của mô hình\n",
        "                                      model_checkpoint, # chỉ lưu mô hình tốt nhất trong quá trình huấn luyện\n",
        "                                      early_stopping, # ngừng mô hình sau X epoch mà không có cải thiện\n",
        "                                      reduce_lr]) # giảm learning rate sau X epoch mà không có cải thiện\n"
      ],
      "metadata": {
        "id": "gUwxc4AD22c_",
        "outputId": "12e493f5-0358-4fdc-ee44-e093f94a26d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ce8adc201ab0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#3.Huấn luyện lại mô hình sử dụng EfficientNetB4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbase_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEfficientNetB4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbase_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Kể tên một lợi ích quan trọng của mixed precision training :\n",
        "Mixed precision training sử dụng tổ hợp của các kiểu dữ liệu precision đơn lẻ (float32) và half-preicison (float16) để tăng tốc độ huấn luyện mô hình (gấp 3 lần trên các GPU hiện đại)."
      ],
      "metadata": {
        "id": "Mnr8l_4s8caE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8ncI458ZkpA"
      },
      "source": [
        "## 📖 Tài liệu đọc thêm\n",
        "\n",
        "* Đọc thêm về hoạch định learning rate và [learning rate scheduler callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler). Đó là gì? Và nó hữu ích như thế nào đối với project này?\n",
        "* Đọc thêm về TensorFlow data loaders ([cải thiện chất lượng data loading trong TensorFlow](https://www.tensorflow.org/guide/data_performance)). Chúng ta có bỏ lỡ điều gì không? Bạn nhớ được những phương pháp nào mỗi khi load dữ liệu trong TensorFlow? Gợi ý: xem lại phần tóm tắt ở cuối trang để hiểu hơn.\n",
        "* Đọc thêm tài liệu về [TensorFlow mixed precision training](https://www.tensorflow.org/guide/mixed_precision). Chúng ta cần nhớ những điều quan trọng nào khi sử dụng mixed precision training?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_JtsvJqcsV2w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
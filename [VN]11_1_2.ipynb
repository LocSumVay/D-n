{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llc17e6ao5zZ"
   },
   "source": [
    "## Lựa chọn đặc trưng bằng Xáo trộn ngẫu nhiên (Random Shuffling)\n",
    "\n",
    "Đây là phương pháp lựa chọn đặc trưng phổ biến, xáo trộn ngẫu nhiên các giá trị của một biến cụ thể và xác định xem phép hoán vị đó ảnh hưởng như thế nào đến chỉ số chất lượng của thuật toán học máy. Nói cách khác, ý tưởng ở đây là hoán vị các giá trị của từng đặc trưng, đo mức độ hoán vị (hoặc xáo trộn các giá trị của nó) làm giảm accuracy (độ chính xác), roc_auc hoặc mse của mô hình học máy (hoặc bất kỳ số liệu chất lượng nào khác!). Nếu các biến quan trọng, hoán vị ngẫu nhiên các giá trị sẽ giảm đáng kể bất kỳ số liệu nào trong số này. Ngược lại, hoán vị hoặc xáo trộn các giá trị sẽ ít hoặc không ảnh hưởng đến chỉ số chất lượng của mô hình mà chúng ta đang đánh giá.\n",
    "\n",
    "Quy trình như sau:\n",
    "\n",
    "- Xây dựng mô hình học máy và lưu trữ chỉ số chất lượng\n",
    "- Xáo trộn một đặc trưng và đưa ra dự đoán mới sử dụng mô hình trước đó\n",
    "- Xác định chất lượng của dự đoán này\n",
    "- Xác định thay đổi trong chất lượng của dự đoán với đặc trưng đa xáo trộn so với đặc trưng ban đầu\n",
    "- Lặp lại cho từng đặc trưng\n",
    "\n",
    "Chúng ta sẽ chọn các đặc trưng làm giảm chất lượng mô hình vượt một ngưỡng thiết lập bất kỳ để lựa chọn đặc trưng.\n",
    "\n",
    "Chúng ta sẽ minh họa cách lựa chọn đặc trưng dựa trên xáo trộn ngẫu nhiên trong bài toán hồi quy và phân loại.\n",
    "\n",
    "**Lưu ý** Chúng ta sẽ tiếp tục dùng Random Forest nhưng với quy trình lựa chọn này, có thể sử dụng với cả thuật toán học máy. Trên thực tế, cần xác định rành mạch độ quan trọng của các đặc trưng cho thuật toán được dùng. Do đó, các thuật toán khác nhau sẽ trả về các tập hợp con khác nhau của đặc trưng quan trọng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BHrSh_-co5zc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XKuqsx-o5zc"
   },
   "source": [
    "## Phân loại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "utOlab-Zo5zd",
    "outputId": "2b5bf3d8-7dc9-4638-b010-c3108208d751"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 109)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load tập dữ liệu\n",
    "data = pd.read_csv('dataset_2.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wqLLhE__o5ze",
    "outputId": "8ac63dbe-1981-4e8c-9d20-c576600dd563"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>...</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_101</th>\n",
       "      <th>var_102</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_104</th>\n",
       "      <th>var_105</th>\n",
       "      <th>var_106</th>\n",
       "      <th>var_107</th>\n",
       "      <th>var_108</th>\n",
       "      <th>var_109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.532710</td>\n",
       "      <td>3.280834</td>\n",
       "      <td>17.982476</td>\n",
       "      <td>4.404259</td>\n",
       "      <td>2.349910</td>\n",
       "      <td>0.603264</td>\n",
       "      <td>2.784655</td>\n",
       "      <td>0.323146</td>\n",
       "      <td>12.009691</td>\n",
       "      <td>0.139346</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079066</td>\n",
       "      <td>6.748819</td>\n",
       "      <td>2.941445</td>\n",
       "      <td>18.360496</td>\n",
       "      <td>17.726613</td>\n",
       "      <td>7.774031</td>\n",
       "      <td>1.473441</td>\n",
       "      <td>1.973832</td>\n",
       "      <td>0.976806</td>\n",
       "      <td>2.541417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.821374</td>\n",
       "      <td>12.098722</td>\n",
       "      <td>13.309151</td>\n",
       "      <td>4.125599</td>\n",
       "      <td>1.045386</td>\n",
       "      <td>1.832035</td>\n",
       "      <td>1.833494</td>\n",
       "      <td>0.709090</td>\n",
       "      <td>8.652883</td>\n",
       "      <td>0.102757</td>\n",
       "      <td>...</td>\n",
       "      <td>2.479789</td>\n",
       "      <td>7.795290</td>\n",
       "      <td>3.557890</td>\n",
       "      <td>17.383378</td>\n",
       "      <td>15.193423</td>\n",
       "      <td>8.263673</td>\n",
       "      <td>1.878108</td>\n",
       "      <td>0.567939</td>\n",
       "      <td>1.018818</td>\n",
       "      <td>1.416433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.938776</td>\n",
       "      <td>7.952752</td>\n",
       "      <td>0.972671</td>\n",
       "      <td>3.459267</td>\n",
       "      <td>1.935782</td>\n",
       "      <td>0.621463</td>\n",
       "      <td>2.338139</td>\n",
       "      <td>0.344948</td>\n",
       "      <td>9.937850</td>\n",
       "      <td>11.691283</td>\n",
       "      <td>...</td>\n",
       "      <td>1.861487</td>\n",
       "      <td>6.130886</td>\n",
       "      <td>3.401064</td>\n",
       "      <td>15.850471</td>\n",
       "      <td>14.620599</td>\n",
       "      <td>6.849776</td>\n",
       "      <td>1.098210</td>\n",
       "      <td>1.959183</td>\n",
       "      <td>1.575493</td>\n",
       "      <td>1.857893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.020690</td>\n",
       "      <td>9.900544</td>\n",
       "      <td>17.869637</td>\n",
       "      <td>4.366715</td>\n",
       "      <td>1.973693</td>\n",
       "      <td>2.026012</td>\n",
       "      <td>2.853025</td>\n",
       "      <td>0.674847</td>\n",
       "      <td>11.816859</td>\n",
       "      <td>0.011151</td>\n",
       "      <td>...</td>\n",
       "      <td>1.340944</td>\n",
       "      <td>7.240058</td>\n",
       "      <td>2.417235</td>\n",
       "      <td>15.194609</td>\n",
       "      <td>13.553772</td>\n",
       "      <td>7.229971</td>\n",
       "      <td>0.835158</td>\n",
       "      <td>2.234482</td>\n",
       "      <td>0.946170</td>\n",
       "      <td>2.700606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.909506</td>\n",
       "      <td>10.576516</td>\n",
       "      <td>0.934191</td>\n",
       "      <td>3.419572</td>\n",
       "      <td>1.871438</td>\n",
       "      <td>3.340811</td>\n",
       "      <td>1.868282</td>\n",
       "      <td>0.439865</td>\n",
       "      <td>13.585620</td>\n",
       "      <td>1.153366</td>\n",
       "      <td>...</td>\n",
       "      <td>2.738095</td>\n",
       "      <td>6.565509</td>\n",
       "      <td>4.341414</td>\n",
       "      <td>15.893832</td>\n",
       "      <td>11.929787</td>\n",
       "      <td>6.954033</td>\n",
       "      <td>1.853364</td>\n",
       "      <td>0.511027</td>\n",
       "      <td>2.599562</td>\n",
       "      <td>0.811364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_1      var_2      var_3     var_4     var_5     var_6     var_7  \\\n",
       "0  4.532710   3.280834  17.982476  4.404259  2.349910  0.603264  2.784655   \n",
       "1  5.821374  12.098722  13.309151  4.125599  1.045386  1.832035  1.833494   \n",
       "2  1.938776   7.952752   0.972671  3.459267  1.935782  0.621463  2.338139   \n",
       "3  6.020690   9.900544  17.869637  4.366715  1.973693  2.026012  2.853025   \n",
       "4  3.909506  10.576516   0.934191  3.419572  1.871438  3.340811  1.868282   \n",
       "\n",
       "      var_8      var_9     var_10  ...   var_100   var_101   var_102  \\\n",
       "0  0.323146  12.009691   0.139346  ...  2.079066  6.748819  2.941445   \n",
       "1  0.709090   8.652883   0.102757  ...  2.479789  7.795290  3.557890   \n",
       "2  0.344948   9.937850  11.691283  ...  1.861487  6.130886  3.401064   \n",
       "3  0.674847  11.816859   0.011151  ...  1.340944  7.240058  2.417235   \n",
       "4  0.439865  13.585620   1.153366  ...  2.738095  6.565509  4.341414   \n",
       "\n",
       "     var_103    var_104   var_105   var_106   var_107   var_108   var_109  \n",
       "0  18.360496  17.726613  7.774031  1.473441  1.973832  0.976806  2.541417  \n",
       "1  17.383378  15.193423  8.263673  1.878108  0.567939  1.018818  1.416433  \n",
       "2  15.850471  14.620599  6.849776  1.098210  1.959183  1.575493  1.857893  \n",
       "3  15.194609  13.553772  7.229971  0.835158  2.234482  0.946170  2.700606  \n",
       "4  15.893832  11.929787  6.954033  1.853364  0.511027  2.599562  0.811364  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9h7-nfH0o5zf"
   },
   "source": [
    "**Quan trọng**\n",
    "\n",
    "Trong tất cả các quy trình lựa chọn đặc trưng, chỉ nên chọn các đặc trưng bằng cách kiểm tra tập huấn luyện, điều này giúp tránh overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fnS4BRFuo5zf",
    "outputId": "7576bb50-a857-484f-fb69-c54dded58b04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 108), (15000, 108))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tách thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),\n",
    "    data['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QO1VLZHVo5zh"
   },
   "outputs": [],
   "source": [
    "# với phương thức này, cần đặt lại chỉ số của\n",
    "# các tập dữ liệu được trả về\n",
    "## Yêu cầu 1:\n",
    "## VIẾT CODE Ở ĐÂY:\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4lZ6MIsq9GN"
   },
   "source": [
    "<details><summary> Gợi ý </summary>\n",
    "\n",
    "[reset_index()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdymw15So5zi"
   },
   "source": [
    "### Huấn luyện thuật toán học máy với toàn bộ các đặc trưng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "owVq7aPio5zj",
    "outputId": "5d501444-1c22-4395-8221-162a686b64b2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc score:  0.690997114685582\n",
      "test auc score:  0.6857035229040285\n"
     ]
    }
   ],
   "source": [
    "# Bước đầu tiên là xác định độ quan trọng của đặc trưng bằng cách xáo trộn đặc trưng\n",
    "# để xây dựng mô hình học máy mà chúng ta cần \n",
    "# để lựa chọn đặc trưng\n",
    "\n",
    "# Ở trường hợp này, chúng ta sẽ xây dựng Random Forest, nhưng hãy nhớ rằng \n",
    "# có thể dùng quy trình này với bất kỳ thuật tóan học máy nào khác\n",
    "\n",
    "## Yêu cầu 2:\n",
    "## VIẾT CODE Ở ĐÂY:\n",
    "# xây dựng ít cây và cây cần nông (shallow) để tránh overfitting\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=50, max_depth=2, random_state=2909, n_jobs=4)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# in ra roc-auc trên các tập huấn luyện và tập kiểm tra\n",
    "print('train auc score: ',\n",
    "      roc_auc_score(y_train, (rf.predict_proba(X_train.fillna(0)))[:, 1]))\n",
    "print('test auc score: ',\n",
    "      roc_auc_score(y_test, (rf.predict_proba(X_test.fillna(0)))[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQQLTVqcxE2F"
   },
   "source": [
    "<details><summary> Gợi ý </summary>\n",
    "\n",
    "[RandomForestClassifier()](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "\n",
    "[roc_auc_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5HPErRgo5zj"
   },
   "source": [
    "### Xáo trộn đặc trưng và đánh giá mức giảm chất lượng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Hfj_6L43o5zk"
   },
   "outputs": [],
   "source": [
    "# trong cell này, hãy xáo trộn lần lượt từng đặc trưng của tập dữ liệu\n",
    "\n",
    "# sau đó sử dụng tập dữ liệu có biến đã xáo trộn để đưa ra dự đoán \n",
    "# với các random forest đã huấn luyện ở cell trước\n",
    "\n",
    "# train roc-auc tổng quát: dùng toàn bộ đặc trưng\n",
    "train_roc = roc_auc_score(y_train, (rf.predict_proba(X_train))[:, 1])\n",
    "\n",
    "# danh sách chứa các thay đổi về chất lượng\n",
    "performance_shift = []\n",
    "\n",
    "# logic lựa chọn\n",
    "for feature in X_train.columns:\n",
    "\n",
    "    X_train_c = X_train.copy()\n",
    "\n",
    "    # xáo trộn đặc trưng riêng lẻ\n",
    "    X_train_c[feature] = X_train_c[feature].sample(\n",
    "        frac=1, random_state=10).reset_index(drop=True)\n",
    "\n",
    "    # dự đoán với đặc trưng đã xáo trộn và tính roc-auc\n",
    "    shuff_roc = roc_auc_score(y_train, rf.predict_proba(X_train_c)[:, 1])\n",
    "    \n",
    "    drift = train_roc - shuff_roc\n",
    "\n",
    "    # lưu mức giảm trong roc-auc\n",
    "    performance_shift.append(drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tJSyg1VBo5zk",
    "outputId": "d80e2778-bd05-4edb-ee4c-64032055cb82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " -9.919140466640997e-05,\n",
       " -5.777064524881137e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -3.334693591705573e-05,\n",
       " 8.796265542265758e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.2864223244933868e-05,\n",
       " -6.957465160806198e-05,\n",
       " 4.371055238927557e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.015497219959881292,\n",
       " -0.00012937667354617766,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0013551709383483601,\n",
       " 0.0,\n",
       " -7.38081844428029e-05,\n",
       " 0.0,\n",
       " 1.2296120844856873e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0015281413151823076,\n",
       " 2.6043867067171433e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.001336418904640313,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00015224539098712686,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.020099856532177e-06,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.17743806627535e-05,\n",
       " 0.0,\n",
       " 0.0017028464517550024,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.07156079421237771,\n",
       " 0.0,\n",
       " -0.00015256447891842662,\n",
       " 4.3209449511305564e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.00018709114134207727,\n",
       " -8.323251390618402e-05,\n",
       " 0.00010579113180830824,\n",
       " 1.5033086339877322e-05,\n",
       " 0.0,\n",
       " 3.216945650863501e-05,\n",
       " 0.008743101448133728,\n",
       " 0.0035736702283486466,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00010268788932177308,\n",
       " 8.200559833926313e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.2970250277133388e-05,\n",
       " 0.0,\n",
       " 0.0002834152488229158,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0003512281755146951,\n",
       " 0.0,\n",
       " -0.00023584867608106297,\n",
       " 0.0,\n",
       " 0.0006831133305189585,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0010592460943602555,\n",
       " 4.597338018363928e-05,\n",
       " -4.512173000126296e-06,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0003018279707167615,\n",
       " -5.0818123703777474e-05,\n",
       " 0.0003170565545920212,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.00023036126250230993,\n",
       " 0.0,\n",
       " 2.3549588167304236e-06,\n",
       " 3.656702750509666e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0066017899781302125,\n",
       " 0.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hãy xem danh sách các chất lượng\n",
    "performance_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "G2bmTonzo5zl",
    "outputId": "36c7b504-d32b-4ff7-f71e-e0fbac15dcce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_1    0.000000\n",
       "var_2   -0.000099\n",
       "var_3   -0.000058\n",
       "var_4    0.000000\n",
       "var_5    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hãy biến đổi list (danh sách) thành pandas Series\n",
    "# để dễ thao tác\n",
    "\n",
    "feature_importance = pd.Series(performance_shift)\n",
    "\n",
    "# thêm tên biến vào chỉ số\n",
    "feature_importance.index = X_train.columns\n",
    "\n",
    "feature_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_E_4YwdEo5zl",
    "outputId": "2381324c-c469-47e9-c507-8f6873a4fd9e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_55     0.071561\n",
       "var_16     0.015497\n",
       "var_69     0.008743\n",
       "var_108    0.006602\n",
       "var_70     0.003574\n",
       "             ...   \n",
       "var_63    -0.000187\n",
       "var_102   -0.000230\n",
       "var_86    -0.000236\n",
       "var_84    -0.000351\n",
       "var_30    -0.001528\n",
       "Length: 108, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Giờ hãy sắp xếp dataframe theo mức giảm chất lượng\n",
    "# do xáo trộn đặc trưng\n",
    "## Yêu cầu 3:\n",
    "## VIẾT CODE Ở ĐÂY:\n",
    "feature_importance.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoYcbNsOrTar"
   },
   "source": [
    "<details><summary> Gợi ý </summary>\n",
    "\n",
    "[sort_values()](https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WJnqGM28o5zm",
    "outputId": "5c95a15c-e7fd-4e3c-b1d6-9da11535605c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_30    -0.001528\n",
       "var_84    -0.000351\n",
       "var_86    -0.000236\n",
       "var_102   -0.000230\n",
       "var_63    -0.000187\n",
       "var_57    -0.000153\n",
       "var_17    -0.000129\n",
       "var_2     -0.000099\n",
       "var_64    -0.000083\n",
       "var_23    -0.000074\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hiển thị top 10 đặc trung gây ra các sự sụt giảm chính\n",
    "# trong roc-auc (hay chất lượng mô hình)\n",
    "## Yêu cầu 4:\n",
    "## VIẾT CODE Ở ĐÂY:\n",
    "feature_importance.sort_values(ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTXaiCU4rcf_"
   },
   "source": [
    "<details><summary> Gợi ý </summary>\n",
    "\n",
    "[sort_values()](https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7vW5e5pno5zm",
    "outputId": "a279c52a-8ac3-4905-8d3c-f210e1ea705c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# số lượng ban đầu của các đặc trưng (trong trường hợp này là hàng)\n",
    "feature_importance.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "q9-CQkD6o5zn",
    "outputId": "c2ae1287-091b-45d4-ba47-1ce7fdf937de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# số lượng đặc trưng khiến chất lượng sụt giảm\n",
    "# khi bị xáo trộn\n",
    "## Yêu cầu 5:\n",
    "## VIẾT CODE Ở ĐÂY:\n",
    "feature_importance[feature_importance>0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYIHXcNSo5zn"
   },
   "source": [
    "Trong tổng số 108 đặc trưng, có 30 đặc trưng khiến chất lượng của các random forest sụt giảm khi hoán vị các giá trị đặc trưng. Điều này tức là chúng ta có thể lựa chọn các đặc trưng đó, loại bỏ các đặc trưng còn lại, và nên giữ lại chất lượng ban đầu của random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "vbIMncezo5zn",
    "outputId": "74dab3ea-4829-458c-efed-79165dc0000c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var_7', 'var_11', 'var_13', 'var_16', 'var_21', 'var_25', 'var_31',\n",
       "       'var_34', 'var_38', 'var_43', 'var_46', 'var_48', 'var_55', 'var_58',\n",
       "       'var_65', 'var_66', 'var_68', 'var_69', 'var_70', 'var_73', 'var_74',\n",
       "       'var_79', 'var_88', 'var_91', 'var_92', 'var_96', 'var_98', 'var_104',\n",
       "       'var_105', 'var_108'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in ra các đặc trưng quan trọng\n",
    "## Yêu cầu 6:\n",
    "## VIẾT CODE Ở ĐÂY:\n",
    "feature_importance[feature_importance>0].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2G9xoBajo5zo"
   },
   "source": [
    "### Lựa chọn đặc trưng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MFg3NtbQo5zo",
    "outputId": "c3fdf75a-4ec7-4bc5-fb36-2a9d92cc9dd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc score:  0.6954703746877449\n",
      "test auc score:  0.6932896839648326\n"
     ]
    }
   ],
   "source": [
    "# Giờ hãy xây một random forest chỉ với các đặc trưng đã chọn\n",
    "\n",
    "# nắm bắt các đặc trưng đã chọn\n",
    "selected_features = feature_importance[feature_importance > 0].index\n",
    "\n",
    "# huấn luyện random forest mới chỉ dùng các đặc trưng đã chọn\n",
    "rf = RandomForestClassifier(n_estimators=50,\n",
    "                            max_depth=2,\n",
    "                            random_state=2909,\n",
    "                            n_jobs=4)\n",
    "\n",
    "rf.fit(X_train[selected_features], y_train)\n",
    "\n",
    "# in ra roc-auc trên các tập huấn luyện và tập kiểm tra\n",
    "print(\n",
    "    'train auc score: ',\n",
    "    roc_auc_score(y_train, (rf.predict_proba(X_train[selected_features]))[:,\n",
    "                                                                          1]))\n",
    "print(\n",
    "    'test auc score: ',\n",
    "    roc_auc_score(y_test, (rf.predict_proba(X_test[selected_features]))[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0al2cRAgo5zo"
   },
   "source": [
    "Như các bạn thấy, random forest với các đặc trưng đã chọn cho thấy chất lượng tương tự (hoặc thậm chí cao hơn một chút) như các random forest đã xây khi dùng toàn bộ đặc trưng. Nó khiến mô hình đơn giản hơn, nhanh hơn và đáng tin hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndKzRBS6pohK"
   },
   "source": [
    "## Phương pháp lai hóa: Loại bỏ đặc trưng đệ quy\n",
    "\n",
    "Phương pháp này gồm các bước sau:\n",
    "\n",
    "1) Xếp hạng các đặc trưng theo mức độ quan trọng lấy từ thuật toán học máy: có thể là độ quan trọng của cây hoặc các hệ số thu được từ mô hình tuyến tính.\n",
    "\n",
    "2) Loại bỏ đặc trưng ít quan trọng nhất và xây dựng thuật toán học máy với các đặc trưng còn lại.\n",
    "\n",
    "3) Tính toán số liệu chất lượng được chọn: roc-auc, mse, rmse, accuracy,...\n",
    "\n",
    "4) Nếu chỉ số giảm nhiều hơn một ngưỡng được thiết lập tùy ý thì đặc trưng đó quan trọng và cần được giữ lại. Nếu không, chúng ta có thể loại đặc trưng đó.\n",
    "\n",
    "5) Lặp lại các bước 2-4 cho đến khi đánh giá hết tất cả các đặc trưng.\n",
    "\n",
    "\n",
    "Phương pháp này được gọi là lai hóa do:\n",
    "\n",
    "- nó lấy độ quan trọng từ thuật toán học máy như các phương pháp nhúng \n",
    "- nó xây dựng một vài mô hình như các phương pháp gói.\n",
    "\n",
    "Phương pháp này nhanh hơn so với các phương pháp gói và thường tốt hơn các phương pháp nhúng. Thực tế, nó hoạt động rất tốt.\n",
    "\n",
    "Cần lưu ý là lượng giảm chất lượng tối thiểu quyết định liệu một đặc trưng có nên giữ lại hay không được thiết lập tùy ý. Lượng giảm càng nhỏ thì càng có nhiều đặc trưng được chọn và ngược lại.\n",
    "\n",
    "Chúng ta sẽ minh họa cách lựa chọn đặc trưng sử dụng phương thức lai hóa trong bài toán phân loại và hồi quy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lWQcii6RplZj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import roc_auc_score, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXhG52RAptv1"
   },
   "source": [
    "## Phân loại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ULj3VYxkplb-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 109)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load tập dữ liệu\n",
    "######## Bài lab khong thấy lin tải dataset_1.csv nên sẽ thay vào dataset_2.csv sẽ có một chút lỗi kiểu dữ liệu\n",
    "data = pd.read_csv('dataset_2.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rN-0jkd9ple5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>...</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_101</th>\n",
       "      <th>var_102</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_104</th>\n",
       "      <th>var_105</th>\n",
       "      <th>var_106</th>\n",
       "      <th>var_107</th>\n",
       "      <th>var_108</th>\n",
       "      <th>var_109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.532710</td>\n",
       "      <td>3.280834</td>\n",
       "      <td>17.982476</td>\n",
       "      <td>4.404259</td>\n",
       "      <td>2.349910</td>\n",
       "      <td>0.603264</td>\n",
       "      <td>2.784655</td>\n",
       "      <td>0.323146</td>\n",
       "      <td>12.009691</td>\n",
       "      <td>0.139346</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079066</td>\n",
       "      <td>6.748819</td>\n",
       "      <td>2.941445</td>\n",
       "      <td>18.360496</td>\n",
       "      <td>17.726613</td>\n",
       "      <td>7.774031</td>\n",
       "      <td>1.473441</td>\n",
       "      <td>1.973832</td>\n",
       "      <td>0.976806</td>\n",
       "      <td>2.541417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.821374</td>\n",
       "      <td>12.098722</td>\n",
       "      <td>13.309151</td>\n",
       "      <td>4.125599</td>\n",
       "      <td>1.045386</td>\n",
       "      <td>1.832035</td>\n",
       "      <td>1.833494</td>\n",
       "      <td>0.709090</td>\n",
       "      <td>8.652883</td>\n",
       "      <td>0.102757</td>\n",
       "      <td>...</td>\n",
       "      <td>2.479789</td>\n",
       "      <td>7.795290</td>\n",
       "      <td>3.557890</td>\n",
       "      <td>17.383378</td>\n",
       "      <td>15.193423</td>\n",
       "      <td>8.263673</td>\n",
       "      <td>1.878108</td>\n",
       "      <td>0.567939</td>\n",
       "      <td>1.018818</td>\n",
       "      <td>1.416433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.938776</td>\n",
       "      <td>7.952752</td>\n",
       "      <td>0.972671</td>\n",
       "      <td>3.459267</td>\n",
       "      <td>1.935782</td>\n",
       "      <td>0.621463</td>\n",
       "      <td>2.338139</td>\n",
       "      <td>0.344948</td>\n",
       "      <td>9.937850</td>\n",
       "      <td>11.691283</td>\n",
       "      <td>...</td>\n",
       "      <td>1.861487</td>\n",
       "      <td>6.130886</td>\n",
       "      <td>3.401064</td>\n",
       "      <td>15.850471</td>\n",
       "      <td>14.620599</td>\n",
       "      <td>6.849776</td>\n",
       "      <td>1.098210</td>\n",
       "      <td>1.959183</td>\n",
       "      <td>1.575493</td>\n",
       "      <td>1.857893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.020690</td>\n",
       "      <td>9.900544</td>\n",
       "      <td>17.869637</td>\n",
       "      <td>4.366715</td>\n",
       "      <td>1.973693</td>\n",
       "      <td>2.026012</td>\n",
       "      <td>2.853025</td>\n",
       "      <td>0.674847</td>\n",
       "      <td>11.816859</td>\n",
       "      <td>0.011151</td>\n",
       "      <td>...</td>\n",
       "      <td>1.340944</td>\n",
       "      <td>7.240058</td>\n",
       "      <td>2.417235</td>\n",
       "      <td>15.194609</td>\n",
       "      <td>13.553772</td>\n",
       "      <td>7.229971</td>\n",
       "      <td>0.835158</td>\n",
       "      <td>2.234482</td>\n",
       "      <td>0.946170</td>\n",
       "      <td>2.700606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.909506</td>\n",
       "      <td>10.576516</td>\n",
       "      <td>0.934191</td>\n",
       "      <td>3.419572</td>\n",
       "      <td>1.871438</td>\n",
       "      <td>3.340811</td>\n",
       "      <td>1.868282</td>\n",
       "      <td>0.439865</td>\n",
       "      <td>13.585620</td>\n",
       "      <td>1.153366</td>\n",
       "      <td>...</td>\n",
       "      <td>2.738095</td>\n",
       "      <td>6.565509</td>\n",
       "      <td>4.341414</td>\n",
       "      <td>15.893832</td>\n",
       "      <td>11.929787</td>\n",
       "      <td>6.954033</td>\n",
       "      <td>1.853364</td>\n",
       "      <td>0.511027</td>\n",
       "      <td>2.599562</td>\n",
       "      <td>0.811364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_1      var_2      var_3     var_4     var_5     var_6     var_7  \\\n",
       "0  4.532710   3.280834  17.982476  4.404259  2.349910  0.603264  2.784655   \n",
       "1  5.821374  12.098722  13.309151  4.125599  1.045386  1.832035  1.833494   \n",
       "2  1.938776   7.952752   0.972671  3.459267  1.935782  0.621463  2.338139   \n",
       "3  6.020690   9.900544  17.869637  4.366715  1.973693  2.026012  2.853025   \n",
       "4  3.909506  10.576516   0.934191  3.419572  1.871438  3.340811  1.868282   \n",
       "\n",
       "      var_8      var_9     var_10  ...   var_100   var_101   var_102  \\\n",
       "0  0.323146  12.009691   0.139346  ...  2.079066  6.748819  2.941445   \n",
       "1  0.709090   8.652883   0.102757  ...  2.479789  7.795290  3.557890   \n",
       "2  0.344948   9.937850  11.691283  ...  1.861487  6.130886  3.401064   \n",
       "3  0.674847  11.816859   0.011151  ...  1.340944  7.240058  2.417235   \n",
       "4  0.439865  13.585620   1.153366  ...  2.738095  6.565509  4.341414   \n",
       "\n",
       "     var_103    var_104   var_105   var_106   var_107   var_108   var_109  \n",
       "0  18.360496  17.726613  7.774031  1.473441  1.973832  0.976806  2.541417  \n",
       "1  17.383378  15.193423  8.263673  1.878108  0.567939  1.018818  1.416433  \n",
       "2  15.850471  14.620599  6.849776  1.098210  1.959183  1.575493  1.857893  \n",
       "3  15.194609  13.553772  7.229971  0.835158  2.234482  0.946170  2.700606  \n",
       "4  15.893832  11.929787  6.954033  1.853364  0.511027  2.599562  0.811364  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JtVB0U7pxGX"
   },
   "source": [
    "**Quan trọng**\n",
    "\n",
    "Trong tất cả các quy trình lựa chọn đặc trưng, chỉ nên chọn các đặc trưng bằng cách kiểm tra tập huấn luyện, điều này giúp tránh overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RBookX9kpyeM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 108), (15000, 108))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tách thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),\n",
    "    data['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZsRdepwp15-"
   },
   "source": [
    "### Loại các đặc trưng không đổi và gần như không đổi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zXwiBzH_pz_v"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n",
      "C:\\Users\\V\\AppData\\Local\\Temp\\ipykernel_2952\\3009294173.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((35000, 108), (15000, 108))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# để tăng tốc độ, hãy loại các đặc trưng không đổi, gần như không đổi và trùng lặp\n",
    "\n",
    "quasi_constant_feat = []\n",
    "\n",
    "# lặp qua từng đặc trưng\n",
    "for feature in X_train.columns:\n",
    "\n",
    "    # tìm các giá trị nổi bật, là các giá trị\n",
    "    # có ở hầu hết các quan sát\n",
    "    predominant = (X_train[feature].value_counts() / np.float(\n",
    "        len(X_train))).sort_values(ascending=False).values[0]\n",
    "\n",
    "    # đánh giá đặc trưng nổi bật: có phải hơn 99% các quan sát\n",
    "    # hiển thị 1 giá trị?\n",
    "    if predominant > 0.998:\n",
    "        \n",
    "        # nếu đúng, hãy thêm biến vào danh sách\n",
    "        quasi_constant_feat.append(feature)\n",
    "\n",
    "X_train.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "X_test.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKAm7ZFWp5z6"
   },
   "source": [
    "### Loại bỏ các đặc trưng trùng lặp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "o2VlI_jlp6XU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_feat = []\n",
    "for i in range(0, len(X_train.columns)):\n",
    "    if i % 10 == 0:  # điều này giúp chúng ta hiểu vòng lặp diễn ra như thế nào\n",
    "        print(i)\n",
    "\n",
    "    col_1 = X_train.columns[i]\n",
    "\n",
    "    for col_2 in X_train.columns[i + 1:]:\n",
    "        if X_train[col_1].equals(X_train[col_2]):\n",
    "            duplicated_feat.append(col_2)\n",
    "            \n",
    "len(duplicated_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-0TNkdOop6bH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 108), (15000, 108))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loại các đặc trưng trùng lặp\n",
    "## Yêu cầu 12:\n",
    "## VIẾT CODE Ở ĐÂY:\n",
    "X_train.drop(labels=duplicated_feat, axis=1, inplace=True)\n",
    "X_test.drop(labels=duplicated_feat, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8Mll_q7sm88"
   },
   "source": [
    "<details><summary> Gợi ý </summary>\n",
    "\n",
    "Sử dụng ```duplicated_feat```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuM08udmp-oJ"
   },
   "source": [
    "### Xây dựng mô hình học máy với toàn bộ các đặc trưng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "n1Ct6X3vp6dV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC=0.704907\n"
     ]
    }
   ],
   "source": [
    "# bước đầu tiên của quy trình này là xây dựng\n",
    "# thuật toán học máy sử dụng tất cả các đặc trưng hiện có\n",
    "# sau đó xác định độ quan trọng của các đặc trưng\n",
    "# theo thuật toán\n",
    "\n",
    "# xây dựng mô hình ban đầu sử dụng tất cả các đặc trưng\n",
    "model_full = GradientBoostingClassifier(n_estimators=10, max_depth=4, random_state=10)\n",
    "\n",
    "model_full.fit(X_train, y_train)\n",
    "\n",
    "# tính roc-auc trong tập kiểm tra\n",
    "y_pred_test = model_full.predict_proba(X_test)[:, 1]\n",
    "roc_full = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print('Test ROC AUC=%f' % (roc_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqIG-SFpqBPI"
   },
   "source": [
    "### Xếp hạng đặc trưng theo độ quan trọng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dSxk5GHtp6fx"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bước thứ hai là độ quan trọng của\n",
    "# từng đặc trưng và xếp theo thứ tự từ ít quan trọng nhất tới\n",
    "# quan trọng nhất\n",
    "\n",
    "# lấy được tên đặc trưng và độ quan trọng\n",
    "## Yêu cầu 13:\n",
    "## VIẾT CODE Ở ĐÂY:\n",
    "features = pd.Series(model_full.feature_importances_)\n",
    "features.index = X_train.columns\n",
    "\n",
    "# sắp xếp các đặc trưng theo độ quan trọng\n",
    "features.sort_values(ascending=True, inplace=True)\n",
    "\n",
    "# vẽ biểu đồ\n",
    "features.plot.bar(figsize=(20,6))\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "if9m1C2ws1h7"
   },
   "source": [
    "<details><summary> Gợi ý </summary>\n",
    "\n",
    "Sử dụng ```feature_importances_```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Rg19Fb3Up6jE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var_1',\n",
       " 'var_74',\n",
       " 'var_73',\n",
       " 'var_72',\n",
       " 'var_71',\n",
       " 'var_68',\n",
       " 'var_65',\n",
       " 'var_64',\n",
       " 'var_63',\n",
       " 'var_76',\n",
       " 'var_62',\n",
       " 'var_59',\n",
       " 'var_58',\n",
       " 'var_57',\n",
       " 'var_56',\n",
       " 'var_52',\n",
       " 'var_51',\n",
       " 'var_50',\n",
       " 'var_49',\n",
       " 'var_60',\n",
       " 'var_77',\n",
       " 'var_78',\n",
       " 'var_79',\n",
       " 'var_107',\n",
       " 'var_106',\n",
       " 'var_105',\n",
       " 'var_103',\n",
       " 'var_102',\n",
       " 'var_101',\n",
       " 'var_100',\n",
       " 'var_98',\n",
       " 'var_97',\n",
       " 'var_95',\n",
       " 'var_93',\n",
       " 'var_92',\n",
       " 'var_90',\n",
       " 'var_89',\n",
       " 'var_87',\n",
       " 'var_83',\n",
       " 'var_82',\n",
       " 'var_81',\n",
       " 'var_80',\n",
       " 'var_46',\n",
       " 'var_45',\n",
       " 'var_54',\n",
       " 'var_43',\n",
       " 'var_26',\n",
       " 'var_25',\n",
       " 'var_24',\n",
       " 'var_23',\n",
       " 'var_44',\n",
       " 'var_20',\n",
       " 'var_19',\n",
       " 'var_13',\n",
       " 'var_11',\n",
       " 'var_10',\n",
       " 'var_8',\n",
       " 'var_7',\n",
       " 'var_6',\n",
       " 'var_5',\n",
       " 'var_4',\n",
       " 'var_3',\n",
       " 'var_2',\n",
       " 'var_27',\n",
       " 'var_29',\n",
       " 'var_109',\n",
       " 'var_33',\n",
       " 'var_37',\n",
       " 'var_35',\n",
       " 'var_39',\n",
       " 'var_40',\n",
       " 'var_38',\n",
       " 'var_41',\n",
       " 'var_42',\n",
       " 'var_31',\n",
       " 'var_47',\n",
       " 'var_18',\n",
       " 'var_12',\n",
       " 'var_66',\n",
       " 'var_86',\n",
       " 'var_85',\n",
       " 'var_17',\n",
       " 'var_28',\n",
       " 'var_15',\n",
       " 'var_99',\n",
       " 'var_53',\n",
       " 'var_22',\n",
       " 'var_14',\n",
       " 'var_104',\n",
       " 'var_9',\n",
       " 'var_67',\n",
       " 'var_108',\n",
       " 'var_84',\n",
       " 'var_32',\n",
       " 'var_96',\n",
       " 'var_75',\n",
       " 'var_34',\n",
       " 'var_30',\n",
       " 'var_36',\n",
       " 'var_94',\n",
       " 'var_48',\n",
       " 'var_70',\n",
       " 'var_21',\n",
       " 'var_91',\n",
       " 'var_69',\n",
       " 'var_88',\n",
       " 'var_16',\n",
       " 'var_55']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tạo danh sách các đặc trưng đã sắp xếp\n",
    "features = list(features.index)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GQUvm5wqFpi"
   },
   "source": [
    "### Lựa chọn đặc trưng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "d91z2I6lqF_q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing recursive feature elimination\n",
      "\n",
      "testing feature:  var_1 1  out of  108\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['var_1'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 46\u001b[0m\n\u001b[0;32m     38\u001b[0m model_int \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# khớp mô hình với tất cả các biến, trừ đặc trưng được đánh giá\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# cũng như tất cả các các đối tượng được coi là bị loại\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# features_to_remove sẽ rỗng ở các lượt đầu tiên\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# nhưng sẽ có các đặc trưng khi tiến hành vòng lặp\u001b[39;00m\n\u001b[0;32m     45\u001b[0m model_int\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m---> 46\u001b[0m     \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_to_remove\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, y_train)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# đưa ra dự đoán, sử dụng tập kiểm tra\u001b[39;00m\n\u001b[0;32m     49\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m model_int\u001b[38;5;241m.\u001b[39mpredict_proba(\n\u001b[0;32m     50\u001b[0m     X_test\u001b[38;5;241m.\u001b[39mdrop(features_to_remove \u001b[38;5;241m+\u001b[39m [feature], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\users\\v\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\v\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py:4957\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4809\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4811\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4818\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4819\u001b[0m ):\n\u001b[0;32m   4820\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4821\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4822\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4955\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4956\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4963\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4964\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4965\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\v\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\users\\v\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\users\\v\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6661\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6661\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6662\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['var_1'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# bước cuối cùng là loại lần lượt\n",
    "# tất cả các đặc trưng, từ ít quan trọng nhất tới quan trọng nhất\n",
    "# và xây dựng mô hình ở từng lượt.\n",
    "\n",
    "# sau khi đã xây dựng mô hình, tính roc-auc mới\n",
    "\n",
    "# nếu roc-auc mới nhỏ hơn roc-auc ban đầu\n",
    "# (với tất cả đặc trưng) thì đặc trưng bị loại\n",
    "# quan trọng, chúng ta cần giữ nó lại.\n",
    "# nếu không, hãy loại bỏ nó\n",
    "\n",
    "# loại đặc trưng đệ quy:\n",
    "\n",
    "# trước tiên, chúng ta tùy ý thiết lập mức giảm trong roc-auc\n",
    "# nếu mức giảm nằm dưới ngưỡng này,\n",
    "# đặc trưng sẽ bị loại\n",
    "tol = 0.0005\n",
    "\n",
    "print('doing recursive feature elimination')\n",
    "\n",
    "# hãy khởi tạo một danh sách thu thập\n",
    "# các đặc trưng nên loại\n",
    "features_to_remove = []\n",
    "\n",
    "# cài đặt bộ đếm để biết vòng lặp ở đâu\n",
    "count = 1\n",
    "\n",
    "# giờ chúng ta lặp qua toàn bộ các đặc trưng, theo độ quan trọng:\n",
    "# nhớ rằng các đặc trưng trong danh sách này được sắp xếp theo\n",
    "# độ quan trọng\n",
    "for feature in features:\n",
    "    \n",
    "    print()\n",
    "    print('testing feature: ', feature, count, ' out of ', len(features))\n",
    "    count = count + 1\n",
    "\n",
    "    # khởi tạo mô hình\n",
    "    model_int = GradientBoostingClassifier(n_estimators=10, max_depth=4, random_state=10)\n",
    "\n",
    "    # khớp mô hình với tất cả các biến, trừ đặc trưng được đánh giá\n",
    "    # cũng như tất cả các các đối tượng được coi là bị loại\n",
    "    \n",
    "    # features_to_remove sẽ rỗng ở các lượt đầu tiên\n",
    "    # nhưng sẽ có các đặc trưng khi tiến hành vòng lặp\n",
    "    model_int.fit(\n",
    "        X_train.drop(features_to_remove + [feature], axis=1), y_train)\n",
    "\n",
    "    # đưa ra dự đoán, sử dụng tập kiểm tra\n",
    "    y_pred_test = model_int.predict_proba(\n",
    "        X_test.drop(features_to_remove + [feature], axis=1))[:, 1]\n",
    "\n",
    "    # tính toán roc-auc mới\n",
    "    roc_int = roc_auc_score(y_test, y_pred_test)\n",
    "    print('New Test ROC AUC={}'.format((roc_int)))\n",
    "\n",
    "    # in ra roc-auc ban đầu với tất cả các đặc trưng\n",
    "    print('Full dataset ROC AUC={}'.format((roc_full)))\n",
    "\n",
    "    # xác định lượng giảm trong roc-auc\n",
    "    diff_roc = roc_full - roc_int\n",
    "\n",
    "    # so sánh lượng giảm trong roc-auc với dung sai\n",
    "    # chúng ta đã thiết lập trước đó\n",
    "    if diff_roc >= tol:\n",
    "        print('Drop in ROC AUC={}'.format(diff_roc))\n",
    "        print('keep: ', feature)\n",
    "        print\n",
    "    else:\n",
    "        print('Drop in ROC AUC={}'.format(diff_roc))\n",
    "        print('remove: ', feature)\n",
    "        print\n",
    "        # nếu lượng giảm trong roc-auc nhỏ và chúng ta loại đặc trưng,\n",
    "        # cần đặt roc-auc mới dựa trên \n",
    "        # các đặc trưng còn lại\n",
    "        roc_full = roc_int\n",
    "        \n",
    "        # và thêm các đặc trưng cần loại vào danh sách thu thập\n",
    "        ## Yêu cầu 14:\n",
    "        ## VIẾT CODE Ở ĐÂY:\n",
    "        features_to_remove.append(roc_full)\n",
    "\n",
    "# vòng lặp giờ đã hoàn thành, hãy đánh giá toàn bộ đặc trưng\n",
    "print('DONE!!')\n",
    "## Yêu cầu 15:\n",
    "## VIẾT CODE Ở ĐÂY:\n",
    "print('total features to remove: ', len(features_to_remove))\n",
    "\n",
    "# xác định các đặc trưng cần giữ (các đặc trưng mà chúng ta sẽ không loại)\n",
    "features_to_keep = [x for x in features if x not in features_to_remove]\n",
    "print('total features to keep: ', len(features_to_keep))\n",
    "\n",
    "# Hãy chờ một lúc, điều này tốn chút thời gian!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRuJy4paqGBo"
   },
   "outputs": [],
   "source": [
    "#  để so sánh, chúng ta sẽ xây dựng một mô hình chỉ với các đặc trưng đã chọn\n",
    "\n",
    "model_final = GradientBoostingClassifier(n_estimators=10, max_depth=4, random_state=10)\n",
    "\n",
    "# khớp mô hình với các đặc trưng đã chọn\n",
    "model_final.fit(X_train[features_to_keep], y_train)\n",
    "\n",
    "# đưa ra dự đoán\n",
    "## Yêu cầu 16:\n",
    "## VIẾT CODE Ở ĐÂY:\n",
    "y_pred_test = model_final.predict_proba(X_test[features_to_keep])[:, 1]\n",
    "\n",
    "# tính roc-auc\n",
    "roc_final = roc_auc_score(y_test, y_pred_test)\n",
    "print('Test selected features ROC AUC=%f' % (roc_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkoKtHI3toUx"
   },
   "source": [
    "<details><summary> Gợi ý </summary>\n",
    "\n",
    "Sử dụng ```predict_proba()```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtUoS2CYqMWu"
   },
   "source": [
    "Như các bạn thấy, mô hình Gradient Boosting với 12 đặc trưng cho thấy chất lượng tương tự với mô hình được xây với tập dữ liệu đầy đủ (cuộn lên trên để tìm giá trị này, chúng ta đã tính một vài cell trước đó).\n",
    "\n",
    "**Bài tập:**\n",
    "Hãy thử các giá trị dung sai khác. Thử với các ngưỡng nhỏ hơn hoặc lớn hơn để hiểu được tác động của điều này tới số lượng các đặc trưng được chọn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YETn1nk7qn5v"
   },
   "source": [
    "## Phương pháp lai hóa: Loại bỏ đặc trưng đệ quy\n",
    "\n",
    "Phương pháp này gồm các bước sau:\n",
    "\n",
    "1) Xếp hạng các đặc trưng theo mức độ quan trọng lấy từ thuật toán học máy: có thể là độ quan trọng của cây hoặc các hệ số thu được từ mô hình tuyến tính.\n",
    "\n",
    "2) Loại bỏ đặc trưng ít quan trọng nhất và xây dựng thuật toán học máy với các đặc trưng còn lại.\n",
    "\n",
    "3) Tính toán số liệu chất lượng được chọn: roc-auc, mse, rmse, accuracy,...\n",
    "\n",
    "4) Nếu chỉ số giảm nhiều hơn một ngưỡng được thiết lập tùy ý thì đặc trưng đó quan trọng và cần được giữ lại. Nếu không, chúng ta có thể loại đặc trưng đó.\n",
    "\n",
    "5) Lặp lại các bước 2-4 cho đến khi đánh giá hết tất cả các đặc trưng.\n",
    "\n",
    "\n",
    "Phương pháp này được gọi là lai hóa do:\n",
    "\n",
    "- nó lấy độ quan trọng từ thuật toán học máy như các phương pháp nhúng \n",
    "- nó xây dựng một vài mô hình như các phương pháp gói.\n",
    "\n",
    "Phương pháp này nhanh hơn so với các phương pháp gói và thường tốt hơn các phương pháp nhúng. Thực tế, nó hoạt động rất tốt.\n",
    "\n",
    "Cần lưu ý là lượng giảm chất lượng tối thiểu quyết định liệu một đặc trưng có nên giữ lại hay không được thiết lập tùy ý. Lượng giảm càng nhỏ thì càng có nhiều đặc trưng được chọn và ngược lại.\n",
    "\n",
    "Chúng ta sẽ minh họa cách lựa chọn đặc trưng sử dụng phương thức lai hóa trong bài toán phân loại và hồi quy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhcIi8FgqpmM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import roc_auc_score, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIOLgMRNqq3m"
   },
   "source": [
    "## Phân loại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lnio2hDiqVDb"
   },
   "outputs": [],
   "source": [
    "# load tập dữ liệu\n",
    "######## Bài lab khong thấy lin tải dataset_1.csv nên sẽ thay vào dataset_2.csv sẽ có một chút lỗi kiểu dữ liệu\n",
    "data = pd.read_csv('dataset_1.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9z02LSOqsUK"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Yc0kVLnqt42"
   },
   "source": [
    "**Quan trọng**\n",
    "\n",
    "Trong tất cả các quy trình lựa chọn đặc trưng, chỉ nên chọn các đặc trưng bằng cách kiểm tra tập huấn luyện, điều này giúp tránh overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W2vJNH-wqsWN"
   },
   "outputs": [],
   "source": [
    "# tách thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),\n",
    "    data['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSgv57pVq1e8"
   },
   "source": [
    "### Loại các đặc trưng không đổi và gần như không đổi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VeGzp19SqsYW"
   },
   "outputs": [],
   "source": [
    "# để tăng tốc độ, hãy loại các đặc trưng không đổi, gần như không đổi và trùng lặp\n",
    "\n",
    "quasi_constant_feat = []\n",
    "\n",
    "# lặp qua từng đặc trưng\n",
    "for feature in X_train.columns:\n",
    "\n",
    "    # tìm các giá trị nổi bật, là các giá trị\n",
    "    # có ở hầu hết các quan sát\n",
    "    predominant = (X_train[feature].value_counts() / np.float(\n",
    "        len(X_train))).sort_values(ascending=False).values[0]\n",
    "\n",
    "    # đánh giá đặc trưng nổi bật: có phải hơn 99% các quan sát\n",
    "    # hiển thị 1 giá trị?\n",
    "    if predominant > 0.998:\n",
    "        \n",
    "        # nếu đúng, hãy thêm biến vào danh sách\n",
    "        quasi_constant_feat.append(feature)\n",
    "\n",
    "## Yêu cầu 20:\n",
    "## VIẾT CODE Ở ĐÂY:\n",
    "X_train.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "X_test.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx6FmLrevC3n"
   },
   "source": [
    "<details><summary> Gợi ý </summary>\n",
    "\n",
    "Sử dụng ```quasi_constant_feat```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "or1yP4i1q49S"
   },
   "source": [
    "### Loại các đặc trưng trùng lặp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GC3nT1pq3iI"
   },
   "outputs": [],
   "source": [
    "duplicated_feat = []\n",
    "for i in range(0, len(X_train.columns)):\n",
    "    if i % 10 == 0:  # điều này giúp chúng ta hiểu vòng lặp diễn ra như thế nào\n",
    "        print(i)\n",
    "\n",
    "    col_1 = X_train.columns[i]\n",
    "\n",
    "    for col_2 in X_train.columns[i + 1:]:\n",
    "        ## Yêu cầu 21:\n",
    "        ## VIẾT CODE Ở ĐÂY:\n",
    "        if X_train[col_1].equals(X_train[col_2]):\n",
    "            duplicated_feat.append(col_1)\n",
    "            \n",
    "len(duplicated_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Wt5AXVpwq3ks"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 108), (15000, 108))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loại các đặc trưng trùng lặp\n",
    "## Yêu cầu 22:\n",
    "## VIẾT CODE Ở ĐÂY:\n",
    "X_train.drop(labels=duplicated_feat, axis=1, inplace=True)\n",
    "X_test.drop(labels=duplicated_feat, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRtNiZs8vdDe"
   },
   "source": [
    "<details><summary> Gợi ý </summary>\n",
    "\n",
    "Sử dụng ```duplicated_feat```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtXU5lX8q8_7"
   },
   "source": [
    "### Huấn luyện mô hình học máy với toàn bộ các đặc trưng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEKONd21q3nB"
   },
   "outputs": [],
   "source": [
    "# bước đầu tiên của quy trình này là xây dựng\n",
    "# thuật toán học máy sử dụng tất cả các đặc trưng hiện có\n",
    "# sau đó xác định độ quan trọng của các đặc trưng\n",
    "# theo thuật toán\n",
    "\n",
    "# xây dựng mô hình ban đầu sử dụng tất cả các đặc trưng\n",
    "model_full = GradientBoostingClassifier(n_estimators=10, max_depth=4, random_state=10)\n",
    "\n",
    "model_full.fit(X_train, y_train)\n",
    "\n",
    "# tính roc-auc trong tập kiểm tra\n",
    "y_pred_test = model_full.predict_proba(X_test)[:, 1]\n",
    "roc_full = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print('Test ROC AUC=%f' % (roc_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLDPTYofrEGM"
   },
   "source": [
    "### Xếp hạng đặc trưng theo độ quan trọng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFYpHgixqsa5"
   },
   "outputs": [],
   "source": [
    "# bước thứ hai là độ quan trọng của\n",
    "# từng đặc trưng theo thứ tự từ ít quan trọng nhất tới\n",
    "# quan trọng nhất\n",
    "\n",
    "# lấy được tên đặc trưng và độ quan trọng\n",
    "features = pd.Series(model_full.feature_importances_)\n",
    "features.index = X_train.columns\n",
    "\n",
    "# sắp xếp các đặc trưng theo độ quan trọng\n",
    "features.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "# vẽ biểu đồ\n",
    "features.plot.bar(figsize=(20,6))\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h_lRd5ASrHLN"
   },
   "outputs": [],
   "source": [
    "# tạo danh sách các đặc trưng đã sắp xếp\n",
    "features = list(features.index)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "culGaVC7rJpw"
   },
   "source": [
    "### Xây dựng mô hình học máy với 1 đặc trưng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qNu_jAoorKQl"
   },
   "outputs": [],
   "source": [
    "# tiếp theo, chúng ta cần xây dựng mô hình học máy \n",
    "# chỉ sử dụng đặc trưng quan trọng nhất\n",
    "\n",
    "# xây dựng mô hình ban đầu với tất cả các đặc trưng\n",
    "model_one_feature = GradientBoostingClassifier(n_estimators=10, max_depth=4, random_state=10)\n",
    "\n",
    "# chỉ huấn luyện với đặc trưng quan trọng nhất\n",
    "model_one_feature.fit(X_train[features[0]].to_frame(), y_train)\n",
    "\n",
    "# tính roc-auc trong tập kiểm tra\n",
    "y_pred_test = model_one_feature.predict_proba(X_test[features[0]].to_frame())[:, 1]\n",
    "\n",
    "roc_first = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print('Test one feature xgb ROC AUC=%f' % (roc_first))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_CYB_wjrNc-"
   },
   "source": [
    "### Lựa chọn đặc trưng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-cS7wwVwrL9p"
   },
   "outputs": [],
   "source": [
    "# bước cuối cùng là lần lượt thêm một đặc trưng\n",
    "# từ quan trọng nhất tới ít quan trọng nhất, xây dựng mô hình\n",
    "# và xác định chất lượng\n",
    "\n",
    "# sau khi đã xây dựng mô hình, tính roc-auc mới\n",
    "# nếu roc-auc mới lớn hơn roc-auc ban đầu\n",
    "# (với 1 đặc trưng) thì đặc trưng được thêm \n",
    "# quan trọng, chúng ta cần giữ nó lại.\n",
    "# nếu không, hãy loại bỏ nó\n",
    "\n",
    "# loại bỏ đặc trưng đệ quy:\n",
    "\n",
    "# trước tiên chúng ta đặt tùy ý mức tăng trong roc-auc\n",
    "# nếu mức tăng vượt ngưỡng này,\n",
    "# thì giữ đặc trưng lại\n",
    "tol = 0.0001\n",
    "\n",
    "print('doing recursive feature addition')\n",
    "\n",
    "# hãy khởi tạo một danh sách thu thập\n",
    "# các đặc trưng nên giữ lại\n",
    "features_to_keep = [features[0]]\n",
    "\n",
    "# đặt bộ đếm để biết đặc trưng nào đang được đánh giá\n",
    "count = 1\n",
    "\n",
    "# giờ chúng ta lặp qua toàn bộ các đặc trưng, theo độ quan trọng:\n",
    "# nhớ rằng các đặc trưng trong danh sách được sắp xếp\n",
    "# theo độ quan trọng\n",
    "for feature in features[1:]:\n",
    "    print()\n",
    "    print('testing feature: ', feature, count, ' out of ', len(features))\n",
    "    count = count + 1\n",
    "\n",
    "    # khởi tạo mô hình\n",
    "    model_int = GradientBoostingClassifier(n_estimators=10, max_depth=4, random_state=10)\n",
    "\n",
    "    # khớp mô hình với các đặc trưng đã chọn\n",
    "    # và đặc trưng cần đánh giá\n",
    "    model_int.fit(\n",
    "        X_train[features_to_keep + [feature] ], y_train)\n",
    "\n",
    "    # đưa ra dự đoán trên tập kiểm tra\n",
    "    ## Yêu cầu 23:\n",
    "    ## VIẾT CODE Ở ĐÂY:\n",
    "    y_pred_test = model_int.predict_proba(\n",
    "        X_test[features_to_keep + [feature] ])[:, 1]\n",
    "\n",
    "    # tính toán roc-auc mới\n",
    "    roc_int = roc_auc_score(y_test, y_pred_test)\n",
    "    print('New Test ROC AUC={}'.format((roc_int)))\n",
    "\n",
    "    # in ra roc-auc ban đầu với một đặc trưng\n",
    "    print('Previous round Test ROC AUC={}'.format((roc_first)))\n",
    "\n",
    "    # xác định mức tăng trong roc-auc\n",
    "    diff_roc = roc_int - roc_first\n",
    "\n",
    "    # so sánh mức tăng trong roc-auc với dung sai\n",
    "    # chúng ta đã thiết lập trước đó\n",
    "    if diff_roc >= tol:\n",
    "        print('Increase in ROC AUC={}'.format(diff_roc))\n",
    "        print('keep: ', feature)\n",
    "        print\n",
    "        # nếu mức tăng trong roc lớn hơn ngưỡng\n",
    "        # chúng ta giữ lại đặc trưng và điều chỉnh lại roc-auc cho giá trị mới\n",
    "        # xem xét đặc trưng đã thêm\n",
    "        roc_first = roc_int\n",
    "        \n",
    "        # và thêm đặc trưng cần giữ lại vào danh sách\n",
    "        features_to_keep.append(feature)\n",
    "    else:\n",
    "        # bỏ qua đặc trưng\n",
    "        print('Increase in ROC AUC={}'.format(diff_roc))\n",
    "        print('remove: ', feature)\n",
    "        print\n",
    "\n",
    "# vòng lặp giờ đã hoàn thành, hãy đánh giá toàn bộ đặc trưng\n",
    "print('DONE!!')\n",
    "print('total features to keep: ', len(features_to_keep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Sjd5XOrwSNh"
   },
   "source": [
    "<details><summary> Gợi ý </summary>\n",
    "\n",
    "Sử dụng ```features_to_keep```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZh2tuoxrL_5"
   },
   "outputs": [],
   "source": [
    "# cuối cùng, hãy kiểm tra chất lượng của mô hình đã xây sử dụng đặc trưng đã chọn\n",
    "# so với mô hình đầy đủ\n",
    "\n",
    "# xây dựng mô hình đầu tiên\n",
    "model_final = GradientBoostingClassifier(n_estimators=10, max_depth=4, random_state=10)\n",
    "\n",
    "# khớp mô hình với các đặc trưng đã chọn\n",
    "model_final.fit(X_train[features_to_keep], y_train)\n",
    "\n",
    "# đưa ra dự đoán\n",
    "y_pred_test = model_final.predict_proba(X_test[features_to_keep])[:, 1]\n",
    "\n",
    "# tính roc-auc\n",
    "roc_final = roc_auc_score(y_test, y_pred_test)\n",
    "print('Test selected features ROC AUC=%f' % (roc_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQZOwYDerTxY"
   },
   "source": [
    "Như các bạn thấy, mô hình Gradient Boosting với 15 đặc trưng cho thấy chất lượng tương tự với mô hình được xây với tập dữ liệu đầy đủ (cuộn lên trên để tìm giá trị này, chúng ta đã tính một vài cell trước đó).\n",
    "\n",
    "**Bài tập:** Hãy thử các giá trị dung sai khác. Thử với các ngưỡng nhỏ hơn hoặc lớn hơn để hiểu được tác động của điều này tới số lượng các đặc trưng được chọn."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[VN]11_1_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3e81f8",
   "metadata": {},
   "source": [
    "# Mô hình nhận diện từ vựng qua giọng nói bằng phương pháp phân loại và xác suất"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d15eef",
   "metadata": {},
   "source": [
    "- Mô hình phân loại là một hình rất phổ biến hiện nay, nhưng trong speech to text thì được rất ít dùng đến bởi vì phương pháp này có nhiều mặt hạn chế trong các câu và ngữ pháp, Nhưng phân biệt tự vựng nó mang lại được độ chính xác dễ triển khai mà không cần quá nhiều tài nguyên hơn seq2seq. Trong bài này chúng ta sẽ phân tích xây dựng một mô hình phân loại cơ bản thử nghiêm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e5839",
   "metadata": {},
   "source": [
    "- Ưu điểm mô hình này là có thể giới hạn được số từ vựng trainning, và có thể trích xuất nhiều kết quả dự đoán theo dãy xác suất để người dùng nhận biết được nhầm lẫn trong các từ vựng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36d5d647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29940, 20, 98)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "#lấy các thư mục dưới dạng tên của từ vựng\n",
    "folder_path = 'data'\n",
    "ds = os.listdir(folder_path)\n",
    "#thu thập dự liệu âm thanh của từng labels\n",
    "labels = []\n",
    "data = []\n",
    "for step in ds:\n",
    "    files = os.listdir(f'data/{step}')\n",
    "    for i in files:\n",
    "        audio_data, sr = librosa.load(f'data/{step}/{i}', sr=None) \n",
    "        #lầm đều kích thước tranning ~2,5s\n",
    "        audio_data = np.pad(audio_data, (0, 50000 - len(audio_data)), 'constant')\n",
    "        #Trích xuất đặc trưng mfccs\n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sr)\n",
    "        data.append(mfccs)\n",
    "        labels.append(step)  \n",
    "        \n",
    "data_s = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(data_s.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c43b1",
   "metadata": {},
   "source": [
    "*Mã hóa labels sang dạng one-hot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebcc310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(labels)\n",
    "labelss = tokenizer.texts_to_sequences(labels)\n",
    "#mã hóa one-hot\n",
    "one_hot_labels = to_categorical(labelss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed13c8c9",
   "metadata": {},
   "source": [
    "*Chia tập dữ liệu huấn luận*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccc5e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_s, one_hot_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1660f9",
   "metadata": {},
   "source": [
    "**Huấn luyện với model NLP cơ bản**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b5e7d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 162ms/step - accuracy: 0.0188 - loss: 6.1979 - val_accuracy: 0.1979 - val_loss: 3.1786\n",
      "Epoch 2/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 152ms/step - accuracy: 0.2707 - loss: 2.7950 - val_accuracy: 0.4943 - val_loss: 1.6682\n",
      "Epoch 3/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 150ms/step - accuracy: 0.5276 - loss: 1.5804 - val_accuracy: 0.6712 - val_loss: 1.0441\n",
      "Epoch 4/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 154ms/step - accuracy: 0.6663 - loss: 1.0720 - val_accuracy: 0.7710 - val_loss: 0.7077\n",
      "Epoch 5/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 152ms/step - accuracy: 0.7498 - loss: 0.7821 - val_accuracy: 0.8181 - val_loss: 0.5525\n",
      "Epoch 6/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 152ms/step - accuracy: 0.7956 - loss: 0.6311 - val_accuracy: 0.8570 - val_loss: 0.4653\n",
      "Epoch 7/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 152ms/step - accuracy: 0.8334 - loss: 0.5067 - val_accuracy: 0.8699 - val_loss: 0.4057\n",
      "Epoch 8/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 156ms/step - accuracy: 0.8479 - loss: 0.4619 - val_accuracy: 0.8791 - val_loss: 0.3556\n",
      "Epoch 9/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 159ms/step - accuracy: 0.8649 - loss: 0.4046 - val_accuracy: 0.8946 - val_loss: 0.3132\n",
      "Epoch 10/30\n",
      "\u001b[1m749/749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 157ms/step - accuracy: 0.8774 - loss: 0.3724 - val_accuracy: 0.9041 - val_loss: 0.2834\n",
      "Epoch 11/30\n",
      "\u001b[1m161/749\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 138ms/step - accuracy: 0.8900 - loss: 0.3512"


{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRSBur8HMw02"
   },
   "source": [
    "## Thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MjaAEidBMw05"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBmiSN8sMw1A"
   },
   "source": [
    "## Load tập dữ liệu doanh số bán nhà\n",
    "\n",
    "Tập dữ liệu từ doanh số bán nhà quận King, Seatle, WA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7cDLiqAIMw1D",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_data = pandas.read_csv(\"kc_house_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyLeYGvlMw1J"
   },
   "source": [
    "## Tạo các đặc trung mới"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSMOdbHVMw1L"
   },
   "source": [
    "Như ở lab 2 (*Lab-2.ipynb*), chúng ta sẽ xem xét các đặc trưng có các biến đổi đầu vào."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mYzffDTvMw1M"
   },
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "full_data['sqft_living_sqrt'] = full_data['sqft_living'].map(sqrt)\n",
    "full_data['sqft_lot_sqrt'] = full_data['sqft_lot'].map(sqrt)\n",
    "full_data['bedrooms_square'] = full_data['bedrooms'] ** 2\n",
    "\n",
    "# Trong tập dữ liệu, 'floors' được xác định là type string, \n",
    "# nên chúng ta sẽ chuyển chúng thành float trước khi tạo đặc trưng mới. \n",
    "full_data['floors'] = full_data['floors'].astype(float) \n",
    "full_data['floors_square'] = full_data['floors'] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z672nh0kMw1S"
   },
   "source": [
    "* Bình phương bedrooms sẽ tăng phân tách giữa ít phòng ngủ (chẳng hạn 1) và nhiều phòng ngủ (chẳng hạn 4) vì 1^2 = 1 còn 4^2 = 16. Do đó, biến này sẽ ảnh hưởng lớn tới các ngôi nhà có nhiều phòng ngủ.\n",
    "* Mặt khác, căn bậc hai của sqft_living sẽ giảm phân tách giữa nhà lớn và nhà nhỏ. Chủ ngôi nhà cũng sẽ không vui hơn nếu nhà rộng gấp đôi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDo2w5chMw1U"
   },
   "source": [
    "# Tìm hiểu trọng số hồi quy với L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-xMl9bUMw1V"
   },
   "source": [
    "Hãy khớp mô hình với tất cả đặc trưng hiện có cộng với các đặc trưng vừa tạo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OYAUT1PLMw1W"
   },
   "outputs": [],
   "source": [
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7-592ikMw1e"
   },
   "source": [
    "Áp dụng L1 penalty cần thêm tham số (`alpha=l1_penalty`) cho mô hình  `Lasso` của Sklearn. (Các công cụ khác cũng phân tách các triển khai của LASSO). Khá giống Hồi quy Ridge/L2, các đặc trưng cũng cần được co giãn để đảm bảo đồng đều ở giữa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KlTbDC0RMw1g"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "l1_penalty=5e4\n",
    "full_features = scaler.fit_transform(full_data[all_features].values)\n",
    "full_labels = full_data['price'].values\n",
    "model = Lasso(alpha=l1_penalty).fit(full_features, full_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH4847CcMw1m"
   },
   "source": [
    "Tìm các đặc trưng có trọng số khác 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HElqPj8LMw1n",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0.              0.              0.         132571.09360631\n",
      "      0.             -0.             -0.              0.\n",
      "      0.          14623.33961421  29004.06421249      0.\n",
      "  90207.54789031      0.              0.         -10722.34912003\n",
      "      0.        ]\n",
      "sqft_living waterfront view grade yr_built\n"
     ]
    }
   ],
   "source": [
    "# Bạn có biết numpy cũng có boolean selector tích hợp sẵn?\n",
    "print(model.coef_)\n",
    "print(all_features[3],all_features[9],all_features[10],all_features[12],all_features[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0gF5MD_Mw1r"
   },
   "source": [
    "Lưu ý rằng phần lớn trọng số được đặt thành 0. Vì vậy, bằng cách đặt L1 penalty đủ lớn, chúng ta có thể thực hiện lựa chọn tập con.\n",
    "\n",
    "***QUIZ***:\n",
    "Theo list các trọng số này, những đặc trưng nào đã được chọn? \n",
    "  **sqft_living , waterfront , view , grade , yr_built**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Zv3CFZBMw1s"
   },
   "source": [
    "# Lựa chọn L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oc6Vm3RfMw1t"
   },
   "source": [
    "Để tìm một L1 penalty tốt, chúng ta sẽ khám phá nhiều giá trị sử dụng tập kiểm định. Hãy chia dữ liệu thành tập huấn luyện, tập kiểm định và tập kiểm tra:\n",
    "* Chia dữ liệu bán hàng thành 2 tập: tập huấn luyện và tập kiểm tra (9/1)\n",
    "* Chia tiếp tập huấn luyện thành 2 tập: tập huấn luyện và kiểm định (5/5)\n",
    "\n",
    "Hãy dùng seed = 1 để có cùng kết quả!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "U41_wuIcMw1v"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data,test_data = train_test_split(full_data,train_size = 0.9, random_state=0)\n",
    "huanluyen_data,kiemdinh_data = train_test_split(full_data,train_size = 0.5, random_state=0)\n",
    "\n",
    "# Cookie cho những ai cần copy cell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kCoG3VwMw10"
   },
   "source": [
    "Tiếp theo, chúng ta sẽ viết một vòng lặp như sau: \n",
    "* Với `l1_penalty` trong phạm vi 21 bước giữa [1, 10^9] (sử dụng `np.logspace(0, 9, num=21)`.)\n",
    "    * Khớp mô hình hồi quy với `l1_penalty` trong dữ liệu HUẤN LUYỆN. Chỉ định `alpha=l1_penalty` trong tham số.\n",
    "    * Tính RSS trên dữ liệu KIỂM ĐỊNH (sử dụng `.predict()`) cho `l1_penalty`\n",
    "* Báo lại `l1_penalty` nào cho RSS thấp nhất trong dữ liệu KIỂM ĐỊNH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kYf8zDJtMw11",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\v\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.649e+13, tolerance: 1.421e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\users\\v\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e+13, tolerance: 1.421e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\users\\v\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.652e+13, tolerance: 1.421e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\users\\v\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.658e+13, tolerance: 1.421e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\users\\v\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.675e+13, tolerance: 1.421e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\users\\v\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.718e+13, tolerance: 1.421e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\users\\v\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e+13, tolerance: 1.421e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[477137332129531.06, 477148567250585.56, 477180360831126.94, 477270989672931.06, 477534537324713.1, 478341778404632.6, 481129223794446.5, 490330448369652.5, 534241235980652.9, 553919784978954.5, 597497417794524.6, 786006567086542.8, 1477650369721896.5, 1491581209042466.0, 1491581209042466.0, 1491581209042466.0, 1491581209042466.0, 1491581209042466.0, 1491581209042466.0, 1491581209042466.0, 1491581209042466.0]\n"
     ]
    }
   ],
   "source": [
    "# Mức độ trợ giúp: Bình thường.\n",
    "l1_penalty = np.logspace(0, 9, num=21)\n",
    "RSS = []\n",
    "features1 = StandardScaler().fit_transform(huanluyen_data[all_features].values)\n",
    "features2 = StandardScaler().fit_transform(kiemdinh_data[all_features].values)\n",
    "for penalty in l1_penalty:\n",
    "    model = Lasso(alpha=penalty).fit(features1,huanluyen_data['price'])\n",
    "    y_pred = model.predict(features2)\n",
    "    rss = np.sum((kiemdinh_data['price'] - y_pred )**2)\n",
    "    RSS.append(rss)\n",
    "print(RSS)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "477137332129531.06"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(l1_penalty[RSS.index(min(RSS))])\n",
    "min(RSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAneHq6LMw15"
   },
   "source": [
    "***QUIZ:*** Giá trị tốt nhất cho `l1_penalty` là bao nhiêu?  **1.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "oZ1BXWL7Mw16",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\v\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.649e+13, tolerance: 1.421e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Qua quan sát hay tính toán?\n",
    "features1 = StandardScaler().fit_transform(huanluyen_data[all_features].values)\n",
    "features2 = StandardScaler().fit_transform(kiemdinh_data[all_features].values)\n",
    "model = Lasso(alpha=l1_penalty[RSS.index(min(RSS))]).fit(features1,huanluyen_data['price'])\n",
    "print(len(model.coef_[model.coef_!=0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcnSvUHyMw19"
   },
   "source": [
    "***QUIZ***\n",
    "Với giá trị L1 penalty này, chúng ta có bao nhiêu trọng số khác 0? **17**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Od-dOA-IMw1-"
   },
   "outputs": [],
   "source": [
    "# Thú vị phải không?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zNo9ywLMw2F"
   },
   "source": [
    "# Limit the number of nonzero weights Giới hạn số trọng số khác 0\n",
    "\n",
    "Sẽ ra sao nếu chúng ta muốn giới hạn, 5 đặc trưng chẳng hạn? Điều này quan trọng nếu chúng ta muốn suy ra \"quy tắc ngón tay cái\" --- mô hình có thể diễn giải chỉ với một vài đặc trưng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLijk-3UMw2G"
   },
   "source": [
    "Trong phần này, chúng ta sẽ triển khai quy trình đơn giản gồm 2 giai đoạn :\n",
    "1. Thăm dò phạm vi lớn các giá trị `l1_penalty` để tìm vùng các giá trị `l1_penalty` hẹp hơn mà mô hình chắc chắn sẽ có số lượng trọng số khác 0 mong muốn.\n",
    "2. Thăm dò tiếp vùng hẹp đã thấy để tìm gái trị tốt cho `l1_penalty` đạt được độ thưa thớt mong muốn. Ở đây chúng ta sử dụng tập kiểm định để chọn giá trị tốt nhất cho `l1_penalty`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kOwQHIzMMw2H"
   },
   "outputs": [],
   "source": [
    "max_nonzeros = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMv9UnluMw2N"
   },
   "source": [
    "## Khám phá phạm vi giá trị lớn hơn để tìm phạm vi hẹp với độ thưa thớt mong muốn\n",
    "\n",
    "Hãy xác định một loạt các `l1_penalty_values` có thể:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vEaNt8VHMw2O"
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.logspace(3, 5, num=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mxrj8371Mw2S"
   },
   "source": [
    "Giờ hãy triển khi vòng lặp tìm kiếm trong không gian có các giá trị `l1_penalty` có thể:\n",
    "\n",
    "* Với `l1_penalty` trong `np.logspace(3, 5, num=21)`:\n",
    "    * Khớp mô hình hồi quy với `l1_penalty` đã biết trong dữ liệu HUẤN LUYỆN. Chỉ định `alpha=l1_penalty` trong tham số.\n",
    "    * Trích xuất trọng số của mô hình và đếm số trọng số khác 0. Lưu con số này vào một list. \n",
    "        * Gợi ý: `model.coef_` cho các tham số/hệ số đã tìm thấy (intercept) ở dạng mảng numpy. Sau đó có thể dùng array\\[condition\\] cho list các giá trị truyền điều kiện, hoặc chỉ dùng `np.count_nonzero()` có sẵn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_kFzVsaiMw2U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 14, 14, 14, 14, 14, 12, 10, 10, 10, 10, 9, 6, 5, 5, 5, 5, 5, 4, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "# Hoặc có thể thực hiện với python thuần túy. Nó không ảnh hưởng đáng kể tới chất lượng. \n",
    "W = []\n",
    "sll = []\n",
    "features1 = StandardScaler().fit_transform(huanluyen_data[all_features].values)\n",
    "features2 = StandardScaler().fit_transform(kiemdinh_data[all_features].values)\n",
    "for penalty in l1_penalty_values:\n",
    "    model = Lasso(alpha=penalty).fit(features1,huanluyen_data['price'])\n",
    "    W.append(list(model.coef_))\n",
    "    sll.append(len(model.coef_[model.coef_!=0]))\n",
    "print(sll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucgWXpj9Mw2Z"
   },
   "source": [
    "Trong phạm vi lớn này, chúng ta có thể tìm 2 đầu phạm vi hẹp mong muốn của `l1_penalty`. Ở một đầu, các giá trị `l1_penalty` có quá ít giá trị khác 0, còn đầu kia lại có quá nhiều giá trị khác 0.\n",
    "\n",
    "Hãy tìm:\n",
    "* `l1_penalty` nhỏ nhất có các số khác 0 bằng `max_nonzeros` (nếu chọn penalty nhỏ hơn giá trị này chắc chắn sẽ có rất nhiều trọng số khác 0).\n",
    "    * Lưu giá trị này trong biến `l1_penalty_min` (sẽ sử dụng nó sau).\n",
    "* `l1_penalty` lớn nhất có các số khác 0 bằng `max_nonzeros` (nếu chọn penalty lớn hơn giá trị này chắc chắn sẽ có rất ít trọng số khác 0).\n",
    "    * Lưu giá trị này trong biến `l1_penalty_max` (sẽ sử dụng nó sau).\n",
    "\n",
    "\n",
    "*Gợi ý: có nhiều cách để thực hiện, chẳng hạn:*\n",
    "* Lập trình trong vòng lặp trên.\n",
    "* Tạo một list với số lượng khác 0 cho từng giá trị `l1_penalty` và kiểm tra nó để tìm ranh giới thích hợp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UBpwiXEVMw2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19952.62314968879 50118.72336272725\n"
     ]
    }
   ],
   "source": [
    "l1_penalty_min = min(np.array(l1_penalty_values)[np.where(np.array(sll) == max_nonzeros)[0]]) #\n",
    "l1_penalty_max = max(np.array(l1_penalty_values)[np.where(np.array(sll) == max_nonzeros)[0]]) #\n",
    "print(l1_penalty_min,l1_penalty_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-S2jtklaMw2g"
   },
   "source": [
    "***QUIZ.*** Chúng ta tìm thấy các giá trị nào lần lượt cho `l1_penalty_min` và `l1_penalty_max`? **19952.62314968879 50118.72336272725**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-T_xUbJ5Mw2i"
   },
   "source": [
    "## Khám phá phạm vi nhỏ các giá trị để tìm giải pháp với đúng số lượng các số khác 0 có RSS trong tập kiểm định nhỏ nhất\n",
    "\n",
    "Chúng ta sẽ khám phá vùng hẹp các giá trị `l1_penalty` đã tìm thấy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "mEICQwrAMw2k"
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVkWedu9Mw2p"
   },
   "source": [
    "* Với `l1_penalty` trong `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
    "    * Khớp mô hình hồi quy với `l1_penalty` đã biết trong dữ liệu HUẤN LUYỆN. Chỉ định `alpha=l1_penalty`.\n",
    "    * Đo lường RSS của mô hình đã tìm hiểu trong tập KIỂM ĐỊNH.\n",
    "\n",
    "Tìm mô hình có RSS nhỏ nhất trong tập KIỂM ĐỊNH và độ thưa thớt *bằng*  `max_nonzeros`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gKsCKTP3Mw2q",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570273645842013.5\n",
      "19952.62314968879\n",
      "['sqft_living' 'waterfront' 'view' 'grade' 'yr_built']\n"
     ]
    }
   ],
   "source": [
    "# Xem quiz bên dưới\n",
    "penal = 0\n",
    "RSS = float(\"inf\")\n",
    "W = []\n",
    "for penalty in l1_penalty_values:\n",
    "    model = Lasso(alpha=penalty).fit(features1,huanluyen_data['price'])\n",
    "    y_pred = model.predict(features2)\n",
    "    rss = np.sum((kiemdinh_data['price'] - y_pred )**2)\n",
    "    if rss < RSS:\n",
    "        RSS = rss\n",
    "        penal = penalty\n",
    "        W = model.coef_\n",
    "print(RSS)\n",
    "print(penal)\n",
    "print(np.array(all_features)[np.where(np.array(W) != 0)[0]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4vAuKXfMw2u"
   },
   "source": [
    "***QUIZ***\n",
    "1. Giá trị của `l1_penalty` trong phạm vi hẹp hơn có RSS thấp nhất trong tập KIỂM ĐỊNH và độ thưa *bằng* `max_nonzeros` là? **19952.62314968879**\n",
    "2. Các đặc trung nào trong mô hình này có các hệ số khác 0? **'sqft_living' 'waterfront' 'view' 'grade' 'yr_built'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VISUoAMIMw2v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[VN]Lab-5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2da04a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29940, 999)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.utils import shuffle\n",
    "from collections import deque\n",
    "import pickle\n",
    "\n",
    "loaded = np.load(\"arrays.npz\")\n",
    "x_train, x_test, y_train, y_test = loaded[\"array1\"],loaded[\"array3\"],loaded[\"array2\"],loaded[\"array4\"]\n",
    "x_total = np.concatenate((x_train, x_test), axis=0)\n",
    "y_total = np.concatenate((y_train, y_test), axis=0)\n",
    "y_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "460ff817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,880</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">393,728</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">999</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">128,871</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m98\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m18,880\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m24,704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │          \u001b[38;5;34m98,560\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)              │         \u001b[38;5;34m393,728\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)              │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m131,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m999\u001b[0m)                 │         \u001b[38;5;34m128,871\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">799,783</span> (3.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m799,783\u001b[0m (3.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">797,863</span> (3.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m797,863\u001b[0m (3.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.0023 - loss: 0.1159 - top_k_categorical_accuracy: 0.0100 - val_accuracy: 9.1850e-04 - val_loss: 0.0089 - val_top_k_categorical_accuracy: 0.0084\n",
      "Epoch 2/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 4.1246e-04 - loss: 0.0088 - top_k_categorical_accuracy: 0.0067 - val_accuracy: 0.0011 - val_loss: 0.0082 - val_top_k_categorical_accuracy: 0.0089\n",
      "Epoch 3/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.0086 - top_k_categorical_accuracy: 0.0076 - val_accuracy: 0.0011 - val_loss: 0.0082 - val_top_k_categorical_accuracy: 0.0102\n",
      "Epoch 4/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.0016 - loss: 0.0085 - top_k_categorical_accuracy: 0.0137 - val_accuracy: 0.0029 - val_loss: 0.0081 - val_top_k_categorical_accuracy: 0.0166\n",
      "Epoch 5/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.0028 - loss: 0.0083 - top_k_categorical_accuracy: 0.0191 - val_accuracy: 0.0034 - val_loss: 0.0079 - val_top_k_categorical_accuracy: 0.0292\n",
      "Epoch 6/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.0061 - loss: 0.0080 - top_k_categorical_accuracy: 0.0369 - val_accuracy: 0.0069 - val_loss: 0.0077 - val_top_k_categorical_accuracy: 0.0542\n",
      "Epoch 7/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.0135 - loss: 0.0076 - top_k_categorical_accuracy: 0.0712 - val_accuracy: 0.0143 - val_loss: 0.0071 - val_top_k_categorical_accuracy: 0.1025\n",
      "Epoch 8/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.0202 - loss: 0.0071 - top_k_categorical_accuracy: 0.1189 - val_accuracy: 0.0215 - val_loss: 0.0068 - val_top_k_categorical_accuracy: 0.1606\n",
      "Epoch 9/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.0329 - loss: 0.0066 - top_k_categorical_accuracy: 0.1862 - val_accuracy: 0.0401 - val_loss: 0.0065 - val_top_k_categorical_accuracy: 0.2141\n",
      "Epoch 10/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.0635 - loss: 0.0061 - top_k_categorical_accuracy: 0.2910 - val_accuracy: 0.0802 - val_loss: 0.0059 - val_top_k_categorical_accuracy: 0.3292\n",
      "Epoch 11/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.0915 - loss: 0.0057 - top_k_categorical_accuracy: 0.3922 - val_accuracy: 0.1017 - val_loss: 0.0056 - val_top_k_categorical_accuracy: 0.4023\n",
      "Epoch 12/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.1262 - loss: 0.0052 - top_k_categorical_accuracy: 0.5052 - val_accuracy: 0.1459 - val_loss: 0.0051 - val_top_k_categorical_accuracy: 0.5173\n",
      "Epoch 13/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.1774 - loss: 0.0048 - top_k_categorical_accuracy: 0.5855 - val_accuracy: 0.1776 - val_loss: 0.0048 - val_top_k_categorical_accuracy: 0.5820\n",
      "Epoch 14/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.2294 - loss: 0.0044 - top_k_categorical_accuracy: 0.6964 - val_accuracy: 0.2342 - val_loss: 0.0045 - val_top_k_categorical_accuracy: 0.6665\n",
      "Epoch 15/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.3008 - loss: 0.0040 - top_k_categorical_accuracy: 0.7618 - val_accuracy: 0.2840 - val_loss: 0.0042 - val_top_k_categorical_accuracy: 0.7140\n",
      "Epoch 16/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.3252 - loss: 0.0039 - top_k_categorical_accuracy: 0.7848 - val_accuracy: 0.3208 - val_loss: 0.0040 - val_top_k_categorical_accuracy: 0.7550\n",
      "Epoch 17/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.4008 - loss: 0.0034 - top_k_categorical_accuracy: 0.8601 - val_accuracy: 0.3653 - val_loss: 0.0037 - val_top_k_categorical_accuracy: 0.7976\n",
      "Epoch 18/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.4380 - loss: 0.0032 - top_k_categorical_accuracy: 0.8889 - val_accuracy: 0.3663 - val_loss: 0.0037 - val_top_k_categorical_accuracy: 0.8007\n",
      "Epoch 19/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.4815 - loss: 0.0030 - top_k_categorical_accuracy: 0.9094 - val_accuracy: 0.4208 - val_loss: 0.0034 - val_top_k_categorical_accuracy: 0.8390\n",
      "Epoch 20/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.5142 - loss: 0.0028 - top_k_categorical_accuracy: 0.9270 - val_accuracy: 0.4321 - val_loss: 0.0034 - val_top_k_categorical_accuracy: 0.8359\n",
      "Epoch 21/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.5835 - loss: 0.0026 - top_k_categorical_accuracy: 0.9428 - val_accuracy: 0.4610 - val_loss: 0.0032 - val_top_k_categorical_accuracy: 0.8623\n",
      "Epoch 22/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.6120 - loss: 0.0024 - top_k_categorical_accuracy: 0.9547 - val_accuracy: 0.4757 - val_loss: 0.0033 - val_top_k_categorical_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.6340 - loss: 0.0023 - top_k_categorical_accuracy: 0.9706 - val_accuracy: 0.4942 - val_loss: 0.0032 - val_top_k_categorical_accuracy: 0.8704\n",
      "Epoch 24/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.6517 - loss: 0.0022 - top_k_categorical_accuracy: 0.9708 - val_accuracy: 0.5109 - val_loss: 0.0031 - val_top_k_categorical_accuracy: 0.8723\n",
      "Epoch 25/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.6964 - loss: 0.0020 - top_k_categorical_accuracy: 0.9781 - val_accuracy: 0.5277 - val_loss: 0.0030 - val_top_k_categorical_accuracy: 0.8808\n",
      "Epoch 26/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.7137 - loss: 0.0019 - top_k_categorical_accuracy: 0.9813 - val_accuracy: 0.5286 - val_loss: 0.0030 - val_top_k_categorical_accuracy: 0.8811\n",
      "Epoch 27/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7387 - loss: 0.0018 - top_k_categorical_accuracy: 0.9847 - val_accuracy: 0.5423 - val_loss: 0.0030 - val_top_k_categorical_accuracy: 0.8900\n",
      "Epoch 28/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7569 - loss: 0.0017 - top_k_categorical_accuracy: 0.9862 - val_accuracy: 0.5400 - val_loss: 0.0030 - val_top_k_categorical_accuracy: 0.8894\n",
      "Epoch 29/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.7558 - loss: 0.0018 - top_k_categorical_accuracy: 0.9851 - val_accuracy: 0.5518 - val_loss: 0.0030 - val_top_k_categorical_accuracy: 0.8895\n",
      "Epoch 30/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7673 - loss: 0.0016 - top_k_categorical_accuracy: 0.9904 - val_accuracy: 0.5625 - val_loss: 0.0029 - val_top_k_categorical_accuracy: 0.8945\n",
      "Epoch 31/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - accuracy: 0.8033 - loss: 0.0015 - top_k_categorical_accuracy: 0.9932 - val_accuracy: 0.5574 - val_loss: 0.0030 - val_top_k_categorical_accuracy: 0.8942\n",
      "Epoch 32/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.8124 - loss: 0.0014 - top_k_categorical_accuracy: 0.9911 - val_accuracy: 0.5664 - val_loss: 0.0030 - val_top_k_categorical_accuracy: 0.8939\n",
      "Epoch 33/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.8284 - loss: 0.0014 - top_k_categorical_accuracy: 0.9956 - val_accuracy: 0.5711 - val_loss: 0.0031 - val_top_k_categorical_accuracy: 0.8959\n",
      "Epoch 34/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.8273 - loss: 0.0014 - top_k_categorical_accuracy: 0.9960 - val_accuracy: 0.5819 - val_loss: 0.0029 - val_top_k_categorical_accuracy: 0.9003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.8416 - loss: 0.0013 - top_k_categorical_accuracy: 0.9962 - val_accuracy: 0.5796 - val_loss: 0.0031 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 36/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.8412 - loss: 0.0013 - top_k_categorical_accuracy: 0.9973 - val_accuracy: 0.5816 - val_loss: 0.0031 - val_top_k_categorical_accuracy: 0.9012\n",
      "Epoch 37/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.8656 - loss: 0.0012 - top_k_categorical_accuracy: 0.9979 - val_accuracy: 0.5935 - val_loss: 0.0031 - val_top_k_categorical_accuracy: 0.9063\n",
      "Epoch 38/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.8646 - loss: 0.0012 - top_k_categorical_accuracy: 0.9962 - val_accuracy: 0.5952 - val_loss: 0.0031 - val_top_k_categorical_accuracy: 0.9040\n",
      "Epoch 39/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.8556 - loss: 0.0012 - top_k_categorical_accuracy: 0.9961 - val_accuracy: 0.5895 - val_loss: 0.0031 - val_top_k_categorical_accuracy: 0.8994\n",
      "Epoch 40/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.8659 - loss: 0.0011 - top_k_categorical_accuracy: 0.9977 - val_accuracy: 0.5836 - val_loss: 0.0032 - val_top_k_categorical_accuracy: 0.8951\n",
      "Epoch 41/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.8598 - loss: 0.0012 - top_k_categorical_accuracy: 0.9973 - val_accuracy: 0.5907 - val_loss: 0.0033 - val_top_k_categorical_accuracy: 0.8937\n",
      "Epoch 42/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.8832 - loss: 0.0011 - top_k_categorical_accuracy: 0.9978 - val_accuracy: 0.5949 - val_loss: 0.0032 - val_top_k_categorical_accuracy: 0.8977\n",
      "Epoch 43/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.8819 - loss: 0.0010 - top_k_categorical_accuracy: 0.9984 - val_accuracy: 0.5961 - val_loss: 0.0032 - val_top_k_categorical_accuracy: 0.8955\n",
      "Epoch 44/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.8906 - loss: 0.0010 - top_k_categorical_accuracy: 0.9964 - val_accuracy: 0.5969 - val_loss: 0.0033 - val_top_k_categorical_accuracy: 0.9033\n",
      "Epoch 45/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.8926 - loss: 9.9704e-04 - top_k_categorical_accuracy: 0.9967 - val_accuracy: 0.6012 - val_loss: 0.0033 - val_top_k_categorical_accuracy: 0.8971\n",
      "Epoch 46/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9012 - loss: 9.3507e-04 - top_k_categorical_accuracy: 0.9981 - val_accuracy: 0.6017 - val_loss: 0.0033 - val_top_k_categorical_accuracy: 0.8990\n",
      "Epoch 47/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.8935 - loss: 9.5375e-04 - top_k_categorical_accuracy: 0.9985 - val_accuracy: 0.6082 - val_loss: 0.0033 - val_top_k_categorical_accuracy: 0.9028\n",
      "Epoch 48/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9136 - loss: 8.7904e-04 - top_k_categorical_accuracy: 0.9983 - val_accuracy: 0.5950 - val_loss: 0.0034 - val_top_k_categorical_accuracy: 0.8971\n",
      "Epoch 49/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9117 - loss: 8.8801e-04 - top_k_categorical_accuracy: 0.9984 - val_accuracy: 0.5990 - val_loss: 0.0034 - val_top_k_categorical_accuracy: 0.8948\n",
      "Epoch 50/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9160 - loss: 8.5724e-04 - top_k_categorical_accuracy: 0.9995 - val_accuracy: 0.5980 - val_loss: 0.0036 - val_top_k_categorical_accuracy: 0.8957\n",
      "Epoch 51/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9099 - loss: 8.6739e-04 - top_k_categorical_accuracy: 0.9988 - val_accuracy: 0.6049 - val_loss: 0.0035 - val_top_k_categorical_accuracy: 0.8998\n",
      "Epoch 52/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.9298 - loss: 7.8562e-04 - top_k_categorical_accuracy: 0.9995 - val_accuracy: 0.6031 - val_loss: 0.0034 - val_top_k_categorical_accuracy: 0.9035\n",
      "Epoch 53/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9173 - loss: 8.3693e-04 - top_k_categorical_accuracy: 0.9989 - val_accuracy: 0.6048 - val_loss: 0.0035 - val_top_k_categorical_accuracy: 0.8991\n",
      "Epoch 54/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9223 - loss: 8.2682e-04 - top_k_categorical_accuracy: 0.9989 - val_accuracy: 0.6032 - val_loss: 0.0036 - val_top_k_categorical_accuracy: 0.8947\n",
      "Epoch 55/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9237 - loss: 8.2165e-04 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.6070 - val_loss: 0.0035 - val_top_k_categorical_accuracy: 0.9016\n",
      "Epoch 56/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9272 - loss: 7.8036e-04 - top_k_categorical_accuracy: 0.9997 - val_accuracy: 0.6037 - val_loss: 0.0036 - val_top_k_categorical_accuracy: 0.8988\n",
      "Epoch 57/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9219 - loss: 7.7033e-04 - top_k_categorical_accuracy: 0.9985 - val_accuracy: 0.6097 - val_loss: 0.0037 - val_top_k_categorical_accuracy: 0.8942\n",
      "Epoch 58/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9475 - loss: 6.6248e-04 - top_k_categorical_accuracy: 0.9992 - val_accuracy: 0.6057 - val_loss: 0.0037 - val_top_k_categorical_accuracy: 0.8992\n",
      "Epoch 59/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9250 - loss: 7.7884e-04 - top_k_categorical_accuracy: 0.9997 - val_accuracy: 0.6040 - val_loss: 0.0037 - val_top_k_categorical_accuracy: 0.8983\n",
      "Epoch 60/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9244 - loss: 7.5646e-04 - top_k_categorical_accuracy: 0.9994 - val_accuracy: 0.6053 - val_loss: 0.0036 - val_top_k_categorical_accuracy: 0.8958\n",
      "Epoch 61/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9378 - loss: 7.5510e-04 - top_k_categorical_accuracy: 0.9991 - val_accuracy: 0.6053 - val_loss: 0.0038 - val_top_k_categorical_accuracy: 0.8978\n",
      "Epoch 62/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9360 - loss: 7.6249e-04 - top_k_categorical_accuracy: 0.9986 - val_accuracy: 0.6028 - val_loss: 0.0038 - val_top_k_categorical_accuracy: 0.8916\n",
      "Epoch 63/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9379 - loss: 7.1349e-04 - top_k_categorical_accuracy: 0.9998 - val_accuracy: 0.5981 - val_loss: 0.0039 - val_top_k_categorical_accuracy: 0.8884\n",
      "Epoch 64/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9293 - loss: 7.5081e-04 - top_k_categorical_accuracy: 0.9987 - val_accuracy: 0.6093 - val_loss: 0.0037 - val_top_k_categorical_accuracy: 0.8982\n",
      "Epoch 65/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9405 - loss: 6.9737e-04 - top_k_categorical_accuracy: 0.9997 - val_accuracy: 0.6108 - val_loss: 0.0038 - val_top_k_categorical_accuracy: 0.8994\n",
      "Epoch 66/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9490 - loss: 6.4585e-04 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.6081 - val_loss: 0.0038 - val_top_k_categorical_accuracy: 0.8992\n",
      "Epoch 67/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9426 - loss: 6.5064e-04 - top_k_categorical_accuracy: 0.9996 - val_accuracy: 0.6053 - val_loss: 0.0039 - val_top_k_categorical_accuracy: 0.8966\n",
      "Epoch 68/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9432 - loss: 6.2456e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.6089 - val_loss: 0.0038 - val_top_k_categorical_accuracy: 0.8993\n",
      "Epoch 69/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9446 - loss: 6.3047e-04 - top_k_categorical_accuracy: 0.9998 - val_accuracy: 0.6108 - val_loss: 0.0040 - val_top_k_categorical_accuracy: 0.8997\n",
      "Epoch 70/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9476 - loss: 6.4700e-04 - top_k_categorical_accuracy: 0.9993 - val_accuracy: 0.6096 - val_loss: 0.0040 - val_top_k_categorical_accuracy: 0.8938\n",
      "Epoch 71/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9468 - loss: 6.4094e-04 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.6116 - val_loss: 0.0040 - val_top_k_categorical_accuracy: 0.8970\n",
      "Epoch 72/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.9428 - loss: 6.5256e-04 - top_k_categorical_accuracy: 0.9995 - val_accuracy: 0.6066 - val_loss: 0.0040 - val_top_k_categorical_accuracy: 0.8955\n",
      "Epoch 73/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9396 - loss: 7.1662e-04 - top_k_categorical_accuracy: 0.9996 - val_accuracy: 0.6056 - val_loss: 0.0040 - val_top_k_categorical_accuracy: 0.8954\n",
      "Epoch 74/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9477 - loss: 6.2953e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.6053 - val_loss: 0.0041 - val_top_k_categorical_accuracy: 0.8959\n",
      "Epoch 75/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9460 - loss: 6.2303e-04 - top_k_categorical_accuracy: 0.9997 - val_accuracy: 0.6142 - val_loss: 0.0041 - val_top_k_categorical_accuracy: 0.8937\n",
      "Epoch 76/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.9456 - loss: 6.3480e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.6116 - val_loss: 0.0041 - val_top_k_categorical_accuracy: 0.8961\n",
      "Epoch 77/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9440 - loss: 6.4190e-04 - top_k_categorical_accuracy: 0.9996 - val_accuracy: 0.6068 - val_loss: 0.0041 - val_top_k_categorical_accuracy: 0.8949\n",
      "Epoch 78/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9580 - loss: 5.8531e-04 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.6053 - val_loss: 0.0042 - val_top_k_categorical_accuracy: 0.8926\n",
      "Epoch 79/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9445 - loss: 6.8054e-04 - top_k_categorical_accuracy: 0.9987 - val_accuracy: 0.6096 - val_loss: 0.0042 - val_top_k_categorical_accuracy: 0.8930\n",
      "Epoch 80/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9522 - loss: 6.0917e-04 - top_k_categorical_accuracy: 0.9996 - val_accuracy: 0.6108 - val_loss: 0.0042 - val_top_k_categorical_accuracy: 0.8925\n",
      "Epoch 81/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9506 - loss: 6.0961e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.6104 - val_loss: 0.0043 - val_top_k_categorical_accuracy: 0.8957\n",
      "Epoch 82/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9525 - loss: 5.8903e-04 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.6176 - val_loss: 0.0041 - val_top_k_categorical_accuracy: 0.8990\n",
      "Epoch 83/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9568 - loss: 5.9343e-04 - top_k_categorical_accuracy: 0.9996 - val_accuracy: 0.6102 - val_loss: 0.0042 - val_top_k_categorical_accuracy: 0.8982\n",
      "Epoch 84/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9508 - loss: 5.8513e-04 - top_k_categorical_accuracy: 0.9995 - val_accuracy: 0.6080 - val_loss: 0.0043 - val_top_k_categorical_accuracy: 0.8975\n",
      "Epoch 85/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.9571 - loss: 5.5997e-04 - top_k_categorical_accuracy: 0.9998 - val_accuracy: 0.6159 - val_loss: 0.0042 - val_top_k_categorical_accuracy: 0.8998\n",
      "Epoch 86/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9605 - loss: 5.0758e-04 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.6147 - val_loss: 0.0042 - val_top_k_categorical_accuracy: 0.8990\n",
      "Epoch 87/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9658 - loss: 5.0871e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.6100 - val_loss: 0.0043 - val_top_k_categorical_accuracy: 0.8959\n",
      "Epoch 88/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9633 - loss: 4.8595e-04 - top_k_categorical_accuracy: 0.9995 - val_accuracy: 0.6132 - val_loss: 0.0042 - val_top_k_categorical_accuracy: 0.8984\n",
      "Epoch 89/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9656 - loss: 4.7044e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.6092 - val_loss: 0.0044 - val_top_k_categorical_accuracy: 0.8940\n",
      "Epoch 90/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9574 - loss: 5.4975e-04 - top_k_categorical_accuracy: 0.9997 - val_accuracy: 0.6163 - val_loss: 0.0042 - val_top_k_categorical_accuracy: 0.8988\n",
      "Epoch 91/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9528 - loss: 5.7908e-04 - top_k_categorical_accuracy: 0.9991 - val_accuracy: 0.6105 - val_loss: 0.0043 - val_top_k_categorical_accuracy: 0.8983\n",
      "Epoch 92/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9554 - loss: 5.7053e-04 - top_k_categorical_accuracy: 0.9990 - val_accuracy: 0.6126 - val_loss: 0.0042 - val_top_k_categorical_accuracy: 0.8991\n",
      "Epoch 93/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9632 - loss: 5.3338e-04 - top_k_categorical_accuracy: 0.9998 - val_accuracy: 0.6121 - val_loss: 0.0043 - val_top_k_categorical_accuracy: 0.8957\n",
      "Epoch 94/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9573 - loss: 5.4131e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.6096 - val_loss: 0.0044 - val_top_k_categorical_accuracy: 0.8970\n",
      "Epoch 95/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9584 - loss: 5.3666e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.6096 - val_loss: 0.0045 - val_top_k_categorical_accuracy: 0.8935\n",
      "Epoch 96/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9596 - loss: 5.1065e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.6102 - val_loss: 0.0044 - val_top_k_categorical_accuracy: 0.8950\n",
      "Epoch 97/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9609 - loss: 5.4121e-04 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.6138 - val_loss: 0.0044 - val_top_k_categorical_accuracy: 0.8999\n",
      "Epoch 98/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.9708 - loss: 4.2083e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.6169 - val_loss: 0.0043 - val_top_k_categorical_accuracy: 0.9012\n",
      "Epoch 99/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - accuracy: 0.9663 - loss: 4.9909e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.6175 - val_loss: 0.0043 - val_top_k_categorical_accuracy: 0.9002\n",
      "Epoch 100/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.9671 - loss: 4.7805e-04 - top_k_categorical_accuracy: 0.9998 - val_accuracy: 0.6140 - val_loss: 0.0044 - val_top_k_categorical_accuracy: 0.8979\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional ,GRU, Conv1D ,BatchNormalization,MaxPooling1D,Flatten\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, MaxPooling1D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Định nghĩa đầu vào\n",
    "inputs = Input(shape=(20, 98))\n",
    "\n",
    "# Lớp 1: Conv1D + BatchNorm + MaxPooling\n",
    "x = Conv1D(64, kernel_size=3, activation='gelu', padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Lớp 2: Conv1D + BatchNorm + MaxPooling\n",
    "x = Conv1D(128, kernel_size=3, activation='gelu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Lớp 3: Conv1D + BatchNorm + MaxPooling\n",
    "x = Conv1D(256, kernel_size=3, activation='gelu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Lớp 4: Conv1D + BatchNorm\n",
    "x = Conv1D(512, kernel_size=3, activation='gelu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Flatten + Dense layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='gelu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Đầu ra\n",
    "output = Dense(999, activation='sigmoid')(x)\n",
    "# Tạo mô hình\n",
    "model_sl= Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model_sl.compile(loss =tf.keras.losses.BinaryCrossentropy(), optimizer='adam', metrics=['accuracy',tf.keras.metrics.TopKCategoricalAccuracy(k=10)])\n",
    "model_sl.summary()\n",
    "History = model_sl.fit(x_train,y_train,validation_data=(x_total, y_total), epochs=100,batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b3b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    def __init__(self, x_data, y_data, num_classes):\n",
    "        self.x_data, self.y_data = shuffle(x_data, y_data)  # Shuffle data\n",
    "        self.num_classes = num_classes\n",
    "        self.current_idx = 0\n",
    "        self.remaining_indices = 999\n",
    "    def reset(self):\n",
    "        #lấy state Ngẫu nhiên đầy đủ\n",
    "        self.current_idx += 1\n",
    "        return self.x_data[self.current_idx]\n",
    "\n",
    "   \n",
    "    def step(self, action):\n",
    "        action_ = np.argsort(action[0])[-10:][::-1]\n",
    "        \n",
    "        true_label = np.argmax(self.y_data[self.current_idx])\n",
    "        # Nếu dự đoán đúng\n",
    "        eward =[1 if int(word) == int(true_label) else 0 for word in action_]\n",
    "        if int(true_label) in action_:\n",
    "            reward = action[0]\n",
    "            reward[action_] = 0\n",
    "            reward[true_label] = 1\n",
    "        else:\n",
    "            reward = action[0]\n",
    "            reward[action_] = 0\n",
    "        max_value_index = np.argmax(action[0])\n",
    "        acti = np.zeros(len(action[0]))\n",
    "        acti[true_label] = 1\n",
    "        return  acti,reward,eward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64bfaed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,880</span> │ conv1d_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ vector_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">999</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024,000</span> │ vector_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">999</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,023,975</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m98\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m18,880\u001b[0m │ conv1d_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m12,352\u001b[0m │ conv1d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ vector_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m999\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ conv1d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)              │       \u001b[38;5;34m1,024,000\u001b[0m │ vector_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m999\u001b[0m)               │       \u001b[38;5;34m1,023,975\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,079,207</span> (7.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,079,207\u001b[0m (7.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,079,207</span> (7.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,079,207\u001b[0m (7.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow\n",
    "def min_max_normalization(values):\n",
    "    values = np.array(values)\n",
    "    min_val = np.min(values)\n",
    "    max_val = np.max(values)\n",
    "    return (values - min_val) / (max_val - min_val)\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_pred_labels = tf.argmax(y_pred, axis=1)\n",
    "    y_true_labels = tf.argmax(y_true, axis=1)\n",
    "    \n",
    "    # So sánh và tính độ chính xác\n",
    "    accuracy = tf.reduce_mean(tf.cast(y_pred_labels == y_true_labels, tf.float32))\n",
    "    \n",
    "    top_10_preds = np.argsort(y_pred, axis=1)[:, -10:]  \n",
    "    matches = [y_true_labels[i] in top_10_preds[i] for i in range(len(y_true))]\n",
    "    # Tính tỷ lệ chính xác top 1\n",
    "    accuracy_ = np.mean(matches)\n",
    "    #print(f'**********-------Accuracy:{accuracy}-------- Accuracy_Top_10:{Accuracy_}')\n",
    "    return accuracy.numpy(),accuracy_\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, Dense, GlobalMaxPooling1D, MultiHeadAttention, Dropout, Concatenate, Reshape, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Đầu vào 1: Chuỗi dữ liệu qua Conv1D\n",
    "input1 = Input(shape=(20, 98), name=\"conv1d_input\")  # (seq_len, feature_dim)\n",
    "x = Conv1D(filters=64, kernel_size=3, activation=\"gelu\")(input1)  # (batch_size, seq_len, filters)\n",
    "x = Conv1D(filters=64, kernel_size=3, activation=\"gelu\")(x) \n",
    "x = Flatten()(x)\n",
    "#x = Reshape((1, 1024))(x)\n",
    "# Đầu vào 2: Vector đặc trưng\n",
    "input2 = Input(shape=(999,), name=\"vector_input\")  # \n",
    "x2 = Dense(1024, activation=\"gelu\")(input2)\n",
    "output = Dense(999, activation=\"linear\")(x*x2)  # Phân loại 10 lớp\n",
    "\n",
    "# Xây dựng mô hình\n",
    "model_reward = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile mô hình\n",
    "model_reward.compile(optimizer='adam', loss='mse', metrics=[\"accuracy\"])\n",
    "\n",
    "# Hiển thị kiến trúc\n",
    "model_reward.summary()\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='accuracy',  # Theo dõi giá trị \n",
    "    patience=3,          # Dừng nếu không cải thiện sau\n",
    "    restore_best_weights=True  # Phục hồi trọng số tốt nhất\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e419f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lớp Replay Buffer\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "\n",
    "    def add(self, state, action, reward, probability):\n",
    "        transition = (state, action, reward, probability)\n",
    "\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(transition)\n",
    "        else:\n",
    "            self.buffer[self.position] = transition\n",
    "\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        if batch_size > len(self.buffer):\n",
    "            batch_size = len(self.buffer)\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        states, actions, rewards, probabilities = zip(*batch)\n",
    "        return (\n",
    "            np.array(states),\n",
    "            np.array(actions),\n",
    "            np.array(rewards),\n",
    "            np.array(probabilities),\n",
    "        )\n",
    "    def sample_r(self, n):\n",
    "        recent = self.buffer[-n:] if n <= len(self.buffer) else self.buffer\n",
    "        states, actions, rewards, probabilities = zip(*recent)\n",
    "        return (\n",
    "            np.array(states),\n",
    "            np.array(actions),\n",
    "            np.array(rewards),\n",
    "            np.array(probabilities),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    def save(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.buffer, f)\n",
    "\n",
    "    def load(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.buffer = pickle.load(f)\n",
    "    def del_(self, n):\n",
    "        \"\"\"Xóa `n` phần tử đầu tiên trong buffer.\"\"\"\n",
    "        if n <= len(self.buffer):\n",
    "            self.buffer = self.buffer[n:]\n",
    "        else:\n",
    "            self.buffer = []\n",
    "    def save(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.buffer, f)\n",
    "\n",
    "    def load(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.buffer = pickle.load(f)\n",
    "ReplayBuffer = ReplayBuffer(30000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5542e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Hàm cập nhật PPO đơn giản\n",
    "def update(model, ReplayBuffer, learning_rate=3e-4, epochs=2, batch_size=32):\n",
    "    # Khởi tạo optimizer\n",
    "    def ewc_loss(y_true, y_pred, model, fisher_information, weights_before):\n",
    "        # Mất mát cho tác vụ mới\n",
    "        task_loss = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
    "\n",
    "        # Tính phần phạt EWC\n",
    "        ewc_penalty = 0\n",
    "        for var, fisher, weight_old in zip(model.trainable_variables, fisher_information, weights_before):\n",
    "            ewc_penalty += tf.reduce_sum(fisher * tf.square(var - weight_old))\n",
    "\n",
    "        # Tổng hợp hàm mất mát\n",
    "        return task_loss + lambda_ewc * ewc_penalty\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    # Huấn luyện mô hình trên tác vụ mới\n",
    "    def fit_ewc(model,x_train_new,y_train_new,epochss):\n",
    "        stop1 = 0\n",
    "        weights_before = model.trainable_variables\n",
    "        for epoch in range(epochss):\n",
    "            for x_batch, y_batch in tf.data.Dataset.from_tensor_slices((x_train_new, y_train_new)).batch(32):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    logits = model(x_batch, training=True)\n",
    "                    loss = ewc_loss(y_batch, logits, model, fisher_information, weights_before)\n",
    "                # Cập nhật trọng số\n",
    "                grads = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            predict = agent.model(x_train_new)\n",
    "            b1,b2 = accuracy(y_train_new,predict)\n",
    "\n",
    "            y_predict = agent.model(x_total)\n",
    "            a1,a2 = accuracy(y_total,y_predict)\n",
    "            print(f\"Epoch {epoch + 1}: Loss = {loss.numpy().mean()}--------------- Accuracy : {a1}--- {a2}\")\n",
    "            if stop1/b1 > 0.98:\n",
    "                break\n",
    "            else:\n",
    "                stop1 = b1\n",
    "        y_predict = agent.model(x_total)\n",
    "        a1,a2 = accuracy(y_total,y_predict)\n",
    "        kq_1.append(a1)\n",
    "        kq_2.append(a2)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    # Lấy dữ liệu từ replay buffer\n",
    "    states1, actions1 ,rewards1,probability1 = ReplayBuffer.sample_r(6000)\n",
    "    rewards1 = min_max_normalization(rewards1)\n",
    "    probability_ = min_max_normalization(probability1)\n",
    "    states = tf.convert_to_tensor(states1, dtype=tf.float32)\n",
    "    actions = tf.convert_to_tensor(actions1, dtype=tf.int32)\n",
    "    rewards = tf.convert_to_tensor(rewards1, dtype=tf.float32)\n",
    "    probability = tf.convert_to_tensor(probability1, dtype=tf.float32)\n",
    "    model_reward.fit([states1,probability_],rewards1 , epochs=20,batch_size=32 ,callbacks = [early_stopping])\n",
    "\n",
    "    rewa = model_reward.predict([states1,probability_])\n",
    "    rewa = min_max_normalization(rewa**2)\n",
    "    fit_ewc(model,states1, rewa,2)\n",
    "\n",
    "    y_predict = agent.model(x_total)\n",
    "    a3,a4 = accuracy(y_total,y_predict)\n",
    "    kq_3.append(a3)\n",
    "    kq_4.append(a4)\n",
    "    print(f'Accuracy:{a3}********************{a4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4ac7c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,880</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_24               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_25               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_26               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">393,728</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_27               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">999</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">128,871</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m98\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_24 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m18,880\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_24               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_18 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_25 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m24,704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_25               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_19 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_26 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │          \u001b[38;5;34m98,560\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_26               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_20 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)              │         \u001b[38;5;34m393,728\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_27               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)              │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m131,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_34 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m999\u001b[0m)                 │         \u001b[38;5;34m128,871\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">799,783</span> (3.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m799,783\u001b[0m (3.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">797,863</span> (3.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m797,863\u001b[0m (3.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_sl.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "          loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "          metrics=['accuracy',tf.keras.metrics.TopKCategoricalAccuracy(k=10)])\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.state_shape = (20,98)\n",
    "        self.action_space = 999\n",
    "        self.batch_size = 32\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.99\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.gamma = 0.95\n",
    "        self.model = model_sl\n",
    "        \n",
    "        #self.replay_buffer = ReplayBuffer(30000)\n",
    "        \n",
    "    def act(self, state):\n",
    "\n",
    "        q_values = self.model.predict(state, verbose=0)\n",
    "        return q_values\n",
    "    def key(self):\n",
    "        tokenizer = pickle.load(open('tokenizer.pkl', 'rb'))\n",
    "        word_index = tokenizer.word_index\n",
    "        key = list(word_index.keys())\n",
    "        return key\n",
    "        \n",
    "    def remember(self, state, action, reward):\n",
    "        self.replay_buffer.add((state, action, reward ,probability))\n",
    "        \n",
    "    \n",
    "    def update_target_model(self,Replaybuffer):\n",
    "        update(self.model, Replaybuffer)\n",
    "        # Cập nhật target model sau mỗi 1000 episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b80c2edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fisher_information = []\n",
    "#state_, action_, reward_, probability_\n",
    "# Duyệt qua tập dữ liệu để tính toán Fisher Information\n",
    "for x, y in tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(32):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Kích hoạt gradient theo các trọng số mô hình\n",
    "        logits = model_sl(x, training=False)\n",
    "        loss = tf.keras.losses.BinaryCrossentropy()(y, logits)\n",
    "    # Tính gradient của loss đối với tất cả trọng số\n",
    "    grads = tape.gradient(loss, model_sl.trainable_variables)\n",
    "\n",
    "    # Bình phương gradient và cộng dồn\n",
    "    if not fisher_information:\n",
    "        fisher_information = [tf.square(g) for g in grads]\n",
    "    else:\n",
    "        fisher_information = [f + tf.square(g) for f, g in zip(fisher_information, grads)]\n",
    "\n",
    "# Lấy giá trị trung bình Fisher Information trên toàn bộ dữ liệu\n",
    "fisher_information = [f / len(x_train) for f in fisher_information]\n",
    "\n",
    "\n",
    "# Hệ số điều chỉnh λ\n",
    "\n",
    "lambda_ewc = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "523317f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent()\n",
    "batch_size = 32\n",
    "episodes =5900\n",
    "evn = Env(x_train,y_train,999)\n",
    "\n",
    "kq = []\n",
    "# Huấn luyện agent\n",
    "kq_1 = []\n",
    "kq_2 = []\n",
    "kq_3 = []\n",
    "kq_4 = []\n",
    "n = 2\n",
    "for e in range(episodes):\n",
    "    state = evn.reset()\n",
    "    state = np.expand_dims(state, axis=0)  # Thêm chiều batch\n",
    "    probability = agent.act(state)\n",
    "  \n",
    "    action,reward,uu = evn.step(probability)\n",
    "    kq.append(uu)\n",
    "    ReplayBuffer.add(state[0], action, reward, probability[0])\n",
    "    \n",
    "        \n",
    "    e += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "175f905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "ReplayBuffer_s = copy.deepcopy(ReplayBuffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62c9ad22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8863 - loss: 7.2853e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9340 - loss: 6.8094e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9572 - loss: 6.4101e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9648 - loss: 5.9033e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9738 - loss: 5.4767e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9749 - loss: 4.9672e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9767 - loss: 4.4284e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9793 - loss: 3.9195e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9798 - loss: 3.3968e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9800 - loss: 2.9398e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9788 - loss: 2.3897e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9821 - loss: 2.0382e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9813 - loss: 1.6466e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9811 - loss: 1.3845e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9787 - loss: 1.1630e-04\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.003405195428058505--------------- Accuracy : 0.6539745926856995--- 0.8919505678022712\n",
      "Epoch 2: Loss = 0.002332791918888688--------------- Accuracy : 0.6397127509117126--- 0.8815965263861055\n",
      "Accuracy:0.6397127509117126********************0.8815965263861055\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9533 - loss: 1.5761e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9591 - loss: 1.1716e-04\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.0025971648283302784--------------- Accuracy : 0.6554108262062073--- 0.8929859719438877\n",
      "Epoch 2: Loss = 0.002824772149324417--------------- Accuracy : 0.6634268760681152--- 0.8966599866399465\n",
      "Accuracy:0.6634268760681152********************0.8966599866399465\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9372 - loss: 1.3655e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9371 - loss: 1.0705e-04\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.0030117828864604235--------------- Accuracy : 0.6871075630187988--- 0.9078490313961256\n",
      "Epoch 2: Loss = 0.002624176675453782--------------- Accuracy : 0.695858359336853--- 0.9117902471609887\n",
      "Accuracy:0.695858359336853********************0.9117902471609887\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9202 - loss: 1.1862e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9163 - loss: 9.5941e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.0016433126293122768--------------- Accuracy : 0.6946559548377991--- 0.9153974615898464\n",
      "Epoch 2: Loss = 0.0014451397582888603--------------- Accuracy : 0.7067802548408508--- 0.9179692718770875\n",
      "Accuracy:0.7067802548408508********************0.9179692718770875\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9049 - loss: 1.0884e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9045 - loss: 8.5930e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.0014613056555390358--------------- Accuracy : 0.7185370922088623--- 0.9224782899131596\n",
      "Epoch 2: Loss = 0.0014717835001647472--------------- Accuracy : 0.729124903678894--- 0.9261857047428189\n",
      "Accuracy:0.729124903678894********************0.9261857047428189\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8859 - loss: 1.0151e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8917 - loss: 7.9490e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.001455266261473298--------------- Accuracy : 0.7401803731918335--- 0.9296593186372746\n",
      "Epoch 2: Loss = 0.0014117672108113766--------------- Accuracy : 0.7505009770393372--- 0.9322311289245157\n",
      "Accuracy:0.7505009770393372********************0.9322311289245157\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8830 - loss: 8.5732e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8840 - loss: 7.2355e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.0017085087019950151--------------- Accuracy : 0.758249819278717--- 0.9348363393453574\n",
      "Epoch 2: Loss = 0.0015246968250721693--------------- Accuracy : 0.7667668461799622--- 0.9367735470941884\n",
      "Accuracy:0.7667668461799622********************0.9367735470941884\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8971 - loss: 7.2972e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9009 - loss: 6.4820e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.0020833094604313374--------------- Accuracy : 0.7714095115661621--- 0.9380761523046092\n",
      "Epoch 2: Loss = 0.002062365645542741--------------- Accuracy : 0.7776219248771667--- 0.9381763527054108\n",
      "Accuracy:0.7776219248771667********************0.9381763527054108\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9024 - loss: 8.0868e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9017 - loss: 6.3921e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.0018463095184415579--------------- Accuracy : 0.7854041457176208--- 0.9408817635270541\n",
      "Epoch 2: Loss = 0.0016573485918343067--------------- Accuracy : 0.7883767485618591--- 0.9410821643286573\n",
      "Accuracy:0.7883767485618591********************0.9410821643286573\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9098 - loss: 7.0113e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9110 - loss: 5.7537e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.001984948292374611--------------- Accuracy : 0.7934201955795288--- 0.9430193720774883\n",
      "Epoch 2: Loss = 0.0016396325081586838--------------- Accuracy : 0.7982298135757446--- 0.9439211756847027\n",
      "Accuracy:0.7982298135757446********************0.9439211756847027\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9161 - loss: 6.3901e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9195 - loss: 6.0267e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.0013393766712397337--------------- Accuracy : 0.8072812557220459--- 0.9469939879759519\n",
      "Epoch 2: Loss = 0.0012081792810931802--------------- Accuracy : 0.8116900324821472--- 0.9468937875751503\n",
      "Accuracy:0.8116900324821472********************0.9468937875751503\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9242 - loss: 7.1151e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9120 - loss: 5.6104e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.002345308195799589--------------- Accuracy : 0.8097862601280212--- 0.9455243820975284\n",
      "Epoch 2: Loss = 0.002199057023972273--------------- Accuracy : 0.8126252293586731--- 0.9452571810287241\n",
      "Accuracy:0.8126252293586731********************0.9452571810287241\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9186 - loss: 6.0808e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9233 - loss: 5.0906e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.0016205881256610155--------------- Accuracy : 0.8236806988716125--- 0.9485303941215765\n",
      "Epoch 2: Loss = 0.00158967066090554--------------- Accuracy : 0.832030713558197--- 0.9491315965263861\n",
      "Accuracy:0.832030713558197********************0.9491315965263861\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9280 - loss: 5.3068e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9241 - loss: 4.7766e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.001326868892647326--------------- Accuracy : 0.8342351317405701--- 0.9492985971943888\n",
      "Epoch 2: Loss = 0.0013305330649018288--------------- Accuracy : 0.8376753330230713--- 0.950501002004008\n",
      "Accuracy:0.8376753330230713********************0.950501002004008\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9249 - loss: 7.0297e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9187 - loss: 8.8968e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.0021467143669724464--------------- Accuracy : 0.8361389636993408--- 0.9483633934535738\n",
      "Epoch 2: Loss = 0.0020230598747730255--------------- Accuracy : 0.836172342300415--- 0.9471609886439546\n",
      "Accuracy:0.836172342300415********************0.9471609886439546\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9280 - loss: 9.2223e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9264 - loss: 5.9707e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.002293969038873911--------------- Accuracy : 0.8376753330230713--- 0.9475283901135605\n",
      "Epoch 2: Loss = 0.0018884075107052922--------------- Accuracy : 0.8423847556114197--- 0.9460253841015364\n",
      "Accuracy:0.8423847556114197********************0.9460253841015364\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9305 - loss: 6.1365e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9249 - loss: 4.9291e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.0012244201498106122--------------- Accuracy : 0.8516700267791748--- 0.9481963927855711\n",
      "Epoch 2: Loss = 0.0011218753643333912--------------- Accuracy : 0.8561456203460693--- 0.9476619906479626\n",
      "Accuracy:0.8561456203460693********************0.9476619906479626\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9306 - loss: 5.4686e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9334 - loss: 4.1145e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.002030393108725548--------------- Accuracy : 0.8537741899490356--- 0.9462925851703406\n",
      "Epoch 2: Loss = 0.0017528112512081861--------------- Accuracy : 0.8538410067558289--- 0.9458917835671342\n",
      "Accuracy:0.8538410067558289********************0.9458917835671342\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9292 - loss: 4.5430e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9425 - loss: 3.8770e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.0019009322859346867--------------- Accuracy : 0.8582832217216492--- 0.945557782231129\n",
      "Epoch 2: Loss = 0.001696210354566574--------------- Accuracy : 0.8608550429344177--- 0.9463259853039412\n",
      "Accuracy:0.8608550429344177********************0.9463259853039412\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9349 - loss: 4.1485e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9320 - loss: 3.1552e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Epoch 1: Loss = 0.0020208503119647503--------------- Accuracy : 0.8681696653366089--- 0.9467935871743487\n",
      "Epoch 2: Loss = 0.0018534963019192219--------------- Accuracy : 0.8722444772720337--- 0.9471275885103541\n",
      "Accuracy:0.8722444772720337********************0.9471275885103541\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9335 - loss: 3.2601e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9344 - loss: 2.7825e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.0011899766977876425--------------- Accuracy : 0.8760855197906494--- 0.9475951903807616\n",
      "Epoch 2: Loss = 0.0013378055300563574--------------- Accuracy : 0.8788242936134338--- 0.9483633934535738\n",
      "Accuracy:0.8788242936134338********************0.9483633934535738\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9263 - loss: 3.0697e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9280 - loss: 2.6788e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.0015085600316524506--------------- Accuracy : 0.8768537044525146--- 0.9473613894455578\n",
      "Epoch 2: Loss = 0.0015892956871539354--------------- Accuracy : 0.878156304359436--- 0.9468269873079492\n",
      "Accuracy:0.878156304359436********************0.9468269873079492\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9261 - loss: 2.6320e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9287 - loss: 1.9726e-05\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1: Loss = 0.0021899123676121235--------------- Accuracy : 0.8780561089515686--- 0.9467267869071476\n",
      "Epoch 2: Loss = 0.0017227685311809182--------------- Accuracy : 0.880561113357544--- 0.9469939879759519\n",
      "Accuracy:0.880561113357544********************0.9469939879759519\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n"
     ]
    }
   ],
   "source": [
    "ReplayBuffer = copy.deepcopy(ReplayBuffer_s)\n",
    "rw  = []\n",
    "agent = Agent()\n",
    "memory = deque(maxlen=10000)\n",
    "batch_size = 32\n",
    "episodes =23000\n",
    "#evn = Env(x_train,y_train,999)\n",
    "evn = Env(x_test,y_test,999)\n",
    "kq = []\n",
    "los = []\n",
    "# Huấn luyện agent\n",
    "kq_1 = []\n",
    "kq_2 = []\n",
    "kq_3 = []\n",
    "kq_4 = []\n",
    "n = 2\n",
    "for e in range(episodes):\n",
    "    state = evn.reset()\n",
    "    state = np.expand_dims(state, axis=0)  # Thêm chiều batch\n",
    "    probability = agent.act(state)\n",
    "  \n",
    "    action,reward,uu = evn.step(probability)\n",
    "    kq.append(uu)\n",
    "    ReplayBuffer.add(state[0], action, reward, probability[0])\n",
    "    \n",
    "        \n",
    "    e += 1\n",
    "\n",
    "    if e % 1000 == 0:\n",
    "        agent.update_target_model(ReplayBuffer)\n",
    "        print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
    "\n",
    "\n",
    "\n",
    "        # Cập nhật target model sau mỗi episode\n",
    "        #if episodes // 30 ==0:\n",
    "           # agent.update_target_model("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e9b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
